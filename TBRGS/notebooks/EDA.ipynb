{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "53af67d6",
      "metadata": {
        "id": "53af67d6"
      },
      "source": [
        "# Traffic-based Route Guidance Solution\n",
        "\n",
        "## Data Preprocessing & Analyzing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34243419",
      "metadata": {
        "id": "34243419"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as nm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70369816",
      "metadata": {
        "id": "70369816"
      },
      "source": [
        "1. Load the VicRoads Boroondara dataset (.csv)\n",
        "\n",
        "2. Clean and preprocess:\n",
        "    * Convert timestamps\n",
        "\n",
        "    * Handle missing values\n",
        "\n",
        "    * Normalize/scale traffic flow values\n",
        "\n",
        "3. Reshape for time-series forecasting (e.g., sequences of past 1-2 hours to predict next 15-min slot)\n",
        "\n",
        "### Import the Dataset for analyze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eac413ca",
      "metadata": {
        "scrolled": true,
        "id": "eac413ca",
        "outputId": "f405c51b-e0cf-4cbe-b075-4dbc952cbbcf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SCATS Number</th>\n",
              "      <th>Location</th>\n",
              "      <th>CD_MELWAY</th>\n",
              "      <th>NB_LATITUDE</th>\n",
              "      <th>NB_LONGITUDE</th>\n",
              "      <th>HF VicRoads Internal</th>\n",
              "      <th>VR Internal Stat</th>\n",
              "      <th>VR Internal Loc</th>\n",
              "      <th>NB_TYPE_SURVEY</th>\n",
              "      <th>Date</th>\n",
              "      <th>...</th>\n",
              "      <th>V89</th>\n",
              "      <th>V90</th>\n",
              "      <th>V91</th>\n",
              "      <th>V92</th>\n",
              "      <th>V93</th>\n",
              "      <th>V94</th>\n",
              "      <th>V95</th>\n",
              "      <th>Unnamed: 106</th>\n",
              "      <th>Unnamed: 107</th>\n",
              "      <th>Unnamed: 108</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>970</td>\n",
              "      <td>WARRIGAL_RD N of HIGH STREET_RD</td>\n",
              "      <td>060 G10</td>\n",
              "      <td>-37.86703</td>\n",
              "      <td>145.09159</td>\n",
              "      <td>249</td>\n",
              "      <td>182</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1/10/2006</td>\n",
              "      <td>...</td>\n",
              "      <td>66</td>\n",
              "      <td>81</td>\n",
              "      <td>50</td>\n",
              "      <td>59</td>\n",
              "      <td>47</td>\n",
              "      <td>29</td>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>970</td>\n",
              "      <td>WARRIGAL_RD N of HIGH STREET_RD</td>\n",
              "      <td>060 G10</td>\n",
              "      <td>-37.86703</td>\n",
              "      <td>145.09159</td>\n",
              "      <td>249</td>\n",
              "      <td>182</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2/10/2006</td>\n",
              "      <td>...</td>\n",
              "      <td>114</td>\n",
              "      <td>80</td>\n",
              "      <td>60</td>\n",
              "      <td>62</td>\n",
              "      <td>48</td>\n",
              "      <td>44</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>970</td>\n",
              "      <td>WARRIGAL_RD N of HIGH STREET_RD</td>\n",
              "      <td>060 G10</td>\n",
              "      <td>-37.86703</td>\n",
              "      <td>145.09159</td>\n",
              "      <td>249</td>\n",
              "      <td>182</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3/10/2006</td>\n",
              "      <td>...</td>\n",
              "      <td>86</td>\n",
              "      <td>93</td>\n",
              "      <td>90</td>\n",
              "      <td>73</td>\n",
              "      <td>57</td>\n",
              "      <td>29</td>\n",
              "      <td>40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>970</td>\n",
              "      <td>WARRIGAL_RD N of HIGH STREET_RD</td>\n",
              "      <td>060 G10</td>\n",
              "      <td>-37.86703</td>\n",
              "      <td>145.09159</td>\n",
              "      <td>249</td>\n",
              "      <td>182</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4/10/2006</td>\n",
              "      <td>...</td>\n",
              "      <td>101</td>\n",
              "      <td>113</td>\n",
              "      <td>90</td>\n",
              "      <td>78</td>\n",
              "      <td>66</td>\n",
              "      <td>52</td>\n",
              "      <td>44</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>970</td>\n",
              "      <td>WARRIGAL_RD N of HIGH STREET_RD</td>\n",
              "      <td>060 G10</td>\n",
              "      <td>-37.86703</td>\n",
              "      <td>145.09159</td>\n",
              "      <td>249</td>\n",
              "      <td>182</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5/10/2006</td>\n",
              "      <td>...</td>\n",
              "      <td>113</td>\n",
              "      <td>99</td>\n",
              "      <td>91</td>\n",
              "      <td>61</td>\n",
              "      <td>55</td>\n",
              "      <td>49</td>\n",
              "      <td>36</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4187</th>\n",
              "      <td>4821</td>\n",
              "      <td>VICTORIA_ST W OF BURNLEY_ST</td>\n",
              "      <td>002HF02</td>\n",
              "      <td>-37.81296</td>\n",
              "      <td>145.00830</td>\n",
              "      <td>6673</td>\n",
              "      <td>1513</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>27/10/2006</td>\n",
              "      <td>...</td>\n",
              "      <td>103</td>\n",
              "      <td>122</td>\n",
              "      <td>124</td>\n",
              "      <td>117</td>\n",
              "      <td>99</td>\n",
              "      <td>108</td>\n",
              "      <td>88</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4188</th>\n",
              "      <td>4821</td>\n",
              "      <td>VICTORIA_ST W OF BURNLEY_ST</td>\n",
              "      <td>002HF02</td>\n",
              "      <td>-37.81296</td>\n",
              "      <td>145.00830</td>\n",
              "      <td>6673</td>\n",
              "      <td>1513</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>28/10/2006</td>\n",
              "      <td>...</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>112</td>\n",
              "      <td>82</td>\n",
              "      <td>97</td>\n",
              "      <td>106</td>\n",
              "      <td>107</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4189</th>\n",
              "      <td>4821</td>\n",
              "      <td>VICTORIA_ST W OF BURNLEY_ST</td>\n",
              "      <td>002HF02</td>\n",
              "      <td>-37.81296</td>\n",
              "      <td>145.00830</td>\n",
              "      <td>6673</td>\n",
              "      <td>1513</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>29/10/2006</td>\n",
              "      <td>...</td>\n",
              "      <td>76</td>\n",
              "      <td>66</td>\n",
              "      <td>64</td>\n",
              "      <td>77</td>\n",
              "      <td>60</td>\n",
              "      <td>49</td>\n",
              "      <td>45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4190</th>\n",
              "      <td>4821</td>\n",
              "      <td>VICTORIA_ST W OF BURNLEY_ST</td>\n",
              "      <td>002HF02</td>\n",
              "      <td>-37.81296</td>\n",
              "      <td>145.00830</td>\n",
              "      <td>6673</td>\n",
              "      <td>1513</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>30/10/2006</td>\n",
              "      <td>...</td>\n",
              "      <td>80</td>\n",
              "      <td>74</td>\n",
              "      <td>48</td>\n",
              "      <td>67</td>\n",
              "      <td>62</td>\n",
              "      <td>50</td>\n",
              "      <td>62</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4191</th>\n",
              "      <td>4821</td>\n",
              "      <td>VICTORIA_ST W OF BURNLEY_ST</td>\n",
              "      <td>002HF02</td>\n",
              "      <td>-37.81296</td>\n",
              "      <td>145.00830</td>\n",
              "      <td>6673</td>\n",
              "      <td>1513</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>31/10/2006</td>\n",
              "      <td>...</td>\n",
              "      <td>87</td>\n",
              "      <td>74</td>\n",
              "      <td>87</td>\n",
              "      <td>75</td>\n",
              "      <td>63</td>\n",
              "      <td>51</td>\n",
              "      <td>54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4192 rows × 109 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      SCATS Number                         Location CD_MELWAY  NB_LATITUDE  \\\n",
              "0              970  WARRIGAL_RD N of HIGH STREET_RD   060 G10    -37.86703   \n",
              "1              970  WARRIGAL_RD N of HIGH STREET_RD   060 G10    -37.86703   \n",
              "2              970  WARRIGAL_RD N of HIGH STREET_RD   060 G10    -37.86703   \n",
              "3              970  WARRIGAL_RD N of HIGH STREET_RD   060 G10    -37.86703   \n",
              "4              970  WARRIGAL_RD N of HIGH STREET_RD   060 G10    -37.86703   \n",
              "...            ...                              ...       ...          ...   \n",
              "4187          4821      VICTORIA_ST W OF BURNLEY_ST   002HF02    -37.81296   \n",
              "4188          4821      VICTORIA_ST W OF BURNLEY_ST   002HF02    -37.81296   \n",
              "4189          4821      VICTORIA_ST W OF BURNLEY_ST   002HF02    -37.81296   \n",
              "4190          4821      VICTORIA_ST W OF BURNLEY_ST   002HF02    -37.81296   \n",
              "4191          4821      VICTORIA_ST W OF BURNLEY_ST   002HF02    -37.81296   \n",
              "\n",
              "      NB_LONGITUDE  HF VicRoads Internal  VR Internal Stat  VR Internal Loc  \\\n",
              "0        145.09159                   249               182                1   \n",
              "1        145.09159                   249               182                1   \n",
              "2        145.09159                   249               182                1   \n",
              "3        145.09159                   249               182                1   \n",
              "4        145.09159                   249               182                1   \n",
              "...            ...                   ...               ...              ...   \n",
              "4187     145.00830                  6673              1513                7   \n",
              "4188     145.00830                  6673              1513                7   \n",
              "4189     145.00830                  6673              1513                7   \n",
              "4190     145.00830                  6673              1513                7   \n",
              "4191     145.00830                  6673              1513                7   \n",
              "\n",
              "      NB_TYPE_SURVEY        Date  ...  V89  V90  V91  V92  V93  V94  V95  \\\n",
              "0                  1   1/10/2006  ...   66   81   50   59   47   29   34   \n",
              "1                  1   2/10/2006  ...  114   80   60   62   48   44   26   \n",
              "2                  1   3/10/2006  ...   86   93   90   73   57   29   40   \n",
              "3                  1   4/10/2006  ...  101  113   90   78   66   52   44   \n",
              "4                  1   5/10/2006  ...  113   99   91   61   55   49   36   \n",
              "...              ...         ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "4187               1  27/10/2006  ...  103  122  124  117   99  108   88   \n",
              "4188               1  28/10/2006  ...  105  105  112   82   97  106  107   \n",
              "4189               1  29/10/2006  ...   76   66   64   77   60   49   45   \n",
              "4190               1  30/10/2006  ...   80   74   48   67   62   50   62   \n",
              "4191               1  31/10/2006  ...   87   74   87   75   63   51   54   \n",
              "\n",
              "      Unnamed: 106  Unnamed: 107  Unnamed: 108  \n",
              "0              NaN           NaN           NaN  \n",
              "1              NaN           NaN           NaN  \n",
              "2              NaN           NaN           NaN  \n",
              "3              NaN           NaN           NaN  \n",
              "4              NaN           NaN           NaN  \n",
              "...            ...           ...           ...  \n",
              "4187           NaN           NaN           NaN  \n",
              "4188           NaN           NaN           NaN  \n",
              "4189           NaN           NaN           NaN  \n",
              "4190           NaN           NaN           NaN  \n",
              "4191           NaN           NaN           NaN  \n",
              "\n",
              "[4192 rows x 109 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('../data/raw/Scats Data October 2006.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "91d03b75-67ce-4d36-b6b0-006f60c84331",
      "metadata": {
        "id": "91d03b75-67ce-4d36-b6b0-006f60c84331",
        "outputId": "82594fd4-5884-4ed9-c029-3068f3f47097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 1 fields in line 42, saw 48\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0507a3cb39e1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Load the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://github.com/yasirulokesha/IntroToAI-Assignment-2B/blob/main/TBRGS/data/raw/Scats%20Data%20October%202006.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Assuming your dataframe 'df' is already loaded and preprocessed as in your previous code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 42, saw 48\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Load the dataframe\n",
        "df = pd.read_csv('https://github.com/yasirulokesha/IntroToAI-Assignment-2B/blob/main/TBRGS/data/raw/Scats%20Data%20October%202006.csv')\n",
        "\n",
        "# Assuming your dataframe 'df' is already loaded and preprocessed as in your previous code\n",
        "\n",
        "# Feature Engineering (Example: Create time features)\n",
        "df['Timestamp'] = pd.to_datetime(df['TIMESTAMP'])\n",
        "df['Hour'] = df['Timestamp'].dt.hour\n",
        "df['DayOfWeek'] = df['Timestamp'].dt.dayofweek\n",
        "df['Month'] = df['Timestamp'].dt.month\n",
        "\n",
        "\n",
        "# Select relevant features for prediction (adjust as needed)\n",
        "features = ['Volume', 'Hour', 'DayOfWeek', 'Month', 'Detector ID'] # Example features\n",
        "target = 'Volume'  # Target variable (traffic volume)\n",
        "\n",
        "\n",
        "# One-hot encode categorical features (if needed)\n",
        "df = pd.get_dummies(df, columns=['Detector ID'], prefix='Detector')\n",
        "\n",
        "\n",
        "# Normalize/Scale Numerical Features (important for neural networks)\n",
        "scaler = MinMaxScaler()\n",
        "numerical_features = ['Volume', 'Hour', 'DayOfWeek', 'Month'] # Features to scale\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "\n",
        "# Prepare the data for time series prediction (Example: sequences of past 2 hours to predict next 15 minutes)\n",
        "def create_sequences(data, seq_length):\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for i in range(len(data) - seq_length - 1):\n",
        "        x = data[i:(i + seq_length)]\n",
        "        y = data[i + seq_length]\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    return np.array(xs), np.array(ys)\n",
        "\n",
        "\n",
        "seq_length = 2 # Example sequence length (adjust as needed)\n",
        "X, y = create_sequences(df[features].values, seq_length)\n",
        "\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Build and train an LSTM model (example)\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X_train, y_train[:, 0], epochs=50, batch_size=32, validation_split = 0.1, verbose = 1) # Adjust epochs and batch size\n",
        "\n",
        "\n",
        "# Prediction Function\n",
        "def predict_traffic(model, data, origin, destination, timestamp):\n",
        "    # Preprocess the input (e.g., convert timestamp to features like Hour, DayOfWeek)\n",
        "    # One-hot encode categorical features (e.g. Origin and Destination)\n",
        "    # Scale input data\n",
        "    # Reshape the data into a sequence of length 'seq_length'\n",
        "    # Use the model to make a prediction\n",
        "    prediction = model.predict(data)[0][0]  # Extract prediction\n",
        "    prediction = scaler.inverse_transform([[prediction, 0, 0, 0]])[0][0] # Inverse transform prediction to original scale\n",
        "    return prediction\n",
        "\n",
        "# Example usage (replace with actual data)\n",
        "# Input the origin, destination, date, and time\n",
        "# Preprocess the input data\n",
        "# Predict the traffic volume for that timestamp\n",
        "# Output the prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7_Vx9OK6Hzgw"
      },
      "id": "7_Vx9OK6Hzgw",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}