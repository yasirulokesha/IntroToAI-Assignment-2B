{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7378b7",
   "metadata": {},
   "source": [
    "# Traffic-based Route Guidance Solution\n",
    "\n",
    "## Import the Dependancies and Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34243419",
   "metadata": {
    "id": "34243419"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70369816",
   "metadata": {
    "id": "70369816"
   },
   "source": [
    "## Data Preprocessing & Analyzing\n",
    "\n",
    "1. Load the VicRoads Boroondara dataset (.csv)\n",
    "\n",
    "2. Clean and preprocess:\n",
    "    * Convert timestamps\n",
    "\n",
    "    * Handle missing values\n",
    "\n",
    "    * Normalize/scale traffic flow values\n",
    "\n",
    "3. Reshape for time-series forecasting (e.g., sequences of past 1-2 hours to predict next 15-min slot)\n",
    "\n",
    "### Import the Dataset for analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac413ca",
   "metadata": {
    "id": "eac413ca",
    "outputId": "f405c51b-e0cf-4cbe-b075-4dbc952cbbcf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_dataset = pd.read_csv('https://raw.githubusercontent.com/yasirulokesha/IntroToAI-Assignment-2B/refs/heads/main/TBRGS/data/raw/Scats%20Data%20October%202006.csv', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb1782",
   "metadata": {},
   "source": [
    "### Cluster and Make the Train and Test the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7_Vx9OK6Hzgw",
   "metadata": {
    "id": "7_Vx9OK6Hzgw"
   },
   "outputs": [],
   "source": [
    "# Create time mapping for V00â€“V95 (15-minute intervals)\n",
    "time_labels = [f\"{h:02}:{m:02}:00\" for h in range(24) for m in range(0, 60, 15)]\n",
    "v_columns = [f\"V{str(i).zfill(2)}\" for i in range(96)]\n",
    "time_map = dict(zip(v_columns, time_labels))\n",
    "\n",
    "# Melt the V columns into long format\n",
    "df_melted = main_dataset.melt(\n",
    "    id_vars=[\"SCATS Number\", \"Location\", \"Date\"],\n",
    "    value_vars=v_columns,\n",
    "    var_name=\"time_code\",\n",
    "    value_name=\"volume\"\n",
    ")\n",
    "\n",
    "# Map time codes to actual time strings\n",
    "df_melted['time_str'] = df_melted['time_code'].map(time_map)\n",
    "\n",
    "# Combine Date and Time into a full timestamp\n",
    "df_melted['timestamp'] = pd.to_datetime(df_melted['Date'] + ' ' + df_melted['time_str'], dayfirst=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_melted = df_melted.rename(columns={\n",
    "    \"SCATS Number\": \"site_id\",\n",
    "    \"Location\": \"location\"\n",
    "})\n",
    "\n",
    "# Select and reorder important columns\n",
    "df_traffic = df_melted[[\"site_id\", \"location\", \"timestamp\", \"volume\"]]\n",
    "\n",
    "# ğŸ” AGGREGATE: Sum volume over all directions at each site per timestamp\n",
    "final_dataset = df_melted.groupby(['site_id', 'timestamp'])['volume'].sum().reset_index()\n",
    "\n",
    "sites = final_dataset['site_id'].unique()\n",
    "\n",
    "final_dataset.to_csv('../data/processed/processed_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca94c7",
   "metadata": {},
   "source": [
    "### Scaling the dataset using MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c2600",
   "metadata": {},
   "source": [
    "### Breakdown the dataset for unique sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb038e7",
   "metadata": {},
   "source": [
    "### Data processing for ML\n",
    "\n",
    "#### Create Time Series Sequences for Training and Testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a35749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for creating sequences\n",
    "def create_sequences(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd61da",
   "metadata": {},
   "source": [
    "### Make the unique sequences for different sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63bf9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_sequences(data_set):\n",
    "    x, y = create_sequences(data_set, 96)\n",
    "    x = x.reshape(-1, 96, 1)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e44ab",
   "metadata": {},
   "source": [
    "### Drop Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ccd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace outliers using IQR\n",
    "def replace_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)  # First quartile (25th percentile)\n",
    "    Q3 = df[column].quantile(0.75)  # Third quartile (75th percentile)\n",
    "    IQR = Q3 - Q1  # Interquartile range\n",
    "\n",
    "    # Define bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Replace outliers with the median\n",
    "    median = df[column].median()\n",
    "    df[column] = df[column].apply(lambda x: median if x < lower_bound or x > upper_bound else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277b0f53",
   "metadata": {},
   "source": [
    "## - Generating the models and save for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae54790a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.2023 - mae: 0.3558 - val_loss: 0.0461 - val_mae: 0.1802\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0397 - mae: 0.1638 - val_loss: 0.0218 - val_mae: 0.1142\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0206 - mae: 0.1124 - val_loss: 0.0154 - val_mae: 0.0967\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0154 - mae: 0.0980 - val_loss: 0.0114 - val_mae: 0.0799\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0115 - mae: 0.0818 - val_loss: 0.0147 - val_mae: 0.1019\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0168 - mae: 0.1063 - val_loss: 0.0142 - val_mae: 0.0956\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0131 - mae: 0.0904 - val_loss: 0.0096 - val_mae: 0.0761\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0093 - mae: 0.0750 - val_loss: 0.0076 - val_mae: 0.0659\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0075 - mae: 0.0652 - val_loss: 0.0062 - val_mae: 0.0604\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0062 - mae: 0.0594 - val_loss: 0.0052 - val_mae: 0.0570\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0052 - mae: 0.0562 - val_loss: 0.0045 - val_mae: 0.0530\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0045 - mae: 0.0523 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0035 - val_mae: 0.0457\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0035 - mae: 0.0459 - val_loss: 0.0031 - val_mae: 0.0430\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0031 - mae: 0.0425 - val_loss: 0.0027 - val_mae: 0.0399\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0403 - val_loss: 0.0023 - val_mae: 0.0365\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0390 - val_loss: 0.0022 - val_mae: 0.0357\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0366 - val_loss: 0.0020 - val_mae: 0.0336\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0022 - mae: 0.0361 - val_loss: 0.0022 - val_mae: 0.0355\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0371 - val_loss: 0.0024 - val_mae: 0.0357\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0022 - mae: 0.0353 - val_loss: 0.0023 - val_mae: 0.0349\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0021 - mae: 0.0344 - val_loss: 0.0021 - val_mae: 0.0339\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0334 - val_loss: 0.0020 - val_mae: 0.0332\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0019 - mae: 0.0327 - val_loss: 0.0019 - val_mae: 0.0326\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0321 - val_loss: 0.0018 - val_mae: 0.0317\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0314 - val_loss: 0.0017 - val_mae: 0.0312\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0308 - val_loss: 0.0017 - val_mae: 0.0304\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0303 - val_loss: 0.0017 - val_mae: 0.0298\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.0017 - val_mae: 0.0296\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0017 - val_mae: 0.0297\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0017 - val_mae: 0.0293\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0017 - val_mae: 0.0296\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0016 - val_mae: 0.0289\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0017 - val_mae: 0.0298\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0016 - val_mae: 0.0285\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0018 - val_mae: 0.0304\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0015 - val_mae: 0.0283\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0017 - val_mae: 0.0299\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0015 - val_mae: 0.0281\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0016 - val_mae: 0.0291\n",
      "\n",
      "âœ… Model and scaler saved for site 970.\n",
      "2000\n",
      "Epoch 1/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1690 - mae: 0.3264 - val_loss: 0.0454 - val_mae: 0.1787\n",
      "Epoch 2/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0414 - mae: 0.1706 - val_loss: 0.0262 - val_mae: 0.1355\n",
      "Epoch 3/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0278 - mae: 0.1364 - val_loss: 0.0173 - val_mae: 0.1060\n",
      "Epoch 4/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0191 - mae: 0.1103 - val_loss: 0.0131 - val_mae: 0.0916\n",
      "Epoch 5/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0157 - mae: 0.1001 - val_loss: 0.0181 - val_mae: 0.1077\n",
      "Epoch 6/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0202 - mae: 0.1142 - val_loss: 0.0144 - val_mae: 0.1008\n",
      "Epoch 7/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0153 - mae: 0.1044 - val_loss: 0.0106 - val_mae: 0.0841\n",
      "Epoch 8/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0108 - mae: 0.0859 - val_loss: 0.0078 - val_mae: 0.0707\n",
      "Epoch 9/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 71.0801 - mae: 0.1862 - val_loss: 0.0310 - val_mae: 0.1384\n",
      "Epoch 10/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0495 - mae: 0.1747 - val_loss: 0.0724 - val_mae: 0.2222\n",
      "Epoch 11/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0722 - mae: 0.2150 - val_loss: 0.0691 - val_mae: 0.2134\n",
      "Epoch 12/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0675 - mae: 0.2043 - val_loss: 0.0629 - val_mae: 0.2011\n",
      "Epoch 13/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0615 - mae: 0.1932 - val_loss: 0.0572 - val_mae: 0.1909\n",
      "Epoch 14/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0562 - mae: 0.1842 - val_loss: 0.0523 - val_mae: 0.1822\n",
      "Epoch 15/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0516 - mae: 0.1764 - val_loss: 0.0480 - val_mae: 0.1745\n",
      "Epoch 16/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0475 - mae: 0.1697 - val_loss: 0.0442 - val_mae: 0.1675\n",
      "Epoch 17/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0439 - mae: 0.1637 - val_loss: 0.0408 - val_mae: 0.1612\n",
      "Epoch 18/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0408 - mae: 0.1584 - val_loss: 0.0378 - val_mae: 0.1556\n",
      "Epoch 19/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0380 - mae: 0.1535 - val_loss: 0.0352 - val_mae: 0.1504\n",
      "Epoch 20/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0355 - mae: 0.1492 - val_loss: 0.0329 - val_mae: 0.1457\n",
      "Epoch 21/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0333 - mae: 0.1452 - val_loss: 0.0308 - val_mae: 0.1416\n",
      "Epoch 22/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0314 - mae: 0.1418 - val_loss: 0.0290 - val_mae: 0.1380\n",
      "Epoch 23/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0297 - mae: 0.1387 - val_loss: 0.0273 - val_mae: 0.1348\n",
      "Epoch 24/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0281 - mae: 0.1360 - val_loss: 0.0258 - val_mae: 0.1320\n",
      "Epoch 25/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0267 - mae: 0.1335 - val_loss: 0.0245 - val_mae: 0.1293\n",
      "Epoch 26/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0253 - mae: 0.1310 - val_loss: 0.0231 - val_mae: 0.1266\n",
      "Epoch 27/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0238 - mae: 0.1282 - val_loss: 0.0212 - val_mae: 0.1224\n",
      "Epoch 28/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 6671331840.0000 - mae: 1400.1244 - val_loss: 0.0359 - val_mae: 0.1672\n",
      "Epoch 29/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0803 - mae: 0.2535 - val_loss: 0.0655 - val_mae: 0.2357\n",
      "Epoch 30/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0336 - mae: 0.1552 - val_loss: 0.0137 - val_mae: 0.1009\n",
      "Epoch 31/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0155 - mae: 0.1070 - val_loss: 0.0116 - val_mae: 0.0904\n",
      "Epoch 32/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0129 - mae: 0.0957 - val_loss: 0.0099 - val_mae: 0.0804\n",
      "Epoch 33/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0113 - mae: 0.0859 - val_loss: 0.0088 - val_mae: 0.0729\n",
      "Epoch 34/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0102 - mae: 0.0792 - val_loss: 0.0081 - val_mae: 0.0699\n",
      "Epoch 35/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0093 - mae: 0.0752 - val_loss: 0.0071 - val_mae: 0.0633\n",
      "Epoch 36/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0082 - mae: 0.0686 - val_loss: 0.0061 - val_mae: 0.0580\n",
      "Epoch 37/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0070 - mae: 0.0638 - val_loss: 0.0057 - val_mae: 0.0577\n",
      "Epoch 38/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0071 - mae: 0.0660 - val_loss: 0.0059 - val_mae: 0.0597\n",
      "Epoch 39/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0069 - mae: 0.0655 - val_loss: 0.0049 - val_mae: 0.0541\n",
      "Epoch 40/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0056 - mae: 0.0560 - val_loss: 0.0047 - val_mae: 0.0533\n",
      "\n",
      "âœ… Model and scaler saved for site 2000.\n",
      "2200\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.2338 - mae: 0.3876 - val_loss: 0.0524 - val_mae: 0.1910\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0409 - mae: 0.1631 - val_loss: 0.0182 - val_mae: 0.0943\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0168 - mae: 0.0880 - val_loss: 0.0131 - val_mae: 0.0913\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0127 - mae: 0.0878 - val_loss: 0.0096 - val_mae: 0.0722\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0108 - mae: 0.0783 - val_loss: 0.0110 - val_mae: 0.0813\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0103 - mae: 0.0762 - val_loss: 0.0081 - val_mae: 0.0679\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0085 - mae: 0.0702 - val_loss: 0.0110 - val_mae: 0.0873\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0096 - mae: 0.0773 - val_loss: 0.0080 - val_mae: 0.0710\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0081 - mae: 0.0688 - val_loss: 0.0101 - val_mae: 0.0835\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0090 - mae: 0.0740 - val_loss: 0.0059 - val_mae: 0.0559\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0060 - mae: 0.0573 - val_loss: 0.0048 - val_mae: 0.0518\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0051 - mae: 0.0536 - val_loss: 0.0052 - val_mae: 0.0562\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0045 - mae: 0.0509 - val_loss: 0.0039 - val_mae: 0.0495\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0038 - mae: 0.0472 - val_loss: 0.0030 - val_mae: 0.0443\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0033 - val_mae: 0.0474\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0033 - mae: 0.0433 - val_loss: 0.0039 - val_mae: 0.0469\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0040 - mae: 0.0468 - val_loss: 0.0035 - val_mae: 0.0450\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0036 - mae: 0.0454 - val_loss: 0.0023 - val_mae: 0.0354\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0394 - val_loss: 0.0022 - val_mae: 0.0368\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0023 - val_mae: 0.0385\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0019 - val_mae: 0.0322\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0024 - mae: 0.0364 - val_loss: 0.0021 - val_mae: 0.0361\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0024 - mae: 0.0368 - val_loss: 0.0018 - val_mae: 0.0315\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0022 - mae: 0.0349 - val_loss: 0.0019 - val_mae: 0.0305\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0022 - mae: 0.0351 - val_loss: 0.0018 - val_mae: 0.0308\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0344 - val_loss: 0.0018 - val_mae: 0.0301\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0022 - mae: 0.0344 - val_loss: 0.0018 - val_mae: 0.0301\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0021 - mae: 0.0336 - val_loss: 0.0019 - val_mae: 0.0311\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0022 - mae: 0.0343 - val_loss: 0.0017 - val_mae: 0.0299\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0021 - mae: 0.0337 - val_loss: 0.0017 - val_mae: 0.0296\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0021 - mae: 0.0331 - val_loss: 0.0017 - val_mae: 0.0295\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0021 - mae: 0.0334 - val_loss: 0.0017 - val_mae: 0.0295\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0021 - mae: 0.0333 - val_loss: 0.0017 - val_mae: 0.0294\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0021 - mae: 0.0331 - val_loss: 0.0017 - val_mae: 0.0294\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 0.0017 - val_mae: 0.0293\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0016 - val_mae: 0.0287\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0016 - val_mae: 0.0290\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0327 - val_loss: 0.0017 - val_mae: 0.0303\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0320 - val_loss: 0.0020 - val_mae: 0.0351\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0019 - mae: 0.0324 - val_loss: 0.0023 - val_mae: 0.0394\n",
      "\n",
      "âœ… Model and scaler saved for site 2200.\n",
      "2820\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1452 - mae: 0.2992 - val_loss: 0.0235 - val_mae: 0.1318\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0239 - mae: 0.1334 - val_loss: 0.0127 - val_mae: 0.0920\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0149 - mae: 0.0965 - val_loss: 0.0075 - val_mae: 0.0674\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0095 - mae: 0.0746 - val_loss: 0.0065 - val_mae: 0.0641\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0078 - mae: 0.0662 - val_loss: 0.0060 - val_mae: 0.0621\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0633 - val_loss: 0.0052 - val_mae: 0.0568\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0569 - val_loss: 0.0051 - val_mae: 0.0571\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0051 - mae: 0.0541 - val_loss: 0.0049 - val_mae: 0.0567\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0045 - mae: 0.0503 - val_loss: 0.0042 - val_mae: 0.0520\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0047 - mae: 0.0514 - val_loss: 0.0041 - val_mae: 0.0517\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0043 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0510\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0043 - mae: 0.0485 - val_loss: 0.0037 - val_mae: 0.0489\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0040 - mae: 0.0464 - val_loss: 0.0038 - val_mae: 0.0490\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0036 - mae: 0.0443 - val_loss: 0.0032 - val_mae: 0.0433\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0040 - mae: 0.0464 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0043 - mae: 0.0489 - val_loss: 0.0034 - val_mae: 0.0462\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0039 - mae: 0.0459 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0037 - mae: 0.0451 - val_loss: 0.0034 - val_mae: 0.0465\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0036 - mae: 0.0444 - val_loss: 0.0032 - val_mae: 0.0454\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0035 - mae: 0.0435 - val_loss: 0.0032 - val_mae: 0.0450\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0034 - mae: 0.0428 - val_loss: 0.0032 - val_mae: 0.0452\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0033 - mae: 0.0421 - val_loss: 0.0032 - val_mae: 0.0452\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0031 - mae: 0.0411 - val_loss: 0.0030 - val_mae: 0.0438\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0399 - val_loss: 0.0028 - val_mae: 0.0415\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0384 - val_loss: 0.0024 - val_mae: 0.0375\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0366 - val_loss: 0.0024 - val_mae: 0.0375\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0025 - mae: 0.0355 - val_loss: 0.0023 - val_mae: 0.0361\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0025 - mae: 0.0353 - val_loss: 0.0024 - val_mae: 0.0365\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0025 - mae: 0.0353 - val_loss: 0.0023 - val_mae: 0.0364\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0024 - mae: 0.0347 - val_loss: 0.0024 - val_mae: 0.0365\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0025 - mae: 0.0352 - val_loss: 0.0024 - val_mae: 0.0370\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0024 - mae: 0.0346 - val_loss: 0.0024 - val_mae: 0.0362\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0023 - mae: 0.0342 - val_loss: 0.0025 - val_mae: 0.0382\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0023 - mae: 0.0345 - val_loss: 0.0023 - val_mae: 0.0353\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0023 - mae: 0.0337 - val_loss: 0.0025 - val_mae: 0.0373\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0022 - mae: 0.0337 - val_loss: 0.0024 - val_mae: 0.0369\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0336 - val_loss: 0.0023 - val_mae: 0.0359\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0022 - mae: 0.0333 - val_loss: 0.0025 - val_mae: 0.0368\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0023 - mae: 0.0336 - val_loss: 0.0022 - val_mae: 0.0349\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0336 - val_loss: 0.0024 - val_mae: 0.0366\n",
      "\n",
      "âœ… Model and scaler saved for site 2820.\n",
      "2825\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1263 - mae: 0.2797 - val_loss: 0.0308 - val_mae: 0.1422\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0271 - mae: 0.1297 - val_loss: 0.0177 - val_mae: 0.0998\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0177 - mae: 0.0982 - val_loss: 0.0119 - val_mae: 0.0801\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0130 - mae: 0.0870 - val_loss: 0.0097 - val_mae: 0.0735\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0114 - mae: 0.0812 - val_loss: 0.0098 - val_mae: 0.0749\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0101 - mae: 0.0740 - val_loss: 0.0077 - val_mae: 0.0663\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0081 - mae: 0.0678 - val_loss: 0.0131 - val_mae: 0.0959\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0154 - mae: 0.0971 - val_loss: 0.0129 - val_mae: 0.0866\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0126 - mae: 0.0866 - val_loss: 0.0089 - val_mae: 0.0705\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0094 - mae: 0.0725 - val_loss: 0.0076 - val_mae: 0.0636\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0082 - mae: 0.0665 - val_loss: 0.0069 - val_mae: 0.0608\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0075 - mae: 0.0638 - val_loss: 0.0063 - val_mae: 0.0589\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0068 - mae: 0.0610 - val_loss: 0.0057 - val_mae: 0.0562\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0061 - mae: 0.0581 - val_loss: 0.0058 - val_mae: 0.0604\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0050 - mae: 0.0504 - val_loss: 0.0037 - val_mae: 0.0438\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0050 - mae: 0.0503 - val_loss: 0.0043 - val_mae: 0.0458\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0044 - mae: 0.0471 - val_loss: 0.0037 - val_mae: 0.0454\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0037 - mae: 0.0436 - val_loss: 0.0037 - val_mae: 0.0466\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0034 - mae: 0.0435 - val_loss: 0.0036 - val_mae: 0.0465\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0427 - val_loss: 0.0032 - val_mae: 0.0428\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0031 - mae: 0.0414 - val_loss: 0.0032 - val_mae: 0.0434\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0031 - mae: 0.0411 - val_loss: 0.0030 - val_mae: 0.0411\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0405 - val_loss: 0.0031 - val_mae: 0.0417\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0403 - val_loss: 0.0029 - val_mae: 0.0397\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0396 - val_loss: 0.0029 - val_mae: 0.0404\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0029 - mae: 0.0394 - val_loss: 0.0027 - val_mae: 0.0392\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0028 - mae: 0.0389 - val_loss: 0.0028 - val_mae: 0.0404\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0387 - val_loss: 0.0026 - val_mae: 0.0389\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0028 - mae: 0.0379 - val_loss: 0.0026 - val_mae: 0.0395\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0027 - mae: 0.0376 - val_loss: 0.0027 - val_mae: 0.0396\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0375 - val_loss: 0.0026 - val_mae: 0.0392\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0027 - mae: 0.0370 - val_loss: 0.0026 - val_mae: 0.0393\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0027 - mae: 0.0371 - val_loss: 0.0026 - val_mae: 0.0389\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0367 - val_loss: 0.0026 - val_mae: 0.0391\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0367 - val_loss: 0.0025 - val_mae: 0.0386\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0364 - val_loss: 0.0026 - val_mae: 0.0390\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0026 - mae: 0.0366 - val_loss: 0.0025 - val_mae: 0.0384\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0363 - val_loss: 0.0026 - val_mae: 0.0388\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0026 - mae: 0.0365 - val_loss: 0.0025 - val_mae: 0.0383\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0362 - val_loss: 0.0026 - val_mae: 0.0390\n",
      "\n",
      "âœ… Model and scaler saved for site 2825.\n",
      "2827\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1883 - mae: 0.3480 - val_loss: 0.0348 - val_mae: 0.1613\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0376 - mae: 0.1633 - val_loss: 0.0220 - val_mae: 0.1273\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0222 - mae: 0.1253 - val_loss: 0.0122 - val_mae: 0.0878\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0132 - mae: 0.0901 - val_loss: 0.0085 - val_mae: 0.0759\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0092 - mae: 0.0775 - val_loss: 0.0069 - val_mae: 0.0681\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0072 - mae: 0.0676 - val_loss: 0.0051 - val_mae: 0.0573\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0562 - val_loss: 0.0043 - val_mae: 0.0527\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0045 - mae: 0.0518 - val_loss: 0.0033 - val_mae: 0.0443\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0037 - mae: 0.0469 - val_loss: 0.0027 - val_mae: 0.0397\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 0.0033 - val_mae: 0.0485\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0027 - mae: 0.0406 - val_loss: 0.0025 - val_mae: 0.0396\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0029 - mae: 0.0419 - val_loss: 0.0025 - val_mae: 0.0383\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0029 - mae: 0.0406 - val_loss: 0.0023 - val_mae: 0.0399\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0351 - val_loss: 0.0024 - val_mae: 0.0420\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0355 - val_loss: 0.0030 - val_mae: 0.0477\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 0.0016 - val_mae: 0.0310\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0344 - val_loss: 0.0015 - val_mae: 0.0298\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0019 - mae: 0.0327 - val_loss: 0.0023 - val_mae: 0.0416\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0021 - mae: 0.0355 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0018 - mae: 0.0314 - val_loss: 0.0016 - val_mae: 0.0323\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0018 - mae: 0.0328 - val_loss: 0.0015 - val_mae: 0.0310\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0330 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0306 - val_loss: 0.0017 - val_mae: 0.0337\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0019 - mae: 0.0329 - val_loss: 0.0014 - val_mae: 0.0275\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0307 - val_loss: 0.0014 - val_mae: 0.0290\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0313 - val_loss: 0.0014 - val_mae: 0.0282\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0312 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0017 - mae: 0.0305 - val_loss: 0.0014 - val_mae: 0.0288\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0312 - val_loss: 0.0014 - val_mae: 0.0279\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0304 - val_loss: 0.0014 - val_mae: 0.0292\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0017 - mae: 0.0310 - val_loss: 0.0013 - val_mae: 0.0281\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0016 - mae: 0.0303 - val_loss: 0.0014 - val_mae: 0.0287\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0307 - val_loss: 0.0013 - val_mae: 0.0280\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 0.0014 - val_mae: 0.0284\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0016 - mae: 0.0304 - val_loss: 0.0013 - val_mae: 0.0281\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 0.0013 - val_mae: 0.0282\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 0.0013 - val_mae: 0.0280\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0013 - val_mae: 0.0279\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0013 - val_mae: 0.0280\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.0013 - val_mae: 0.0275\n",
      "\n",
      "âœ… Model and scaler saved for site 2827.\n",
      "2846\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.1152 - mae: 0.2627 - val_loss: 0.0303 - val_mae: 0.1412\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0291 - mae: 0.1337 - val_loss: 0.0216 - val_mae: 0.1162\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0212 - mae: 0.1130 - val_loss: 0.0144 - val_mae: 0.0880\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0145 - mae: 0.0898 - val_loss: 0.0120 - val_mae: 0.0839\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0121 - mae: 0.0838 - val_loss: 0.0102 - val_mae: 0.0806\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0112 - mae: 0.0820 - val_loss: 0.0090 - val_mae: 0.0713\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0091 - mae: 0.0698 - val_loss: 0.0059 - val_mae: 0.0598\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0062 - mae: 0.0566 - val_loss: 0.0043 - val_mae: 0.0516\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0123 - mae: 0.0800 - val_loss: 0.0148 - val_mae: 0.0894\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0142 - mae: 0.0910 - val_loss: 0.0111 - val_mae: 0.0850\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0844 - val_loss: 0.0093 - val_mae: 0.0736\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0098 - mae: 0.0744 - val_loss: 0.0080 - val_mae: 0.0668\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0087 - mae: 0.0685 - val_loss: 0.0071 - val_mae: 0.0612\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0077 - mae: 0.0632 - val_loss: 0.0058 - val_mae: 0.0547\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.9721 - mae: 0.0768 - val_loss: 0.0073 - val_mae: 0.0615\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0117 - mae: 0.0781 - val_loss: 0.0140 - val_mae: 0.0895\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0150 - mae: 0.0935 - val_loss: 0.0129 - val_mae: 0.0889\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0138 - mae: 0.0921 - val_loss: 0.0122 - val_mae: 0.0882\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0132 - mae: 0.0911 - val_loss: 0.0119 - val_mae: 0.0878\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0129 - mae: 0.0905 - val_loss: 0.0117 - val_mae: 0.0875\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0127 - mae: 0.0901 - val_loss: 0.0116 - val_mae: 0.0871\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0125 - mae: 0.0897 - val_loss: 0.0115 - val_mae: 0.0867\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0124 - mae: 0.0892 - val_loss: 0.0114 - val_mae: 0.0862\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0123 - mae: 0.0888 - val_loss: 0.0113 - val_mae: 0.0857\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0123 - mae: 0.0883 - val_loss: 0.0112 - val_mae: 0.0851\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0122 - mae: 0.0878 - val_loss: 0.0111 - val_mae: 0.0846\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0121 - mae: 0.0873 - val_loss: 0.0110 - val_mae: 0.0840\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0120 - mae: 0.0868 - val_loss: 0.0109 - val_mae: 0.0835\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0119 - mae: 0.0863 - val_loss: 0.0109 - val_mae: 0.0830\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0119 - mae: 0.0858 - val_loss: 0.0108 - val_mae: 0.0825\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0118 - mae: 0.0854 - val_loss: 0.0107 - val_mae: 0.0820\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0117 - mae: 0.0849 - val_loss: 0.0106 - val_mae: 0.0815\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0117 - mae: 0.0845 - val_loss: 0.0106 - val_mae: 0.0810\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0116 - mae: 0.0841 - val_loss: 0.0105 - val_mae: 0.0806\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0116 - mae: 0.0837 - val_loss: 0.0105 - val_mae: 0.0801\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0115 - mae: 0.0833 - val_loss: 0.0104 - val_mae: 0.0797\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0115 - mae: 0.0829 - val_loss: 0.0103 - val_mae: 0.0793\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0825 - val_loss: 0.0103 - val_mae: 0.0789\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0822 - val_loss: 0.0102 - val_mae: 0.0785\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0113 - mae: 0.0818 - val_loss: 0.0102 - val_mae: 0.0781\n",
      "\n",
      "âœ… Model and scaler saved for site 2846.\n",
      "3001\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1294 - mae: 0.2957 - val_loss: 0.0333 - val_mae: 0.1556\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0257 - mae: 0.1301 - val_loss: 0.0208 - val_mae: 0.1181\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0185 - mae: 0.1079 - val_loss: 0.0167 - val_mae: 0.1006\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0152 - mae: 0.0935 - val_loss: 0.0143 - val_mae: 0.0907\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0131 - mae: 0.0874 - val_loss: 0.0132 - val_mae: 0.0874\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0119 - mae: 0.0839 - val_loss: 0.0121 - val_mae: 0.0815\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 462250.6562 - mae: 19.7408 - val_loss: 0.0194 - val_mae: 0.0991\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0217 - mae: 0.1066 - val_loss: 0.0268 - val_mae: 0.1177\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0260 - mae: 0.1183 - val_loss: 0.0257 - val_mae: 0.1145\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0233 - mae: 0.1118 - val_loss: 0.0131 - val_mae: 0.0894\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0121 - mae: 0.0837 - val_loss: 0.0122 - val_mae: 0.0839\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0109 - mae: 0.0799 - val_loss: 0.0116 - val_mae: 0.0834\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0104 - mae: 0.0784 - val_loss: 0.0111 - val_mae: 0.0796\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0100 - mae: 0.0759 - val_loss: 0.0120 - val_mae: 0.0811\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0116 - mae: 0.0802 - val_loss: 0.0121 - val_mae: 0.0843\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0104 - mae: 0.0794 - val_loss: 0.0111 - val_mae: 0.0764\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0099 - mae: 0.0749 - val_loss: 0.0108 - val_mae: 0.0763\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0095 - mae: 0.0737 - val_loss: 0.0107 - val_mae: 0.0776\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0094 - mae: 0.0736 - val_loss: 0.0107 - val_mae: 0.0781\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0094 - mae: 0.0734 - val_loss: 0.0106 - val_mae: 0.0780\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0093 - mae: 0.0731 - val_loss: 0.0105 - val_mae: 0.0776\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0092 - mae: 0.0728 - val_loss: 0.0104 - val_mae: 0.0769\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0091 - mae: 0.0723 - val_loss: 0.0103 - val_mae: 0.0763\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0090 - mae: 0.0717 - val_loss: 0.0102 - val_mae: 0.0758\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0089 - mae: 0.0711 - val_loss: 0.0101 - val_mae: 0.0750\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0088 - mae: 0.0704 - val_loss: 0.0100 - val_mae: 0.0745\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0087 - mae: 0.0699 - val_loss: 0.0099 - val_mae: 0.0739\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0086 - mae: 0.0692 - val_loss: 0.0098 - val_mae: 0.0732\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0085 - mae: 0.0686 - val_loss: 0.0097 - val_mae: 0.0724\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0084 - mae: 0.0679 - val_loss: 0.0096 - val_mae: 0.0714\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0083 - mae: 0.0671 - val_loss: 0.0097 - val_mae: 0.0721\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0086 - mae: 0.0692 - val_loss: 0.0098 - val_mae: 0.0736\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0081 - mae: 0.0671 - val_loss: 0.0093 - val_mae: 0.0710\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0079 - mae: 0.0664 - val_loss: 0.0093 - val_mae: 0.0715\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0079 - mae: 0.0667 - val_loss: 0.0093 - val_mae: 0.0713\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0079 - mae: 0.0666 - val_loss: 0.0092 - val_mae: 0.0712\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0079 - mae: 0.0666 - val_loss: 0.0092 - val_mae: 0.0712\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0079 - mae: 0.0666 - val_loss: 0.0092 - val_mae: 0.0711\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0078 - mae: 0.0666 - val_loss: 0.0092 - val_mae: 0.0711\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0078 - mae: 0.0666 - val_loss: 0.0092 - val_mae: 0.0712\n",
      "\n",
      "âœ… Model and scaler saved for site 3001.\n",
      "3002\n",
      "Epoch 1/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.2447 - mae: 0.4070 - val_loss: 0.0696 - val_mae: 0.2048\n",
      "Epoch 2/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0582 - mae: 0.1989 - val_loss: 0.0288 - val_mae: 0.1445\n",
      "Epoch 3/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0293 - mae: 0.1395 - val_loss: 0.0160 - val_mae: 0.0872\n",
      "Epoch 4/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0167 - mae: 0.0901 - val_loss: 0.0144 - val_mae: 0.0990\n",
      "Epoch 5/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0166 - mae: 0.1027 - val_loss: 0.0135 - val_mae: 0.0932\n",
      "Epoch 6/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0138 - mae: 0.0901 - val_loss: 0.0106 - val_mae: 0.0787\n",
      "Epoch 7/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0108 - mae: 0.0786 - val_loss: 0.0093 - val_mae: 0.0758\n",
      "Epoch 8/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0092 - mae: 0.0734 - val_loss: 0.0078 - val_mae: 0.0700\n",
      "Epoch 9/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0074 - mae: 0.0658 - val_loss: 0.0135 - val_mae: 0.0987\n",
      "Epoch 10/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0155 - mae: 0.1032 - val_loss: 0.0151 - val_mae: 0.1038\n",
      "Epoch 11/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0152 - mae: 0.1018 - val_loss: 0.0101 - val_mae: 0.0820\n",
      "Epoch 12/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0100 - mae: 0.0795 - val_loss: 0.0067 - val_mae: 0.0578\n",
      "Epoch 13/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0072 - mae: 0.0648 - val_loss: 0.0060 - val_mae: 0.0608\n",
      "Epoch 14/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0060 - mae: 0.0591 - val_loss: 0.0054 - val_mae: 0.0572\n",
      "Epoch 15/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0068 - mae: 0.0618 - val_loss: 0.0094 - val_mae: 0.0786\n",
      "Epoch 16/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0105 - mae: 0.0824 - val_loss: 0.0080 - val_mae: 0.0689\n",
      "Epoch 17/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0084 - mae: 0.0700 - val_loss: 0.0063 - val_mae: 0.0598\n",
      "Epoch 18/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0065 - mae: 0.0610 - val_loss: 0.0050 - val_mae: 0.0526\n",
      "Epoch 19/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0050 - mae: 0.0533 - val_loss: 0.0043 - val_mae: 0.0482\n",
      "Epoch 20/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0043 - mae: 0.0496 - val_loss: 0.0037 - val_mae: 0.0446\n",
      "Epoch 21/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0036 - mae: 0.0442 - val_loss: 0.0033 - val_mae: 0.0410\n",
      "Epoch 22/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0046 - mae: 0.0513 - val_loss: 0.0052 - val_mae: 0.0544\n",
      "Epoch 23/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0050 - mae: 0.0551 - val_loss: 0.0043 - val_mae: 0.0491\n",
      "Epoch 24/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0038 - mae: 0.0468 - val_loss: 0.0036 - val_mae: 0.0425\n",
      "Epoch 25/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0434 - val_loss: 0.0026 - val_mae: 0.0365\n",
      "Epoch 26/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 0.0047 - val_mae: 0.0483\n",
      "Epoch 27/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0046 - mae: 0.0525 - val_loss: 0.0027 - val_mae: 0.0374\n",
      "Epoch 28/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0029 - mae: 0.0401 - val_loss: 0.0030 - val_mae: 0.0406\n",
      "Epoch 29/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0022 - val_mae: 0.0335\n",
      "Epoch 30/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0335 - val_loss: 0.0047 - val_mae: 0.0490\n",
      "Epoch 31/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0051 - mae: 0.0568 - val_loss: 0.0043 - val_mae: 0.0496\n",
      "Epoch 32/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - mae: 0.0482 - val_loss: 0.0023 - val_mae: 0.0349\n",
      "Epoch 33/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0357 - val_loss: 0.0019 - val_mae: 0.0313\n",
      "Epoch 34/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0309 - val_loss: 0.0025 - val_mae: 0.0379\n",
      "Epoch 35/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0019 - mae: 0.0334 - val_loss: 0.0020 - val_mae: 0.0326\n",
      "Epoch 36/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0018 - mae: 0.0312 - val_loss: 0.0026 - val_mae: 0.0387\n",
      "Epoch 37/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0334 - val_loss: 0.0020 - val_mae: 0.0315\n",
      "Epoch 38/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0306 - val_loss: 0.0024 - val_mae: 0.0360\n",
      "Epoch 39/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0019 - mae: 0.0324 - val_loss: 0.0019 - val_mae: 0.0313\n",
      "Epoch 40/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0017 - mae: 0.0303 - val_loss: 0.0024 - val_mae: 0.0361\n",
      "\n",
      "âœ… Model and scaler saved for site 3002.\n",
      "3120\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.1991 - mae: 0.3667 - val_loss: 0.0375 - val_mae: 0.1580\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0302 - mae: 0.1399 - val_loss: 0.0189 - val_mae: 0.1089\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0181 - mae: 0.1051 - val_loss: 0.0122 - val_mae: 0.0834\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0125 - mae: 0.0859 - val_loss: 0.0110 - val_mae: 0.0841\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0109 - mae: 0.0835 - val_loss: 0.0073 - val_mae: 0.0661\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0643 - val_loss: 0.0043 - val_mae: 0.0502\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0806 - val_loss: 0.0114 - val_mae: 0.0864\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0108 - mae: 0.0835 - val_loss: 0.0065 - val_mae: 0.0631\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0628 - val_loss: 0.0047 - val_mae: 0.0524\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0047 - mae: 0.0532 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0029 - val_mae: 0.0430\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0027 - val_mae: 0.0396\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0403 - val_loss: 0.0026 - val_mae: 0.0390\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0393 - val_loss: 0.0024 - val_mae: 0.0369\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0380 - val_loss: 0.0024 - val_mae: 0.0373\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0024 - mae: 0.0377 - val_loss: 0.0025 - val_mae: 0.0383\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0024 - mae: 0.0379 - val_loss: 0.0022 - val_mae: 0.0353\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.0022 - val_mae: 0.0357\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0022 - mae: 0.0361 - val_loss: 0.0021 - val_mae: 0.0362\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0360 - val_loss: 0.0022 - val_mae: 0.0374\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0361 - val_loss: 0.0019 - val_mae: 0.0341\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0349 - val_loss: 0.0020 - val_mae: 0.0350\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0347 - val_loss: 0.0020 - val_mae: 0.0355\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0347 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0340 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0019 - mae: 0.0339 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0337 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0019 - mae: 0.0334 - val_loss: 0.0018 - val_mae: 0.0342\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0333 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0019 - mae: 0.0331 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0018 - mae: 0.0329 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0328 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0327 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0018 - mae: 0.0326 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0018 - mae: 0.0325 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0018 - mae: 0.0324 - val_loss: 0.0017 - val_mae: 0.0332\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0323 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0321 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0018 - mae: 0.0321 - val_loss: 0.0017 - val_mae: 0.0328\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0319 - val_loss: 0.0017 - val_mae: 0.0327\n",
      "\n",
      "âœ… Model and scaler saved for site 3120.\n",
      "3122\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.2399 - mae: 0.3827 - val_loss: 0.0344 - val_mae: 0.1551\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0337 - mae: 0.1508 - val_loss: 0.0213 - val_mae: 0.1172\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0213 - mae: 0.1146 - val_loss: 0.0141 - val_mae: 0.0933\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0152 - mae: 0.0973 - val_loss: 0.0137 - val_mae: 0.0954\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0142 - mae: 0.0957 - val_loss: 0.0099 - val_mae: 0.0769\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0107 - mae: 0.0801 - val_loss: 0.0121 - val_mae: 0.0914\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0122 - mae: 0.0908 - val_loss: 0.0087 - val_mae: 0.0740\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0086 - mae: 0.0714 - val_loss: 0.0059 - val_mae: 0.0599\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0618 - val_loss: 0.0052 - val_mae: 0.0569\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0052 - mae: 0.0574 - val_loss: 0.0041 - val_mae: 0.0502\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0044 - mae: 0.0531 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0032 - val_mae: 0.0441\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0034 - mae: 0.0464 - val_loss: 0.0031 - val_mae: 0.0425\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0033 - mae: 0.0450 - val_loss: 0.0027 - val_mae: 0.0402\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0423 - val_loss: 0.0026 - val_mae: 0.0387\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0029 - mae: 0.0417 - val_loss: 0.0024 - val_mae: 0.0374\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0027 - mae: 0.0402 - val_loss: 0.0022 - val_mae: 0.0362\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0022 - val_mae: 0.0354\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0021 - val_mae: 0.0343\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0379 - val_loss: 0.0020 - val_mae: 0.0339\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0378 - val_loss: 0.0021 - val_mae: 0.0349\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0022 - val_mae: 0.0365\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0025 - mae: 0.0386 - val_loss: 0.0022 - val_mae: 0.0349\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 0.0019 - val_mae: 0.0321\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0022 - mae: 0.0353 - val_loss: 0.0021 - val_mae: 0.0363\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0022 - mae: 0.0356 - val_loss: 0.0019 - val_mae: 0.0325\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0352 - val_loss: 0.0018 - val_mae: 0.0315\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0337 - val_loss: 0.0016 - val_mae: 0.0302\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0019 - mae: 0.0323 - val_loss: 0.0017 - val_mae: 0.0310\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0018 - mae: 0.0321 - val_loss: 0.0015 - val_mae: 0.0293\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0018 - mae: 0.0313 - val_loss: 0.0015 - val_mae: 0.0282\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0304 - val_loss: 0.0015 - val_mae: 0.0286\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0305 - val_loss: 0.0015 - val_mae: 0.0289\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0017 - mae: 0.0301 - val_loss: 0.0015 - val_mae: 0.0294\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0299 - val_loss: 0.0015 - val_mae: 0.0290\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0015 - val_mae: 0.0284\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0014 - val_mae: 0.0272\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0014 - val_mae: 0.0278\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0014 - val_mae: 0.0271\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0013 - val_mae: 0.0268\n",
      "\n",
      "âœ… Model and scaler saved for site 3122.\n",
      "3126\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1165 - mae: 0.2709 - val_loss: 0.0268 - val_mae: 0.1339\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0271 - mae: 0.1331 - val_loss: 0.0200 - val_mae: 0.1115\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0197 - mae: 0.1090 - val_loss: 0.0135 - val_mae: 0.0874\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0144 - mae: 0.0928 - val_loss: 0.0111 - val_mae: 0.0821\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0119 - mae: 0.0858 - val_loss: 0.0083 - val_mae: 0.0702\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0091 - mae: 0.0726 - val_loss: 0.0063 - val_mae: 0.0581\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0072 - mae: 0.0633 - val_loss: 0.0095 - val_mae: 0.0784\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0092 - mae: 0.0744 - val_loss: 0.0058 - val_mae: 0.0551\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0064 - mae: 0.0590 - val_loss: 0.0043 - val_mae: 0.0484\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0047 - mae: 0.0513 - val_loss: 0.0031 - val_mae: 0.0432\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0037 - mae: 0.0459 - val_loss: 0.0025 - val_mae: 0.0389\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0035 - mae: 0.0439 - val_loss: 0.0025 - val_mae: 0.0380\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0031 - mae: 0.0412 - val_loss: 0.0024 - val_mae: 0.0391\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0022 - val_mae: 0.0353\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0388 - val_loss: 0.0021 - val_mae: 0.0344\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0381 - val_loss: 0.0020 - val_mae: 0.0335\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0025 - mae: 0.0365 - val_loss: 0.0019 - val_mae: 0.0324\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0024 - mae: 0.0354 - val_loss: 0.0019 - val_mae: 0.0322\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0031 - mae: 0.0402 - val_loss: 0.0034 - val_mae: 0.0425\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0040 - mae: 0.0472 - val_loss: 0.0027 - val_mae: 0.0409\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0032 - mae: 0.0430 - val_loss: 0.0023 - val_mae: 0.0372\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0028 - mae: 0.0391 - val_loss: 0.0020 - val_mae: 0.0336\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0025 - mae: 0.0358 - val_loss: 0.0018 - val_mae: 0.0317\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0353 - val_loss: 0.0019 - val_mae: 0.0332\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0353 - val_loss: 0.0018 - val_mae: 0.0327\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0346 - val_loss: 0.0018 - val_mae: 0.0319\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0342 - val_loss: 0.0018 - val_mae: 0.0313\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0340 - val_loss: 0.0018 - val_mae: 0.0313\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0340 - val_loss: 0.0018 - val_mae: 0.0313\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0339 - val_loss: 0.0017 - val_mae: 0.0310\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0022 - mae: 0.0338 - val_loss: 0.0017 - val_mae: 0.0308\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0338 - val_loss: 0.0017 - val_mae: 0.0310\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0337 - val_loss: 0.0017 - val_mae: 0.0307\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0335 - val_loss: 0.0017 - val_mae: 0.0307\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0334 - val_loss: 0.0017 - val_mae: 0.0306\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0334 - val_loss: 0.0017 - val_mae: 0.0306\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0334 - val_loss: 0.0017 - val_mae: 0.0305\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0021 - mae: 0.0333 - val_loss: 0.0017 - val_mae: 0.0304\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0021 - mae: 0.0332 - val_loss: 0.0017 - val_mae: 0.0304\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0021 - mae: 0.0332 - val_loss: 0.0017 - val_mae: 0.0304\n",
      "\n",
      "âœ… Model and scaler saved for site 3126.\n",
      "3127\n",
      "Epoch 1/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.2515 - mae: 0.4067 - val_loss: 0.0555 - val_mae: 0.2025\n",
      "Epoch 2/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0523 - mae: 0.1924 - val_loss: 0.0229 - val_mae: 0.1206\n",
      "Epoch 3/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0240 - mae: 0.1126 - val_loss: 0.0144 - val_mae: 0.0902\n",
      "Epoch 4/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0162 - mae: 0.0933 - val_loss: 0.0104 - val_mae: 0.0793\n",
      "Epoch 5/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0137 - mae: 0.0881 - val_loss: 0.0196 - val_mae: 0.1097\n",
      "Epoch 6/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0225 - mae: 0.1167 - val_loss: 0.0136 - val_mae: 0.0905\n",
      "Epoch 7/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0157 - mae: 0.0926 - val_loss: 0.0107 - val_mae: 0.0763\n",
      "Epoch 8/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0128 - mae: 0.0821 - val_loss: 0.0093 - val_mae: 0.0707\n",
      "Epoch 9/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0788 - val_loss: 0.0085 - val_mae: 0.0691\n",
      "Epoch 10/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0103 - mae: 0.0763 - val_loss: 0.0079 - val_mae: 0.0669\n",
      "Epoch 11/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0094 - mae: 0.0724 - val_loss: 0.0072 - val_mae: 0.0634\n",
      "Epoch 12/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0084 - mae: 0.0675 - val_loss: 0.0063 - val_mae: 0.0586\n",
      "Epoch 13/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0073 - mae: 0.0620 - val_loss: 0.0054 - val_mae: 0.0551\n",
      "Epoch 14/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0062 - mae: 0.0581 - val_loss: 0.0067 - val_mae: 0.0678\n",
      "Epoch 15/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0570 - val_loss: 0.0044 - val_mae: 0.0531\n",
      "Epoch 16/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0048 - mae: 0.0522 - val_loss: 0.0037 - val_mae: 0.0488\n",
      "Epoch 17/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0045 - mae: 0.0515 - val_loss: 0.0041 - val_mae: 0.0437\n",
      "Epoch 18/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0045 - mae: 0.0484 - val_loss: 0.0045 - val_mae: 0.0537\n",
      "Epoch 19/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0045 - mae: 0.0501 - val_loss: 0.0039 - val_mae: 0.0513\n",
      "Epoch 20/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0440 - val_loss: 0.0029 - val_mae: 0.0406\n",
      "Epoch 21/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0030 - mae: 0.0393 - val_loss: 0.0037 - val_mae: 0.0514\n",
      "Epoch 22/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0436 - val_loss: 0.0031 - val_mae: 0.0452\n",
      "Epoch 23/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0398 - val_loss: 0.0027 - val_mae: 0.0415\n",
      "Epoch 24/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0384 - val_loss: 0.0020 - val_mae: 0.0319\n",
      "Epoch 25/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0027 - val_mae: 0.0401\n",
      "Epoch 26/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0029 - mae: 0.0395 - val_loss: 0.0024 - val_mae: 0.0392\n",
      "Epoch 27/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0397 - val_loss: 0.0025 - val_mae: 0.0354\n",
      "Epoch 28/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0368 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "Epoch 29/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0032 - val_mae: 0.0473\n",
      "Epoch 30/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0394 - val_loss: 0.0022 - val_mae: 0.0365\n",
      "Epoch 31/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0027 - val_mae: 0.0424\n",
      "Epoch 32/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0387 - val_loss: 0.0020 - val_mae: 0.0343\n",
      "Epoch 33/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0349 - val_loss: 0.0020 - val_mae: 0.0318\n",
      "Epoch 34/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0024 - mae: 0.0343 - val_loss: 0.0020 - val_mae: 0.0349\n",
      "Epoch 35/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0351 - val_loss: 0.0021 - val_mae: 0.0352\n",
      "Epoch 36/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0351 - val_loss: 0.0023 - val_mae: 0.0384\n",
      "Epoch 37/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0377 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "Epoch 38/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.0020 - val_mae: 0.0332\n",
      "Epoch 39/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0351 - val_loss: 0.0022 - val_mae: 0.0373\n",
      "Epoch 40/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0023 - mae: 0.0360 - val_loss: 0.0020 - val_mae: 0.0331\n",
      "\n",
      "âœ… Model and scaler saved for site 3127.\n",
      "3180\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.1288 - mae: 0.2802 - val_loss: 0.0322 - val_mae: 0.1479\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0266 - mae: 0.1291 - val_loss: 0.0167 - val_mae: 0.0916\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0156 - mae: 0.0872 - val_loss: 0.0114 - val_mae: 0.0772\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0114 - mae: 0.0787 - val_loss: 0.0102 - val_mae: 0.0764\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0100 - mae: 0.0742 - val_loss: 0.0082 - val_mae: 0.0655\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0088 - mae: 0.0694 - val_loss: 0.0079 - val_mae: 0.0663\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0079 - mae: 0.0659 - val_loss: 0.0063 - val_mae: 0.0594\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0603 - val_loss: 0.0107 - val_mae: 0.0849\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0123 - mae: 0.0865 - val_loss: 0.0098 - val_mae: 0.0722\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0093 - mae: 0.0679 - val_loss: 0.0074 - val_mae: 0.0589\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0074 - mae: 0.0597 - val_loss: 0.0065 - val_mae: 0.0558\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0065 - mae: 0.0564 - val_loss: 0.0057 - val_mae: 0.0521\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0521 - val_loss: 0.0049 - val_mae: 0.0478\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0049 - mae: 0.0483 - val_loss: 0.0041 - val_mae: 0.0443\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0041 - mae: 0.0470 - val_loss: 0.0038 - val_mae: 0.0452\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0041 - mae: 0.0465 - val_loss: 0.0035 - val_mae: 0.0434\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0033 - mae: 0.0423 - val_loss: 0.0033 - val_mae: 0.0411\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0034 - mae: 0.0424 - val_loss: 0.0035 - val_mae: 0.0456\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0035 - mae: 0.0458 - val_loss: 0.0030 - val_mae: 0.0388\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0029 - val_mae: 0.0388\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0388 - val_loss: 0.0028 - val_mae: 0.0373\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0030 - mae: 0.0410 - val_loss: 0.0029 - val_mae: 0.0394\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0026 - val_mae: 0.0359\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0395 - val_loss: 0.0027 - val_mae: 0.0365\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0027 - mae: 0.0373 - val_loss: 0.0027 - val_mae: 0.0365\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0387 - val_loss: 0.0027 - val_mae: 0.0375\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0372 - val_loss: 0.0026 - val_mae: 0.0356\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0388 - val_loss: 0.0028 - val_mae: 0.0384\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0027 - mae: 0.0376 - val_loss: 0.0026 - val_mae: 0.0355\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0370 - val_loss: 0.0028 - val_mae: 0.0386\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0377 - val_loss: 0.0025 - val_mae: 0.0353\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0373 - val_loss: 0.0027 - val_mae: 0.0384\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0027 - mae: 0.0378 - val_loss: 0.0026 - val_mae: 0.0361\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0362 - val_loss: 0.0025 - val_mae: 0.0352\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0371 - val_loss: 0.0025 - val_mae: 0.0351\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0357 - val_loss: 0.0025 - val_mae: 0.0350\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0362 - val_loss: 0.0025 - val_mae: 0.0346\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0025 - mae: 0.0357 - val_loss: 0.0025 - val_mae: 0.0359\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0026 - mae: 0.0365 - val_loss: 0.0025 - val_mae: 0.0347\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0026 - mae: 0.0364 - val_loss: 0.0028 - val_mae: 0.0379\n",
      "\n",
      "âœ… Model and scaler saved for site 3180.\n",
      "3662\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.2272 - mae: 0.3940 - val_loss: 0.0474 - val_mae: 0.1864\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0486 - mae: 0.1808 - val_loss: 0.0299 - val_mae: 0.1389\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0257 - mae: 0.1254 - val_loss: 0.0173 - val_mae: 0.0925\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0161 - mae: 0.0937 - val_loss: 0.0135 - val_mae: 0.0900\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0149 - mae: 0.0931 - val_loss: 0.0342 - val_mae: 0.1461\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0346 - mae: 0.1505 - val_loss: 0.0263 - val_mae: 0.1337\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0240 - mae: 0.1282 - val_loss: 0.0203 - val_mae: 0.1163\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0189 - mae: 0.1111 - val_loss: 0.0165 - val_mae: 0.1006\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0155 - mae: 0.0964 - val_loss: 0.0135 - val_mae: 0.0843\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0128 - mae: 0.0828 - val_loss: 0.0109 - val_mae: 0.0735\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0101 - mae: 0.0715 - val_loss: 0.0085 - val_mae: 0.0664\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0080 - mae: 0.0647 - val_loss: 0.0103 - val_mae: 0.0810\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0102 - mae: 0.0796 - val_loss: 0.0096 - val_mae: 0.0744\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0088 - mae: 0.0717 - val_loss: 0.0073 - val_mae: 0.0625\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0067 - mae: 0.0614 - val_loss: 0.0061 - val_mae: 0.0566\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0057 - mae: 0.0558 - val_loss: 0.0052 - val_mae: 0.0524\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0050 - mae: 0.0523 - val_loss: 0.0047 - val_mae: 0.0492\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0046 - mae: 0.0504 - val_loss: 0.0043 - val_mae: 0.0475\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0042 - mae: 0.0484 - val_loss: 0.0040 - val_mae: 0.0459\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0039 - mae: 0.0469 - val_loss: 0.0037 - val_mae: 0.0447\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0037 - mae: 0.0457 - val_loss: 0.0035 - val_mae: 0.0436\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0035 - mae: 0.0447 - val_loss: 0.0034 - val_mae: 0.0428\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0034 - mae: 0.0441 - val_loss: 0.0033 - val_mae: 0.0420\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0033 - mae: 0.0433 - val_loss: 0.0032 - val_mae: 0.0414\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0032 - mae: 0.0426 - val_loss: 0.0031 - val_mae: 0.0407\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0032 - mae: 0.0421 - val_loss: 0.0031 - val_mae: 0.0402\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0031 - mae: 0.0417 - val_loss: 0.0030 - val_mae: 0.0398\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0030 - mae: 0.0411 - val_loss: 0.0029 - val_mae: 0.0392\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0403 - val_loss: 0.0028 - val_mae: 0.0385\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0394 - val_loss: 0.0026 - val_mae: 0.0374\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0382 - val_loss: 0.0025 - val_mae: 0.0361\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0025 - mae: 0.0373 - val_loss: 0.0025 - val_mae: 0.0361\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0025 - val_mae: 0.0357\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0027 - mae: 0.0386 - val_loss: 0.0025 - val_mae: 0.0358\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0366 - val_loss: 0.0024 - val_mae: 0.0348\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0362 - val_loss: 0.0024 - val_mae: 0.0347\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0023 - mae: 0.0362 - val_loss: 0.0023 - val_mae: 0.0345\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0355 - val_loss: 0.0023 - val_mae: 0.0347\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0038 - mae: 0.0453 - val_loss: 0.0051 - val_mae: 0.0507\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0042 - mae: 0.0471 - val_loss: 0.0026 - val_mae: 0.0367\n",
      "\n",
      "âœ… Model and scaler saved for site 3662.\n",
      "3682\n",
      "Epoch 1/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0978 - mae: 0.2353 - val_loss: 0.0251 - val_mae: 0.1296\n",
      "Epoch 2/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0278 - mae: 0.1308 - val_loss: 0.0177 - val_mae: 0.1089\n",
      "Epoch 3/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0193 - mae: 0.1102 - val_loss: 0.0118 - val_mae: 0.0857\n",
      "Epoch 4/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0133 - mae: 0.0922 - val_loss: 0.0094 - val_mae: 0.0783\n",
      "Epoch 5/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0104 - mae: 0.0817 - val_loss: 0.0070 - val_mae: 0.0654\n",
      "Epoch 6/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0128 - mae: 0.0695 - val_loss: 0.0088 - val_mae: 0.0751\n",
      "Epoch 7/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0114 - mae: 0.0839 - val_loss: 0.0099 - val_mae: 0.0812\n",
      "Epoch 8/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0116 - mae: 0.0858 - val_loss: 0.0084 - val_mae: 0.0728\n",
      "Epoch 9/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0096 - mae: 0.0756 - val_loss: 0.0059 - val_mae: 0.0590\n",
      "Epoch 10/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 8.0514 - mae: 0.2508 - val_loss: 0.0276 - val_mae: 0.1245\n",
      "Epoch 11/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0279 - mae: 0.1222 - val_loss: 0.0217 - val_mae: 0.1103\n",
      "Epoch 12/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0219 - mae: 0.1105 - val_loss: 0.0165 - val_mae: 0.1003\n",
      "Epoch 13/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0176 - mae: 0.1030 - val_loss: 0.0137 - val_mae: 0.0949\n",
      "Epoch 14/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0154 - mae: 0.0995 - val_loss: 0.0125 - val_mae: 0.0926\n",
      "Epoch 15/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0144 - mae: 0.0981 - val_loss: 0.0120 - val_mae: 0.0913\n",
      "Epoch 16/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0140 - mae: 0.0971 - val_loss: 0.0117 - val_mae: 0.0902\n",
      "Epoch 17/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0137 - mae: 0.0961 - val_loss: 0.0115 - val_mae: 0.0892\n",
      "Epoch 18/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0135 - mae: 0.0952 - val_loss: 0.0113 - val_mae: 0.0882\n",
      "Epoch 19/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0133 - mae: 0.0943 - val_loss: 0.0111 - val_mae: 0.0873\n",
      "Epoch 20/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0131 - mae: 0.0934 - val_loss: 0.0109 - val_mae: 0.0864\n",
      "Epoch 21/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0129 - mae: 0.0925 - val_loss: 0.0107 - val_mae: 0.0855\n",
      "Epoch 22/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0127 - mae: 0.0917 - val_loss: 0.0106 - val_mae: 0.0847\n",
      "Epoch 23/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0126 - mae: 0.0909 - val_loss: 0.0104 - val_mae: 0.0838\n",
      "Epoch 24/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0124 - mae: 0.0901 - val_loss: 0.0103 - val_mae: 0.0830\n",
      "Epoch 25/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0123 - mae: 0.0893 - val_loss: 0.0102 - val_mae: 0.0822\n",
      "Epoch 26/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0121 - mae: 0.0885 - val_loss: 0.0100 - val_mae: 0.0814\n",
      "Epoch 27/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0120 - mae: 0.0877 - val_loss: 0.0099 - val_mae: 0.0806\n",
      "Epoch 28/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0119 - mae: 0.0870 - val_loss: 0.0098 - val_mae: 0.0798\n",
      "Epoch 29/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0117 - mae: 0.0862 - val_loss: 0.0096 - val_mae: 0.0790\n",
      "Epoch 30/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0116 - mae: 0.0855 - val_loss: 0.0095 - val_mae: 0.0783\n",
      "Epoch 31/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0115 - mae: 0.0848 - val_loss: 0.0094 - val_mae: 0.0776\n",
      "Epoch 32/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0113 - mae: 0.0841 - val_loss: 0.0093 - val_mae: 0.0769\n",
      "Epoch 33/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0112 - mae: 0.0834 - val_loss: 0.0092 - val_mae: 0.0762\n",
      "Epoch 34/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0111 - mae: 0.0827 - val_loss: 0.0091 - val_mae: 0.0756\n",
      "Epoch 35/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0110 - mae: 0.0821 - val_loss: 0.0090 - val_mae: 0.0749\n",
      "Epoch 36/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0109 - mae: 0.0814 - val_loss: 0.0089 - val_mae: 0.0743\n",
      "Epoch 37/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0108 - mae: 0.0808 - val_loss: 0.0088 - val_mae: 0.0737\n",
      "Epoch 38/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0107 - mae: 0.0802 - val_loss: 0.0087 - val_mae: 0.0731\n",
      "Epoch 39/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0106 - mae: 0.0796 - val_loss: 0.0086 - val_mae: 0.0725\n",
      "Epoch 40/40\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0105 - mae: 0.0790 - val_loss: 0.0085 - val_mae: 0.0719\n",
      "\n",
      "âœ… Model and scaler saved for site 3682.\n",
      "3685\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.2497 - mae: 0.4022 - val_loss: 0.0140 - val_mae: 0.0998\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0487 - mae: 0.1819 - val_loss: 0.0109 - val_mae: 0.0880\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0244 - mae: 0.1248 - val_loss: 0.0105 - val_mae: 0.0917\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0157 - mae: 0.0974 - val_loss: 0.0094 - val_mae: 0.0858\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0130 - mae: 0.0872 - val_loss: 0.0103 - val_mae: 0.0911\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0121 - mae: 0.0875 - val_loss: 0.0061 - val_mae: 0.0680\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0103 - mae: 0.0775 - val_loss: 0.0067 - val_mae: 0.0725\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0085 - mae: 0.0716 - val_loss: 0.0055 - val_mae: 0.0644\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0079 - mae: 0.0689 - val_loss: 0.0068 - val_mae: 0.0749\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0063 - mae: 0.0614 - val_loss: 0.0044 - val_mae: 0.0564\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0091 - mae: 0.0771 - val_loss: 0.0028 - val_mae: 0.0423\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0057 - mae: 0.0550 - val_loss: 0.0043 - val_mae: 0.0578\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0274 - mae: 0.0643 - val_loss: 0.0050 - val_mae: 0.0592\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0453 - mae: 0.1652 - val_loss: 0.0084 - val_mae: 0.0809\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0520 - mae: 0.1827 - val_loss: 0.0090 - val_mae: 0.0813\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0412 - mae: 0.1676 - val_loss: 0.0112 - val_mae: 0.0881\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0343 - mae: 0.1584 - val_loss: 0.0132 - val_mae: 0.0971\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0303 - mae: 0.1520 - val_loss: 0.0138 - val_mae: 0.1009\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0273 - mae: 0.1453 - val_loss: 0.0125 - val_mae: 0.0973\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0244 - mae: 0.1364 - val_loss: 0.0095 - val_mae: 0.0857\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0209 - mae: 0.1229 - val_loss: 0.0048 - val_mae: 0.0562\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 426.5892 - mae: 0.8815 - val_loss: 0.0045 - val_mae: 0.0563\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0422 - mae: 0.1601 - val_loss: 0.0049 - val_mae: 0.0592\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 60837.6875 - mae: 6.4739 - val_loss: 0.0086 - val_mae: 0.0819\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 261609248.0000 - mae: 1186.5596 - val_loss: 0.0135 - val_mae: 0.0983\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0580 - mae: 0.2021 - val_loss: 0.0159 - val_mae: 0.1038\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0510 - mae: 0.1927 - val_loss: 0.0169 - val_mae: 0.1062\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0442 - mae: 0.1821 - val_loss: 0.0177 - val_mae: 0.1097\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0397 - mae: 0.1743 - val_loss: 0.0185 - val_mae: 0.1134\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0364 - mae: 0.1685 - val_loss: 0.0192 - val_mae: 0.1169\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0341 - mae: 0.1637 - val_loss: 0.0199 - val_mae: 0.1202\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0323 - mae: 0.1599 - val_loss: 0.0204 - val_mae: 0.1232\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0310 - mae: 0.1567 - val_loss: 0.0210 - val_mae: 0.1259\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0299 - mae: 0.1539 - val_loss: 0.0215 - val_mae: 0.1283\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0290 - mae: 0.1516 - val_loss: 0.0219 - val_mae: 0.1304\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0284 - mae: 0.1496 - val_loss: 0.0222 - val_mae: 0.1322\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0278 - mae: 0.1478 - val_loss: 0.0225 - val_mae: 0.1337\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0273 - mae: 0.1462 - val_loss: 0.0228 - val_mae: 0.1350\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0269 - mae: 0.1449 - val_loss: 0.0230 - val_mae: 0.1360\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0266 - mae: 0.1436 - val_loss: 0.0232 - val_mae: 0.1369\n",
      "\n",
      "âœ… Model and scaler saved for site 3685.\n",
      "3804\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.1871 - mae: 0.3412 - val_loss: 0.0494 - val_mae: 0.1842\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0401 - mae: 0.1653 - val_loss: 0.0248 - val_mae: 0.1258\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0222 - mae: 0.1132 - val_loss: 0.0147 - val_mae: 0.0897\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0143 - mae: 0.0905 - val_loss: 0.0125 - val_mae: 0.0839\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0118 - mae: 0.0810 - val_loss: 0.0148 - val_mae: 0.1005\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0149 - mae: 0.0975 - val_loss: 0.0116 - val_mae: 0.0799\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0110 - mae: 0.0766 - val_loss: 0.0089 - val_mae: 0.0685\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0084 - mae: 0.0663 - val_loss: 0.0072 - val_mae: 0.0604\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0067 - mae: 0.0609 - val_loss: 0.0064 - val_mae: 0.0608\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0060 - mae: 0.0597 - val_loss: 0.0049 - val_mae: 0.0525\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0044 - mae: 0.0513 - val_loss: 0.0046 - val_mae: 0.0538\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0038 - val_mae: 0.0483\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0038 - mae: 0.0464 - val_loss: 0.0166 - val_mae: 0.1077\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0204 - mae: 0.1175 - val_loss: 0.0158 - val_mae: 0.1037\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0141 - mae: 0.0960 - val_loss: 0.0097 - val_mae: 0.0696\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0095 - mae: 0.0697 - val_loss: 0.0076 - val_mae: 0.0611\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0072 - mae: 0.0624 - val_loss: 0.0052 - val_mae: 0.0524\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0086 - mae: 0.0647 - val_loss: 0.0127 - val_mae: 0.0868\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0123 - mae: 0.0867 - val_loss: 0.0091 - val_mae: 0.0746\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0084 - mae: 0.0715 - val_loss: 0.0063 - val_mae: 0.0614\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0062 - mae: 0.0600 - val_loss: 0.0054 - val_mae: 0.0540\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0055 - mae: 0.0546 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0051 - mae: 0.0527 - val_loss: 0.0048 - val_mae: 0.0512\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0048 - mae: 0.0514 - val_loss: 0.0046 - val_mae: 0.0501\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0046 - mae: 0.0502 - val_loss: 0.0044 - val_mae: 0.0491\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0044 - mae: 0.0490 - val_loss: 0.0041 - val_mae: 0.0480\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0042 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0468\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0039 - mae: 0.0465 - val_loss: 0.0037 - val_mae: 0.0453\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0037 - mae: 0.0449 - val_loss: 0.0034 - val_mae: 0.0434\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0033 - mae: 0.0428 - val_loss: 0.0030 - val_mae: 0.0406\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 152439734272.0000 - mae: 6363.3184 - val_loss: 0.0282 - val_mae: 0.1514\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0470 - mae: 0.1978 - val_loss: 0.0682 - val_mae: 0.2452\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0636 - mae: 0.2352 - val_loss: 0.0451 - val_mae: 0.1973\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0409 - mae: 0.1863 - val_loss: 0.0294 - val_mae: 0.1556\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0269 - mae: 0.1476 - val_loss: 0.0204 - val_mae: 0.1253\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0188 - mae: 0.1194 - val_loss: 0.0151 - val_mae: 0.1029\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0140 - mae: 0.0987 - val_loss: 0.0118 - val_mae: 0.0863\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0109 - mae: 0.0823 - val_loss: 0.0075 - val_mae: 0.0577\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0073 - mae: 0.0591 - val_loss: 0.0069 - val_mae: 0.0548\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0068 - mae: 0.0563 - val_loss: 0.0066 - val_mae: 0.0539\n",
      "\n",
      "âœ… Model and scaler saved for site 3804.\n",
      "3812\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.1001 - mae: 0.2442 - val_loss: 0.0299 - val_mae: 0.1485\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0272 - mae: 0.1352 - val_loss: 0.0204 - val_mae: 0.1185\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0199 - mae: 0.1124 - val_loss: 0.0162 - val_mae: 0.1013\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0163 - mae: 0.0966 - val_loss: 0.0141 - val_mae: 0.0905\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0143 - mae: 0.0890 - val_loss: 0.0125 - val_mae: 0.0868\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0125 - mae: 0.0832 - val_loss: 0.0125 - val_mae: 0.0911\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0120 - mae: 0.0807 - val_loss: 0.0108 - val_mae: 0.0808\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0106 - mae: 0.0759 - val_loss: 0.0097 - val_mae: 0.0735\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0283 - mae: 0.0738 - val_loss: 0.0156 - val_mae: 0.0980\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0187 - mae: 0.1010 - val_loss: 0.0216 - val_mae: 0.1094\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0204 - mae: 0.1056 - val_loss: 0.0176 - val_mae: 0.1037\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0168 - mae: 0.0987 - val_loss: 0.0152 - val_mae: 0.0974\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0147 - mae: 0.0917 - val_loss: 0.0134 - val_mae: 0.0887\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0132 - mae: 0.0843 - val_loss: 0.0121 - val_mae: 0.0827\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0117 - mae: 0.0781 - val_loss: 0.0102 - val_mae: 0.0715\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0099 - mae: 0.0685 - val_loss: 0.0092 - val_mae: 0.0673\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0093 - mae: 0.0666 - val_loss: 0.0090 - val_mae: 0.0668\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0091 - mae: 0.0654 - val_loss: 0.0089 - val_mae: 0.0668\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0089 - mae: 0.0645 - val_loss: 0.0088 - val_mae: 0.0668\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0088 - mae: 0.0640 - val_loss: 0.0087 - val_mae: 0.0671\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0087 - mae: 0.0638 - val_loss: 0.0087 - val_mae: 0.0669\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0086 - mae: 0.0636 - val_loss: 0.0086 - val_mae: 0.0667\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0085 - mae: 0.0633 - val_loss: 0.0085 - val_mae: 0.0663\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0083 - mae: 0.0628 - val_loss: 0.0083 - val_mae: 0.0650\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0082 - mae: 0.0627 - val_loss: 0.0082 - val_mae: 0.0647\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0081 - mae: 0.0623 - val_loss: 0.0082 - val_mae: 0.0645\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0080 - mae: 0.0621 - val_loss: 0.0082 - val_mae: 0.0647\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0080 - mae: 0.0622 - val_loss: 0.0081 - val_mae: 0.0643\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0079 - mae: 0.0618 - val_loss: 0.0080 - val_mae: 0.0637\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0078 - mae: 0.0614 - val_loss: 0.0079 - val_mae: 0.0634\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0077 - mae: 0.0614 - val_loss: 0.0079 - val_mae: 0.0633\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0077 - mae: 0.0612 - val_loss: 0.0078 - val_mae: 0.0631\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0076 - mae: 0.0611 - val_loss: 0.0078 - val_mae: 0.0624\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0075 - mae: 0.0609 - val_loss: 0.0079 - val_mae: 0.0638\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0076 - mae: 0.0616 - val_loss: 0.0076 - val_mae: 0.0626\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0080 - mae: 0.0637 - val_loss: 0.0080 - val_mae: 0.0634\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0078 - mae: 0.0622 - val_loss: 0.0076 - val_mae: 0.0632\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0073 - mae: 0.0615 - val_loss: 0.0075 - val_mae: 0.0623\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0073 - mae: 0.0605 - val_loss: 0.0075 - val_mae: 0.0625\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0073 - mae: 0.0604 - val_loss: 0.0074 - val_mae: 0.0616\n",
      "\n",
      "âœ… Model and scaler saved for site 3812.\n",
      "4030\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.2147 - mae: 0.3829 - val_loss: 0.0438 - val_mae: 0.1867\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0355 - mae: 0.1685 - val_loss: 0.0274 - val_mae: 0.1492\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0260 - mae: 0.1439 - val_loss: 0.0226 - val_mae: 0.1345\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0220 - mae: 0.1309 - val_loss: 0.0190 - val_mae: 0.1215\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0185 - mae: 0.1177 - val_loss: 0.0143 - val_mae: 0.1011\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0130 - mae: 0.0931 - val_loss: 0.0090 - val_mae: 0.0758\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0089 - mae: 0.0758 - val_loss: 0.0073 - val_mae: 0.0673\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0075 - mae: 0.0695 - val_loss: 0.0061 - val_mae: 0.0623\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0073 - mae: 0.0705 - val_loss: 0.0065 - val_mae: 0.0632\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0064 - mae: 0.0634 - val_loss: 0.0054 - val_mae: 0.0580\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0055 - mae: 0.0588 - val_loss: 0.0051 - val_mae: 0.0564\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0574 - val_loss: 0.0050 - val_mae: 0.0560\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0050 - mae: 0.0560 - val_loss: 0.0048 - val_mae: 0.0545\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0048 - mae: 0.0547 - val_loss: 0.0046 - val_mae: 0.0534\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0046 - mae: 0.0535 - val_loss: 0.0044 - val_mae: 0.0521\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0044 - mae: 0.0521 - val_loss: 0.0042 - val_mae: 0.0508\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mae: 0.0509 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0037 - val_mae: 0.0472\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0036 - val_mae: 0.0466\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0036 - mae: 0.0463 - val_loss: 0.0036 - val_mae: 0.0466\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0034 - mae: 0.0454 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0034 - mae: 0.0450 - val_loss: 0.0035 - val_mae: 0.0461\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0444 - val_loss: 0.0034 - val_mae: 0.0447\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0032 - mae: 0.0433 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0031 - mae: 0.0428 - val_loss: 0.0033 - val_mae: 0.0448\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0031 - mae: 0.0424 - val_loss: 0.0032 - val_mae: 0.0440\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0420 - val_loss: 0.0032 - val_mae: 0.0437\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0030 - mae: 0.0418 - val_loss: 0.0031 - val_mae: 0.0435\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0030 - mae: 0.0415 - val_loss: 0.0031 - val_mae: 0.0433\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0415 - val_loss: 0.0031 - val_mae: 0.0432\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0412 - val_loss: 0.0031 - val_mae: 0.0431\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0029 - mae: 0.0411 - val_loss: 0.0031 - val_mae: 0.0435\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0410 - val_loss: 0.0031 - val_mae: 0.0435\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0410 - val_loss: 0.0032 - val_mae: 0.0439\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0029 - mae: 0.0411 - val_loss: 0.0032 - val_mae: 0.0442\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0414 - val_loss: 0.0033 - val_mae: 0.0452\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0030 - mae: 0.0417 - val_loss: 0.0035 - val_mae: 0.0472\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0031 - mae: 0.0423 - val_loss: 0.0035 - val_mae: 0.0473\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0422 - val_loss: 0.0034 - val_mae: 0.0462\n",
      "\n",
      "âœ… Model and scaler saved for site 4030.\n",
      "4032\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1318 - mae: 0.2920 - val_loss: 0.0281 - val_mae: 0.1401\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0245 - mae: 0.1284 - val_loss: 0.0153 - val_mae: 0.1006\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0151 - mae: 0.0965 - val_loss: 0.0098 - val_mae: 0.0742\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0103 - mae: 0.0777 - val_loss: 0.0083 - val_mae: 0.0722\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0093 - mae: 0.0768 - val_loss: 0.0070 - val_mae: 0.0656\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0078 - mae: 0.0689 - val_loss: 0.0059 - val_mae: 0.0595\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0064 - mae: 0.0614 - val_loss: 0.0053 - val_mae: 0.0574\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0055 - mae: 0.0581 - val_loss: 0.0035 - val_mae: 0.0452\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0051 - mae: 0.0567 - val_loss: 0.0037 - val_mae: 0.0477\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0049 - mae: 0.0549 - val_loss: 0.0045 - val_mae: 0.0535\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0048 - mae: 0.0540 - val_loss: 0.0034 - val_mae: 0.0436\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0035 - mae: 0.0449 - val_loss: 0.0045 - val_mae: 0.0570\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0051 - mae: 0.0584 - val_loss: 0.0041 - val_mae: 0.0512\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0044 - mae: 0.0519 - val_loss: 0.0033 - val_mae: 0.0437\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0037 - mae: 0.0466 - val_loss: 0.0029 - val_mae: 0.0418\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0032 - mae: 0.0439 - val_loss: 0.0024 - val_mae: 0.0385\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0397 - val_loss: 0.0019 - val_mae: 0.0332\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0020 - mae: 0.0340 - val_loss: 0.0019 - val_mae: 0.0356\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0019 - mae: 0.0328 - val_loss: 0.0017 - val_mae: 0.0323\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0018 - mae: 0.0322 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0017 - mae: 0.0306 - val_loss: 0.0018 - val_mae: 0.0320\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0019 - mae: 0.0322 - val_loss: 0.0015 - val_mae: 0.0289\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0309 - val_loss: 0.0014 - val_mae: 0.0290\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0014 - val_mae: 0.0280\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0014 - val_mae: 0.0287\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0014 - val_mae: 0.0283\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0281\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0013 - val_mae: 0.0281\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0013 - val_mae: 0.0278\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0013 - val_mae: 0.0276\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0013 - val_mae: 0.0275\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0013 - val_mae: 0.0274\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0013 - val_mae: 0.0273\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0013 - val_mae: 0.0272\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0013 - val_mae: 0.0271\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0012 - val_mae: 0.0269\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0012 - val_mae: 0.0269\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0012 - val_mae: 0.0269\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0012 - val_mae: 0.0268\n",
      "\n",
      "âœ… Model and scaler saved for site 4032.\n",
      "4034\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1902 - mae: 0.3559 - val_loss: 0.0372 - val_mae: 0.1566\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0280 - mae: 0.1354 - val_loss: 0.0184 - val_mae: 0.1065\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0172 - mae: 0.1005 - val_loss: 0.0117 - val_mae: 0.0790\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0120 - mae: 0.0825 - val_loss: 0.0106 - val_mae: 0.0796\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0110 - mae: 0.0811 - val_loss: 0.0082 - val_mae: 0.0664\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0084 - mae: 0.0696 - val_loss: 0.0065 - val_mae: 0.0608\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0078 - mae: 0.0684 - val_loss: 0.0088 - val_mae: 0.0759\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0087 - mae: 0.0735 - val_loss: 0.0064 - val_mae: 0.0569\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0587 - val_loss: 0.0044 - val_mae: 0.0511\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0050 - mae: 0.0552 - val_loss: 0.0042 - val_mae: 0.0467\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0042 - mae: 0.0502 - val_loss: 0.0034 - val_mae: 0.0436\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0034 - mae: 0.0458 - val_loss: 0.0030 - val_mae: 0.0420\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0034 - mae: 0.0462 - val_loss: 0.0033 - val_mae: 0.0444\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0033 - mae: 0.0445 - val_loss: 0.0024 - val_mae: 0.0371\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0388 - val_loss: 0.0021 - val_mae: 0.0348\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0021 - mae: 0.0357 - val_loss: 0.0020 - val_mae: 0.0345\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0026 - mae: 0.0391 - val_loss: 0.0023 - val_mae: 0.0395\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0341 - val_loss: 0.0018 - val_mae: 0.0346\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0346 - val_loss: 0.0016 - val_mae: 0.0314\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0018 - mae: 0.0328 - val_loss: 0.0015 - val_mae: 0.0302\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0317 - val_loss: 0.0015 - val_mae: 0.0300\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0307 - val_loss: 0.0016 - val_mae: 0.0321\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0312 - val_loss: 0.0016 - val_mae: 0.0310\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0304 - val_loss: 0.0016 - val_mae: 0.0319\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0016 - mae: 0.0303 - val_loss: 0.0015 - val_mae: 0.0311\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 0.0016 - val_mae: 0.0324\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0303 - val_loss: 0.0015 - val_mae: 0.0303\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0016 - val_mae: 0.0319\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0015 - mae: 0.0298 - val_loss: 0.0014 - val_mae: 0.0298\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0015 - val_mae: 0.0311\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0015 - mae: 0.0296 - val_loss: 0.0014 - val_mae: 0.0290\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0015 - val_mae: 0.0313\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0014 - val_mae: 0.0288\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0014 - val_mae: 0.0305\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0015 - mae: 0.0294 - val_loss: 0.0013 - val_mae: 0.0286\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0014 - mae: 0.0288 - val_loss: 0.0014 - val_mae: 0.0295\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0290 - val_loss: 0.0013 - val_mae: 0.0286\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0288 - val_loss: 0.0014 - val_mae: 0.0293\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0291 - val_loss: 0.0013 - val_mae: 0.0280\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0014 - val_mae: 0.0292\n",
      "\n",
      "âœ… Model and scaler saved for site 4034.\n",
      "4035\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.2646 - mae: 0.4236 - val_loss: 0.0441 - val_mae: 0.1714\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0345 - mae: 0.1493 - val_loss: 0.0218 - val_mae: 0.1183\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0195 - mae: 0.1092 - val_loss: 0.0136 - val_mae: 0.0840\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0129 - mae: 0.0848 - val_loss: 0.0139 - val_mae: 0.0954\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0149 - mae: 0.0979 - val_loss: 0.0117 - val_mae: 0.0855\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0111 - mae: 0.0831 - val_loss: 0.0085 - val_mae: 0.0716\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0087 - mae: 0.0731 - val_loss: 0.0132 - val_mae: 0.0892\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0151 - mae: 0.0974 - val_loss: 0.0124 - val_mae: 0.0877\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0119 - mae: 0.0842 - val_loss: 0.0091 - val_mae: 0.0732\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0092 - mae: 0.0732 - val_loss: 0.0078 - val_mae: 0.0678\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0081 - mae: 0.0695 - val_loss: 0.0071 - val_mae: 0.0655\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0074 - mae: 0.0672 - val_loss: 0.0066 - val_mae: 0.0634\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0069 - mae: 0.0649 - val_loss: 0.0062 - val_mae: 0.0614\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0064 - mae: 0.0628 - val_loss: 0.0057 - val_mae: 0.0591\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0059 - mae: 0.0604 - val_loss: 0.0052 - val_mae: 0.0567\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0054 - mae: 0.0575 - val_loss: 0.0048 - val_mae: 0.0541\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0546 - val_loss: 0.0043 - val_mae: 0.0514\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0045 - mae: 0.0517 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0041 - mae: 0.0494 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0038 - mae: 0.0475 - val_loss: 0.0034 - val_mae: 0.0447\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0035 - mae: 0.0457 - val_loss: 0.0032 - val_mae: 0.0430\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0032 - mae: 0.0441 - val_loss: 0.0030 - val_mae: 0.0417\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0030 - mae: 0.0425 - val_loss: 0.0028 - val_mae: 0.0406\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0412 - val_loss: 0.0028 - val_mae: 0.0405\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0027 - mae: 0.0407 - val_loss: 0.0028 - val_mae: 0.0406\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0404 - val_loss: 0.0027 - val_mae: 0.0404\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0397 - val_loss: 0.0026 - val_mae: 0.0395\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0025 - mae: 0.0389 - val_loss: 0.0025 - val_mae: 0.0390\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0025 - mae: 0.0384 - val_loss: 0.0025 - val_mae: 0.0387\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0024 - mae: 0.0380 - val_loss: 0.0025 - val_mae: 0.0385\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0377 - val_loss: 0.0024 - val_mae: 0.0382\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0023 - mae: 0.0374 - val_loss: 0.0024 - val_mae: 0.0379\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0371 - val_loss: 0.0024 - val_mae: 0.0377\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 0.0023 - val_mae: 0.0375\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0366 - val_loss: 0.0023 - val_mae: 0.0372\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0364 - val_loss: 0.0023 - val_mae: 0.0370\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0361 - val_loss: 0.0022 - val_mae: 0.0360\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0351 - val_loss: 0.0020 - val_mae: 0.0348\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0347 - val_loss: 0.0020 - val_mae: 0.0349\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0021 - mae: 0.0351 - val_loss: 0.0020 - val_mae: 0.0342\n",
      "\n",
      "âœ… Model and scaler saved for site 4035.\n",
      "4040\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1465 - mae: 0.3151 - val_loss: 0.0274 - val_mae: 0.1331\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0255 - mae: 0.1286 - val_loss: 0.0178 - val_mae: 0.1013\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0164 - mae: 0.0977 - val_loss: 0.0116 - val_mae: 0.0827\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0111 - mae: 0.0823 - val_loss: 0.0107 - val_mae: 0.0821\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0107 - mae: 0.0822 - val_loss: 0.0087 - val_mae: 0.0744\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0082 - mae: 0.0718 - val_loss: 0.0067 - val_mae: 0.0656\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0636 - val_loss: 0.0052 - val_mae: 0.0572\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0551 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0040 - mae: 0.0491 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0036 - mae: 0.0466 - val_loss: 0.0031 - val_mae: 0.0441\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0032 - mae: 0.0444 - val_loss: 0.0029 - val_mae: 0.0420\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0030 - mae: 0.0423 - val_loss: 0.0028 - val_mae: 0.0413\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0027 - mae: 0.0401 - val_loss: 0.0025 - val_mae: 0.0392\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0389 - val_loss: 0.0028 - val_mae: 0.0414\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0384 - val_loss: 0.0023 - val_mae: 0.0375\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0370 - val_loss: 0.0027 - val_mae: 0.0416\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0378 - val_loss: 0.0024 - val_mae: 0.0382\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0023 - val_mae: 0.0377\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0359 - val_loss: 0.0023 - val_mae: 0.0375\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0356 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0355 - val_loss: 0.0023 - val_mae: 0.0379\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0021 - mae: 0.0353 - val_loss: 0.0022 - val_mae: 0.0374\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0021 - mae: 0.0349 - val_loss: 0.0021 - val_mae: 0.0362\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0343 - val_loss: 0.0021 - val_mae: 0.0363\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0341 - val_loss: 0.0021 - val_mae: 0.0367\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0340 - val_loss: 0.0021 - val_mae: 0.0364\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0339 - val_loss: 0.0020 - val_mae: 0.0355\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0336 - val_loss: 0.0020 - val_mae: 0.0351\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0338 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0333 - val_loss: 0.0018 - val_mae: 0.0324\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0018 - mae: 0.0323 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0018 - mae: 0.0325 - val_loss: 0.0019 - val_mae: 0.0350\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0018 - mae: 0.0326 - val_loss: 0.0020 - val_mae: 0.0357\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0019 - mae: 0.0329 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0018 - mae: 0.0325 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0320 - val_loss: 0.0018 - val_mae: 0.0329\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0018 - mae: 0.0318 - val_loss: 0.0018 - val_mae: 0.0325\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0018 - mae: 0.0314 - val_loss: 0.0018 - val_mae: 0.0333\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0018 - mae: 0.0317 - val_loss: 0.0018 - val_mae: 0.0329\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0018 - mae: 0.0317 - val_loss: 0.0017 - val_mae: 0.0326\n",
      "\n",
      "âœ… Model and scaler saved for site 4040.\n",
      "4043\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.3534 - mae: 0.4951 - val_loss: 0.0615 - val_mae: 0.2085\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0588 - mae: 0.2045 - val_loss: 0.0368 - val_mae: 0.1631\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0356 - mae: 0.1574 - val_loss: 0.0246 - val_mae: 0.1304\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0237 - mae: 0.1269 - val_loss: 0.0161 - val_mae: 0.1022\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0169 - mae: 0.1058 - val_loss: 0.0115 - val_mae: 0.0847\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0121 - mae: 0.0879 - val_loss: 0.0150 - val_mae: 0.1044\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0153 - mae: 0.1062 - val_loss: 0.0105 - val_mae: 0.0836\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0111 - mae: 0.0851 - val_loss: 0.0080 - val_mae: 0.0701\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0087 - mae: 0.0741 - val_loss: 0.0068 - val_mae: 0.0656\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0076 - mae: 0.0696 - val_loss: 0.0110 - val_mae: 0.0877\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0104 - mae: 0.0865 - val_loss: 0.0067 - val_mae: 0.0644\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0073 - mae: 0.0668 - val_loss: 0.0058 - val_mae: 0.0603\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0063 - mae: 0.0635 - val_loss: 0.0051 - val_mae: 0.0563\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0055 - mae: 0.0594 - val_loss: 0.0045 - val_mae: 0.0533\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0050 - mae: 0.0567 - val_loss: 0.0040 - val_mae: 0.0506\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0043 - mae: 0.0525 - val_loss: 0.0035 - val_mae: 0.0470\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0031 - val_mae: 0.0437\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0034 - mae: 0.0460 - val_loss: 0.0029 - val_mae: 0.0409\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0032 - mae: 0.0438 - val_loss: 0.0028 - val_mae: 0.0395\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0032 - mae: 0.0435 - val_loss: 0.0032 - val_mae: 0.0417\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0029 - mae: 0.0414 - val_loss: 0.0025 - val_mae: 0.0373\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0391 - val_loss: 0.0022 - val_mae: 0.0345\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0033 - val_mae: 0.0469\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0023 - val_mae: 0.0360\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0367 - val_loss: 0.0021 - val_mae: 0.0342\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0021 - mae: 0.0347 - val_loss: 0.0022 - val_mae: 0.0339\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0333 - val_loss: 0.0019 - val_mae: 0.0326\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0351 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0331 - val_loss: 0.0020 - val_mae: 0.0333\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0323 - val_loss: 0.0017 - val_mae: 0.0305\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0016 - mae: 0.0306 - val_loss: 0.0018 - val_mae: 0.0309\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0016 - mae: 0.0306 - val_loss: 0.0018 - val_mae: 0.0308\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0017 - mae: 0.0308 - val_loss: 0.0017 - val_mae: 0.0302\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0016 - mae: 0.0303 - val_loss: 0.0017 - val_mae: 0.0303\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0017 - val_mae: 0.0308\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0016 - mae: 0.0305 - val_loss: 0.0017 - val_mae: 0.0303\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0017 - val_mae: 0.0304\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 0.0016 - val_mae: 0.0301\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0016 - val_mae: 0.0298\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0015 - mae: 0.0294 - val_loss: 0.0016 - val_mae: 0.0299\n",
      "\n",
      "âœ… Model and scaler saved for site 4043.\n",
      "4051\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.1731 - mae: 0.3300 - val_loss: 0.0419 - val_mae: 0.1674\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0301 - mae: 0.1381 - val_loss: 0.0204 - val_mae: 0.1097\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0182 - mae: 0.1012 - val_loss: 0.0145 - val_mae: 0.0872\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0135 - mae: 0.0864 - val_loss: 0.0146 - val_mae: 0.0959\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0193 - mae: 0.1097 - val_loss: 0.0263 - val_mae: 0.1300\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0239 - mae: 0.1253 - val_loss: 0.0210 - val_mae: 0.1182\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0195 - mae: 0.1150 - val_loss: 0.0186 - val_mae: 0.1110\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0175 - mae: 0.1082 - val_loss: 0.0170 - val_mae: 0.1044\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0160 - mae: 0.1021 - val_loss: 0.0156 - val_mae: 0.0988\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0148 - mae: 0.0968 - val_loss: 0.0145 - val_mae: 0.0937\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0138 - mae: 0.0920 - val_loss: 0.0136 - val_mae: 0.0891\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0130 - mae: 0.0877 - val_loss: 0.0128 - val_mae: 0.0851\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0123 - mae: 0.0841 - val_loss: 0.0121 - val_mae: 0.0817\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0117 - mae: 0.0810 - val_loss: 0.0116 - val_mae: 0.0789\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0111 - mae: 0.0784 - val_loss: 0.0111 - val_mae: 0.0766\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0107 - mae: 0.0763 - val_loss: 0.0106 - val_mae: 0.0747\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0102 - mae: 0.0746 - val_loss: 0.0102 - val_mae: 0.0731\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0098 - mae: 0.0731 - val_loss: 0.0099 - val_mae: 0.0718\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0095 - mae: 0.0718 - val_loss: 0.0096 - val_mae: 0.0707\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0092 - mae: 0.0706 - val_loss: 0.0093 - val_mae: 0.0698\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0089 - mae: 0.0696 - val_loss: 0.0090 - val_mae: 0.0689\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0087 - mae: 0.0687 - val_loss: 0.0088 - val_mae: 0.0681\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0085 - mae: 0.0678 - val_loss: 0.0086 - val_mae: 0.0672\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0083 - mae: 0.0670 - val_loss: 0.0084 - val_mae: 0.0664\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0081 - mae: 0.0662 - val_loss: 0.0082 - val_mae: 0.0656\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0079 - mae: 0.0655 - val_loss: 0.0080 - val_mae: 0.0648\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0077 - mae: 0.0648 - val_loss: 0.0078 - val_mae: 0.0640\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0075 - mae: 0.0641 - val_loss: 0.0076 - val_mae: 0.0633\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0073 - mae: 0.0634 - val_loss: 0.0074 - val_mae: 0.0626\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0072 - mae: 0.0627 - val_loss: 0.0072 - val_mae: 0.0619\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0069 - mae: 0.0619 - val_loss: 0.0070 - val_mae: 0.0613\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0067 - mae: 0.0611 - val_loss: 0.0067 - val_mae: 0.0610\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0598 - val_loss: 0.0064 - val_mae: 0.0590\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0060 - mae: 0.0575 - val_loss: 0.0061 - val_mae: 0.0574\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0058 - mae: 0.0563 - val_loss: 0.0057 - val_mae: 0.0549\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0055 - mae: 0.0544 - val_loss: 0.0055 - val_mae: 0.0543\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0052 - mae: 0.0533 - val_loss: 0.0051 - val_mae: 0.0514\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0048 - mae: 0.0511 - val_loss: 0.0047 - val_mae: 0.0500\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0044 - mae: 0.0488 - val_loss: 0.0042 - val_mae: 0.0475\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0039 - mae: 0.0462 - val_loss: 0.0038 - val_mae: 0.0457\n",
      "\n",
      "âœ… Model and scaler saved for site 4051.\n",
      "4057\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1975 - mae: 0.3475 - val_loss: 0.0417 - val_mae: 0.1682\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0397 - mae: 0.1624 - val_loss: 0.0275 - val_mae: 0.1312\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0259 - mae: 0.1277 - val_loss: 0.0183 - val_mae: 0.1001\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0180 - mae: 0.0988 - val_loss: 0.0136 - val_mae: 0.0830\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0138 - mae: 0.0863 - val_loss: 0.0145 - val_mae: 0.0968\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0149 - mae: 0.0954 - val_loss: 0.0110 - val_mae: 0.0724\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0109 - mae: 0.0728 - val_loss: 0.0091 - val_mae: 0.0708\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0139 - mae: 0.0918 - val_loss: 0.0153 - val_mae: 0.0960\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0144 - mae: 0.0926 - val_loss: 0.0109 - val_mae: 0.0729\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0109 - mae: 0.0742 - val_loss: 0.0089 - val_mae: 0.0678\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0090 - mae: 0.0681 - val_loss: 0.0072 - val_mae: 0.0613\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0075 - mae: 0.0618 - val_loss: 0.0062 - val_mae: 0.0580\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0579 - val_loss: 0.0053 - val_mae: 0.0533\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0056 - mae: 0.0538 - val_loss: 0.0046 - val_mae: 0.0500\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0049 - mae: 0.0513 - val_loss: 0.0040 - val_mae: 0.0477\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0042 - mae: 0.0488 - val_loss: 0.0036 - val_mae: 0.0455\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0037 - mae: 0.0469 - val_loss: 0.0033 - val_mae: 0.0436\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0034 - mae: 0.0448 - val_loss: 0.0030 - val_mae: 0.0413\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0037 - mae: 0.0469 - val_loss: 0.0033 - val_mae: 0.0439\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0433 - val_loss: 0.0027 - val_mae: 0.0398\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0409 - val_loss: 0.0026 - val_mae: 0.0382\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0029 - mae: 0.0407 - val_loss: 0.0027 - val_mae: 0.0386\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0401 - val_loss: 0.0026 - val_mae: 0.0378\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0027 - mae: 0.0392 - val_loss: 0.0025 - val_mae: 0.0369\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0387 - val_loss: 0.0024 - val_mae: 0.0363\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 0.0023 - val_mae: 0.0358\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0027 - mae: 0.0396 - val_loss: 0.0023 - val_mae: 0.0366\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0039 - mae: 0.0461 - val_loss: 0.0039 - val_mae: 0.0431\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0037 - mae: 0.0430 - val_loss: 0.0024 - val_mae: 0.0370\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0023 - val_mae: 0.0357\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0025 - mae: 0.0370 - val_loss: 0.0022 - val_mae: 0.0351\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0022 - val_mae: 0.0349\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0363 - val_loss: 0.0022 - val_mae: 0.0346\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0024 - mae: 0.0360 - val_loss: 0.0022 - val_mae: 0.0345\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0024 - mae: 0.0358 - val_loss: 0.0021 - val_mae: 0.0340\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0023 - mae: 0.0355 - val_loss: 0.0021 - val_mae: 0.0336\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0023 - mae: 0.0355 - val_loss: 0.0021 - val_mae: 0.0339\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0023 - mae: 0.0355 - val_loss: 0.0021 - val_mae: 0.0337\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0023 - mae: 0.0350 - val_loss: 0.0020 - val_mae: 0.0334\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0022 - mae: 0.0348 - val_loss: 0.0021 - val_mae: 0.0343\n",
      "\n",
      "âœ… Model and scaler saved for site 4057.\n",
      "4063\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.2045 - mae: 0.3632 - val_loss: 0.0392 - val_mae: 0.1738\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0356 - mae: 0.1632 - val_loss: 0.0231 - val_mae: 0.1266\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0203 - mae: 0.1147 - val_loss: 0.0135 - val_mae: 0.0904\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0141 - mae: 0.0923 - val_loss: 0.0111 - val_mae: 0.0817\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0112 - mae: 0.0804 - val_loss: 0.0085 - val_mae: 0.0692\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0103 - mae: 0.0784 - val_loss: 0.0083 - val_mae: 0.0662\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0085 - mae: 0.0676 - val_loss: 0.0070 - val_mae: 0.0671\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0093 - mae: 0.0781 - val_loss: 0.0104 - val_mae: 0.0823\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0098 - mae: 0.0783 - val_loss: 0.0070 - val_mae: 0.0633\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0074 - mae: 0.0649 - val_loss: 0.0064 - val_mae: 0.0622\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0632 - val_loss: 0.0057 - val_mae: 0.0581\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0059 - mae: 0.0587 - val_loss: 0.0050 - val_mae: 0.0544\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0052 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0497\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0044 - mae: 0.0506 - val_loss: 0.0035 - val_mae: 0.0467\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0028 - val_mae: 0.0412\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0034 - mae: 0.0457 - val_loss: 0.0062 - val_mae: 0.0618\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0606 - val_loss: 0.0043 - val_mae: 0.0482\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0043 - mae: 0.0496 - val_loss: 0.0035 - val_mae: 0.0456\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0036 - mae: 0.0462 - val_loss: 0.0031 - val_mae: 0.0429\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0433 - val_loss: 0.0028 - val_mae: 0.0396\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0403 - val_loss: 0.0025 - val_mae: 0.0378\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0387 - val_loss: 0.0024 - val_mae: 0.0365\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0371 - val_loss: 0.0022 - val_mae: 0.0352\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0023 - mae: 0.0361 - val_loss: 0.0021 - val_mae: 0.0341\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0359 - val_loss: 0.0021 - val_mae: 0.0340\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0021 - mae: 0.0352 - val_loss: 0.0019 - val_mae: 0.0326\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0021 - mae: 0.0347 - val_loss: 0.0019 - val_mae: 0.0324\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0341 - val_loss: 0.0019 - val_mae: 0.0325\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0342 - val_loss: 0.0019 - val_mae: 0.0318\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0336 - val_loss: 0.0019 - val_mae: 0.0321\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0338 - val_loss: 0.0019 - val_mae: 0.0322\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0338 - val_loss: 0.0018 - val_mae: 0.0319\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0336 - val_loss: 0.0019 - val_mae: 0.0319\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0335 - val_loss: 0.0019 - val_mae: 0.0319\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0336 - val_loss: 0.0019 - val_mae: 0.0319\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0336 - val_loss: 0.0018 - val_mae: 0.0318\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0336 - val_loss: 0.0018 - val_mae: 0.0315\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0020 - mae: 0.0337 - val_loss: 0.0018 - val_mae: 0.0312\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0337 - val_loss: 0.0018 - val_mae: 0.0312\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0335 - val_loss: 0.0018 - val_mae: 0.0317\n",
      "\n",
      "âœ… Model and scaler saved for site 4063.\n",
      "4262\n",
      "Epoch 1/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0807 - mae: 0.2285 - val_loss: 0.0233 - val_mae: 0.1277\n",
      "Epoch 2/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0199 - mae: 0.1151 - val_loss: 0.0120 - val_mae: 0.0892\n",
      "Epoch 3/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0126 - mae: 0.0891 - val_loss: 0.0093 - val_mae: 0.0720\n",
      "Epoch 4/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0104 - mae: 0.0753 - val_loss: 0.0084 - val_mae: 0.0697\n",
      "Epoch 5/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0094 - mae: 0.0714 - val_loss: 0.0079 - val_mae: 0.0667\n",
      "Epoch 6/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0088 - mae: 0.0681 - val_loss: 0.0076 - val_mae: 0.0642\n",
      "Epoch 7/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0084 - mae: 0.0651 - val_loss: 0.0073 - val_mae: 0.0617\n",
      "Epoch 8/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0081 - mae: 0.0633 - val_loss: 0.0071 - val_mae: 0.0613\n",
      "Epoch 9/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0078 - mae: 0.0619 - val_loss: 0.0069 - val_mae: 0.0596\n",
      "Epoch 10/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0076 - mae: 0.0604 - val_loss: 0.0067 - val_mae: 0.0568\n",
      "Epoch 11/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0074 - mae: 0.0592 - val_loss: 0.0065 - val_mae: 0.0539\n",
      "Epoch 12/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0072 - mae: 0.0585 - val_loss: 0.0064 - val_mae: 0.0522\n",
      "Epoch 13/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0576 - val_loss: 0.0062 - val_mae: 0.0510\n",
      "Epoch 14/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0070 - mae: 0.0568 - val_loss: 0.0061 - val_mae: 0.0503\n",
      "Epoch 15/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0069 - mae: 0.0560 - val_loss: 0.0062 - val_mae: 0.0501\n",
      "Epoch 16/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0069 - mae: 0.0552 - val_loss: 0.0061 - val_mae: 0.0495\n",
      "Epoch 17/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0542 - val_loss: 0.0061 - val_mae: 0.0497\n",
      "Epoch 18/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0533 - val_loss: 0.0061 - val_mae: 0.0503\n",
      "Epoch 19/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0523 - val_loss: 0.0061 - val_mae: 0.0497\n",
      "Epoch 20/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0517 - val_loss: 0.0060 - val_mae: 0.0490\n",
      "Epoch 21/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0515 - val_loss: 0.0060 - val_mae: 0.0488\n",
      "Epoch 22/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0065 - mae: 0.0512 - val_loss: 0.0060 - val_mae: 0.0488\n",
      "Epoch 23/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0064 - mae: 0.0509 - val_loss: 0.0060 - val_mae: 0.0486\n",
      "Epoch 24/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0064 - mae: 0.0506 - val_loss: 0.0060 - val_mae: 0.0483\n",
      "Epoch 25/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0504 - val_loss: 0.0059 - val_mae: 0.0481\n",
      "Epoch 26/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0503 - val_loss: 0.0059 - val_mae: 0.0479\n",
      "Epoch 27/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0502 - val_loss: 0.0059 - val_mae: 0.0478\n",
      "Epoch 28/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0500 - val_loss: 0.0059 - val_mae: 0.0475\n",
      "Epoch 29/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0498 - val_loss: 0.0059 - val_mae: 0.0473\n",
      "Epoch 30/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0062 - mae: 0.0497 - val_loss: 0.0058 - val_mae: 0.0471\n",
      "Epoch 31/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0062 - mae: 0.0496 - val_loss: 0.0058 - val_mae: 0.0470\n",
      "Epoch 32/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0062 - mae: 0.0494 - val_loss: 0.0058 - val_mae: 0.0467\n",
      "Epoch 33/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0062 - mae: 0.0493 - val_loss: 0.0058 - val_mae: 0.0465\n",
      "Epoch 34/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0062 - mae: 0.0492 - val_loss: 0.0058 - val_mae: 0.0462\n",
      "Epoch 35/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0490 - val_loss: 0.0057 - val_mae: 0.0460\n",
      "Epoch 36/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0061 - mae: 0.0489 - val_loss: 0.0057 - val_mae: 0.0458\n",
      "Epoch 37/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0061 - mae: 0.0487 - val_loss: 0.0057 - val_mae: 0.0455\n",
      "Epoch 38/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0486 - val_loss: 0.0056 - val_mae: 0.0452\n",
      "Epoch 39/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0484 - val_loss: 0.0056 - val_mae: 0.0449\n",
      "Epoch 40/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0060 - mae: 0.0483 - val_loss: 0.0056 - val_mae: 0.0446\n",
      "\n",
      "âœ… Model and scaler saved for site 4262.\n",
      "4263\n",
      "Epoch 1/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1537 - mae: 0.3113 - val_loss: 0.0385 - val_mae: 0.1591\n",
      "Epoch 2/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0354 - mae: 0.1525 - val_loss: 0.0234 - val_mae: 0.1236\n",
      "Epoch 3/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0248 - mae: 0.1242 - val_loss: 0.0167 - val_mae: 0.0996\n",
      "Epoch 4/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0172 - mae: 0.0964 - val_loss: 0.0119 - val_mae: 0.0792\n",
      "Epoch 5/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0120 - mae: 0.0790 - val_loss: 0.0101 - val_mae: 0.0781\n",
      "Epoch 6/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0819 - val_loss: 0.0094 - val_mae: 0.0720\n",
      "Epoch 7/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0095 - mae: 0.0712 - val_loss: 0.0085 - val_mae: 0.0706\n",
      "Epoch 8/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0084 - mae: 0.0673 - val_loss: 0.0141 - val_mae: 0.0954\n",
      "Epoch 9/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0158 - mae: 0.0992 - val_loss: 0.0124 - val_mae: 0.0879\n",
      "Epoch 10/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0127 - mae: 0.0859 - val_loss: 0.0097 - val_mae: 0.0743\n",
      "Epoch 11/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0103 - mae: 0.0758 - val_loss: 0.0082 - val_mae: 0.0689\n",
      "Epoch 12/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0086 - mae: 0.0711 - val_loss: 0.0070 - val_mae: 0.0633\n",
      "Epoch 13/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0072 - mae: 0.0654 - val_loss: 0.0061 - val_mae: 0.0575\n",
      "Epoch 14/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0063 - mae: 0.0600 - val_loss: 0.0054 - val_mae: 0.0539\n",
      "Epoch 15/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0055 - mae: 0.0560 - val_loss: 0.0048 - val_mae: 0.0505\n",
      "Epoch 16/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0048 - mae: 0.0521 - val_loss: 0.0041 - val_mae: 0.0475\n",
      "Epoch 17/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0042 - mae: 0.0488 - val_loss: 0.0037 - val_mae: 0.0452\n",
      "Epoch 18/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0038 - mae: 0.0461 - val_loss: 0.0033 - val_mae: 0.0432\n",
      "Epoch 19/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0034 - mae: 0.0439 - val_loss: 0.0030 - val_mae: 0.0409\n",
      "Epoch 20/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0031 - mae: 0.0417 - val_loss: 0.0027 - val_mae: 0.0390\n",
      "Epoch 21/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0389 - val_loss: 0.0024 - val_mae: 0.0371\n",
      "Epoch 22/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 0.0022 - val_mae: 0.0342\n",
      "Epoch 23/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0361 - val_loss: 0.0022 - val_mae: 0.0349\n",
      "Epoch 24/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0353 - val_loss: 0.0021 - val_mae: 0.0340\n",
      "Epoch 25/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0339 - val_loss: 0.0020 - val_mae: 0.0330\n",
      "Epoch 26/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0331 - val_loss: 0.0020 - val_mae: 0.0334\n",
      "Epoch 27/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0323 - val_loss: 0.0018 - val_mae: 0.0312\n",
      "Epoch 28/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0313 - val_loss: 0.0018 - val_mae: 0.0313\n",
      "Epoch 29/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0306 - val_loss: 0.0018 - val_mae: 0.0312\n",
      "Epoch 30/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0305 - val_loss: 0.0018 - val_mae: 0.0311\n",
      "Epoch 31/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0016 - mae: 0.0306 - val_loss: 0.0018 - val_mae: 0.0312\n",
      "Epoch 32/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0016 - mae: 0.0303 - val_loss: 0.0018 - val_mae: 0.0310\n",
      "Epoch 33/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0017 - val_mae: 0.0305\n",
      "Epoch 34/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0296 - val_loss: 0.0017 - val_mae: 0.0300\n",
      "Epoch 35/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0016 - val_mae: 0.0296\n",
      "Epoch 36/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0016 - val_mae: 0.0300\n",
      "Epoch 37/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0016 - val_mae: 0.0289\n",
      "Epoch 38/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0016 - val_mae: 0.0299\n",
      "Epoch 39/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0016 - val_mae: 0.0297\n",
      "Epoch 40/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0016 - val_mae: 0.0291\n",
      "\n",
      "âœ… Model and scaler saved for site 4263.\n",
      "4264\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1849 - mae: 0.3592 - val_loss: 0.0241 - val_mae: 0.1256\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0270 - mae: 0.1316 - val_loss: 0.0123 - val_mae: 0.0853\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0144 - mae: 0.0877 - val_loss: 0.0075 - val_mae: 0.0651\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0097 - mae: 0.0728 - val_loss: 0.0068 - val_mae: 0.0615\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0090 - mae: 0.0696 - val_loss: 0.0058 - val_mae: 0.0563\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0075 - mae: 0.0630 - val_loss: 0.0053 - val_mae: 0.0549\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0058 - mae: 0.0557 - val_loss: 0.0053 - val_mae: 0.0586\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0050 - mae: 0.0539 - val_loss: 0.0069 - val_mae: 0.0665\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0090 - mae: 0.0738 - val_loss: 0.0048 - val_mae: 0.0497\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0561 - val_loss: 0.0038 - val_mae: 0.0462\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0047 - mae: 0.0507 - val_loss: 0.0033 - val_mae: 0.0427\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0038 - mae: 0.0458 - val_loss: 0.0028 - val_mae: 0.0395\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0032 - mae: 0.0427 - val_loss: 0.0025 - val_mae: 0.0373\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0403 - val_loss: 0.0021 - val_mae: 0.0338\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0383 - val_loss: 0.0021 - val_mae: 0.0350\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0374 - val_loss: 0.0019 - val_mae: 0.0329\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0021 - mae: 0.0357 - val_loss: 0.0016 - val_mae: 0.0297\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0365 - val_loss: 0.0020 - val_mae: 0.0352\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0020 - mae: 0.0347 - val_loss: 0.0017 - val_mae: 0.0316\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0331 - val_loss: 0.0014 - val_mae: 0.0283\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0344 - val_loss: 0.0016 - val_mae: 0.0299\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0018 - mae: 0.0327 - val_loss: 0.0014 - val_mae: 0.0287\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0018 - mae: 0.0329 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0325 - val_loss: 0.0014 - val_mae: 0.0286\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0018 - mae: 0.0324 - val_loss: 0.0015 - val_mae: 0.0294\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0324 - val_loss: 0.0015 - val_mae: 0.0289\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0321 - val_loss: 0.0014 - val_mae: 0.0287\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0323 - val_loss: 0.0015 - val_mae: 0.0290\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0319 - val_loss: 0.0014 - val_mae: 0.0282\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0018 - mae: 0.0321 - val_loss: 0.0015 - val_mae: 0.0290\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0319 - val_loss: 0.0014 - val_mae: 0.0285\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0017 - mae: 0.0317 - val_loss: 0.0014 - val_mae: 0.0284\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0318 - val_loss: 0.0014 - val_mae: 0.0285\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0317 - val_loss: 0.0014 - val_mae: 0.0283\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0317 - val_loss: 0.0014 - val_mae: 0.0285\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0317 - val_loss: 0.0014 - val_mae: 0.0284\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0316 - val_loss: 0.0014 - val_mae: 0.0282\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0315 - val_loss: 0.0014 - val_mae: 0.0283\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0316 - val_loss: 0.0014 - val_mae: 0.0285\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0317 - val_loss: 0.0014 - val_mae: 0.0284\n",
      "\n",
      "âœ… Model and scaler saved for site 4264.\n",
      "4266\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.2593 - mae: 0.4199 - val_loss: 0.0586 - val_mae: 0.1933\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0432 - mae: 0.1707 - val_loss: 0.0237 - val_mae: 0.1227\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0206 - mae: 0.1115 - val_loss: 0.0146 - val_mae: 0.0868\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0143 - mae: 0.0886 - val_loss: 0.0112 - val_mae: 0.0763\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0108 - mae: 0.0770 - val_loss: 0.0087 - val_mae: 0.0678\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0081 - mae: 0.0677 - val_loss: 0.0070 - val_mae: 0.0660\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0079 - mae: 0.0672 - val_loss: 0.0221 - val_mae: 0.1228\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0215 - mae: 0.1220 - val_loss: 0.0157 - val_mae: 0.1012\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0136 - mae: 0.0929 - val_loss: 0.0100 - val_mae: 0.0767\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0093 - mae: 0.0733 - val_loss: 0.0079 - val_mae: 0.0650\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0076 - mae: 0.0646 - val_loss: 0.0066 - val_mae: 0.0601\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0062 - mae: 0.0591 - val_loss: 0.0052 - val_mae: 0.0543\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0047 - mae: 0.0518 - val_loss: 0.0034 - val_mae: 0.0441\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0031 - mae: 0.0424 - val_loss: 0.0027 - val_mae: 0.0389\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0039 - val_mae: 0.0461\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0038 - mae: 0.0442 - val_loss: 0.0033 - val_mae: 0.0420\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0029 - mae: 0.0393 - val_loss: 0.0024 - val_mae: 0.0374\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0022 - mae: 0.0355 - val_loss: 0.0021 - val_mae: 0.0351\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0019 - mae: 0.0338 - val_loss: 0.0019 - val_mae: 0.0334\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0325 - val_loss: 0.0018 - val_mae: 0.0321\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0016 - mae: 0.0312 - val_loss: 0.0017 - val_mae: 0.0312\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0015 - mae: 0.0304 - val_loss: 0.0016 - val_mae: 0.0306\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0015 - mae: 0.0296 - val_loss: 0.0015 - val_mae: 0.0299\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0014 - mae: 0.0289 - val_loss: 0.0015 - val_mae: 0.0295\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - mae: 0.0283 - val_loss: 0.0014 - val_mae: 0.0286\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0013 - mae: 0.0276 - val_loss: 0.0014 - val_mae: 0.0282\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0269 - val_loss: 0.0013 - val_mae: 0.0274\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 0.0013 - val_mae: 0.0272\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 0.0013 - val_mae: 0.0269\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0013 - val_mae: 0.0268\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0013 - val_mae: 0.0270\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0013 - val_mae: 0.0266\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0258 - val_loss: 0.0013 - val_mae: 0.0265\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0258 - val_loss: 0.0013 - val_mae: 0.0263\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0012 - val_mae: 0.0262\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0012 - val_mae: 0.0261\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0251 - val_loss: 0.0013 - val_mae: 0.0265\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0012 - val_mae: 0.0259\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 0.0012 - val_mae: 0.0254\n",
      "\n",
      "âœ… Model and scaler saved for site 4266.\n",
      "4270\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.2565 - mae: 0.4248 - val_loss: 0.0635 - val_mae: 0.2095\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0475 - mae: 0.1825 - val_loss: 0.0271 - val_mae: 0.1352\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0229 - mae: 0.1219 - val_loss: 0.0137 - val_mae: 0.0911\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0142 - mae: 0.0952 - val_loss: 0.0103 - val_mae: 0.0792\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0105 - mae: 0.0820 - val_loss: 0.0100 - val_mae: 0.0785\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0137 - mae: 0.0933 - val_loss: 0.0229 - val_mae: 0.1281\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0205 - mae: 0.1222 - val_loss: 0.0125 - val_mae: 0.0938\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0113 - mae: 0.0895 - val_loss: 0.0084 - val_mae: 0.0740\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0085 - mae: 0.0740 - val_loss: 0.0069 - val_mae: 0.0638\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0071 - mae: 0.0652 - val_loss: 0.0062 - val_mae: 0.0606\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0064 - mae: 0.0625 - val_loss: 0.0058 - val_mae: 0.0587\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0060 - mae: 0.0604 - val_loss: 0.0055 - val_mae: 0.0574\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0058 - mae: 0.0590 - val_loss: 0.0052 - val_mae: 0.0559\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0055 - mae: 0.0574 - val_loss: 0.0050 - val_mae: 0.0545\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0052 - mae: 0.0558 - val_loss: 0.0048 - val_mae: 0.0530\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0049 - mae: 0.0542 - val_loss: 0.0045 - val_mae: 0.0513\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0047 - mae: 0.0525 - val_loss: 0.0043 - val_mae: 0.0497\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0044 - mae: 0.0508 - val_loss: 0.0040 - val_mae: 0.0480\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0041 - mae: 0.0490 - val_loss: 0.0038 - val_mae: 0.0463\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0039 - mae: 0.0472 - val_loss: 0.0036 - val_mae: 0.0448\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0037 - mae: 0.0458 - val_loss: 0.0035 - val_mae: 0.0447\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0036 - mae: 0.0454 - val_loss: 0.0033 - val_mae: 0.0432\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0035 - mae: 0.0442 - val_loss: 0.0033 - val_mae: 0.0435\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0034 - mae: 0.0437 - val_loss: 0.0031 - val_mae: 0.0418\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0033 - mae: 0.0428 - val_loss: 0.0030 - val_mae: 0.0412\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0032 - mae: 0.0422 - val_loss: 0.0029 - val_mae: 0.0404\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0031 - mae: 0.0417 - val_loss: 0.0028 - val_mae: 0.0397\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0030 - mae: 0.0412 - val_loss: 0.0027 - val_mae: 0.0390\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0029 - mae: 0.0407 - val_loss: 0.0026 - val_mae: 0.0384\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0028 - mae: 0.0401 - val_loss: 0.0025 - val_mae: 0.0373\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0026 - mae: 0.0391 - val_loss: 0.0024 - val_mae: 0.0377\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0025 - mae: 0.0387 - val_loss: 0.0022 - val_mae: 0.0352\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0023 - mae: 0.0371 - val_loss: 0.0022 - val_mae: 0.0362\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 0.0021 - val_mae: 0.0353\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0022 - mae: 0.0358 - val_loss: 0.0020 - val_mae: 0.0358\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0021 - mae: 0.0361 - val_loss: 0.0017 - val_mae: 0.0313\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0020 - mae: 0.0340 - val_loss: 0.0017 - val_mae: 0.0310\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0332 - val_loss: 0.0016 - val_mae: 0.0302\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0326 - val_loss: 0.0016 - val_mae: 0.0301\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0018 - mae: 0.0321 - val_loss: 0.0017 - val_mae: 0.0307\n",
      "\n",
      "âœ… Model and scaler saved for site 4270.\n",
      "4272\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1807 - mae: 0.3372 - val_loss: 0.0360 - val_mae: 0.1551\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0336 - mae: 0.1508 - val_loss: 0.0275 - val_mae: 0.1331\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0255 - mae: 0.1299 - val_loss: 0.0217 - val_mae: 0.1159\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0199 - mae: 0.1123 - val_loss: 0.0171 - val_mae: 0.1006\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0153 - mae: 0.0983 - val_loss: 0.0139 - val_mae: 0.0917\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0125 - mae: 0.0901 - val_loss: 0.0117 - val_mae: 0.0838\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0105 - mae: 0.0819 - val_loss: 0.0099 - val_mae: 0.0765\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0085 - mae: 0.0725 - val_loss: 0.0072 - val_mae: 0.0633\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1977487589376.0000 - mae: 156514.3594 - val_loss: 0.0282 - val_mae: 0.1246\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0284 - mae: 0.1253 - val_loss: 0.0319 - val_mae: 0.1333\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0295 - mae: 0.1281 - val_loss: 0.0291 - val_mae: 0.1270\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0258 - mae: 0.1207 - val_loss: 0.0213 - val_mae: 0.1119\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0187 - mae: 0.1094 - val_loss: 0.0177 - val_mae: 0.1027\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0157 - mae: 0.0976 - val_loss: 0.0100 - val_mae: 0.0733\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0199 - mae: 0.0842 - val_loss: 0.0134 - val_mae: 0.0863\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0133 - mae: 0.0868 - val_loss: 0.0149 - val_mae: 0.0905\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0139 - mae: 0.0887 - val_loss: 0.0146 - val_mae: 0.0898\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0136 - mae: 0.0880 - val_loss: 0.0142 - val_mae: 0.0889\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0132 - mae: 0.0872 - val_loss: 0.0139 - val_mae: 0.0881\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0129 - mae: 0.0865 - val_loss: 0.0136 - val_mae: 0.0874\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0126 - mae: 0.0859 - val_loss: 0.0133 - val_mae: 0.0867\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0124 - mae: 0.0854 - val_loss: 0.0130 - val_mae: 0.0861\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0121 - mae: 0.0849 - val_loss: 0.0128 - val_mae: 0.0856\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0119 - mae: 0.0844 - val_loss: 0.0125 - val_mae: 0.0851\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0117 - mae: 0.0840 - val_loss: 0.0124 - val_mae: 0.0847\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0116 - mae: 0.0837 - val_loss: 0.0122 - val_mae: 0.0844\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0114 - mae: 0.0834 - val_loss: 0.0120 - val_mae: 0.0840\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0113 - mae: 0.0831 - val_loss: 0.0119 - val_mae: 0.0837\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0112 - mae: 0.0829 - val_loss: 0.0118 - val_mae: 0.0835\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0111 - mae: 0.0827 - val_loss: 0.0117 - val_mae: 0.0833\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0110 - mae: 0.0825 - val_loss: 0.0116 - val_mae: 0.0831\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0109 - mae: 0.0824 - val_loss: 0.0115 - val_mae: 0.0830\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0109 - mae: 0.0822 - val_loss: 0.0115 - val_mae: 0.0829\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0108 - mae: 0.0822 - val_loss: 0.0114 - val_mae: 0.0828\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0108 - mae: 0.0821 - val_loss: 0.0113 - val_mae: 0.0826\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0107 - mae: 0.0820 - val_loss: 0.0113 - val_mae: 0.0825\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0107 - mae: 0.0820 - val_loss: 0.0112 - val_mae: 0.0825\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0107 - mae: 0.0819 - val_loss: 0.0112 - val_mae: 0.0824\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0106 - mae: 0.0819 - val_loss: 0.0112 - val_mae: 0.0823\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0106 - mae: 0.0819 - val_loss: 0.0111 - val_mae: 0.0822\n",
      "\n",
      "âœ… Model and scaler saved for site 4272.\n",
      "4273\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1402 - mae: 0.2914 - val_loss: 0.0304 - val_mae: 0.1453\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0260 - mae: 0.1272 - val_loss: 0.0170 - val_mae: 0.1020\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0175 - mae: 0.1022 - val_loss: 0.0128 - val_mae: 0.0875\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0136 - mae: 0.0920 - val_loss: 0.0101 - val_mae: 0.0800\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0107 - mae: 0.0824 - val_loss: 0.0077 - val_mae: 0.0684\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0083 - mae: 0.0697 - val_loss: 0.0153 - val_mae: 0.0914\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0169 - mae: 0.0977 - val_loss: 0.0097 - val_mae: 0.0797\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0098 - mae: 0.0775 - val_loss: 0.0065 - val_mae: 0.0608\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 33992489304064.0000 - mae: 465248.7812 - val_loss: 0.0253 - val_mae: 0.1151\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0308 - mae: 0.1296 - val_loss: 0.0256 - val_mae: 0.1159\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0264 - mae: 0.1199 - val_loss: 0.0126 - val_mae: 0.0923\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0119 - mae: 0.0855 - val_loss: 0.0075 - val_mae: 0.0661\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0082 - mae: 0.0671 - val_loss: 0.0079 - val_mae: 0.0663\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0085 - mae: 0.0700 - val_loss: 0.0061 - val_mae: 0.0588\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0062 - mae: 0.0594 - val_loss: 0.0044 - val_mae: 0.0534\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0053 - mae: 0.0559 - val_loss: 0.0088 - val_mae: 0.0672\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0102 - mae: 0.0732 - val_loss: 0.0050 - val_mae: 0.0524\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0058 - mae: 0.0579 - val_loss: 0.0045 - val_mae: 0.0501\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0046 - mae: 0.0527 - val_loss: 0.0043 - val_mae: 0.0504\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0047 - mae: 0.0530 - val_loss: 0.0047 - val_mae: 0.0533\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0046 - mae: 0.0525 - val_loss: 0.0033 - val_mae: 0.0431\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0058 - mae: 0.0548 - val_loss: 0.0073 - val_mae: 0.0630\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0082 - mae: 0.0677 - val_loss: 0.0067 - val_mae: 0.0634\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0075 - mae: 0.0667 - val_loss: 0.0064 - val_mae: 0.0626\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0070 - mae: 0.0649 - val_loss: 0.0061 - val_mae: 0.0602\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0625 - val_loss: 0.0058 - val_mae: 0.0580\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0064 - mae: 0.0603 - val_loss: 0.0055 - val_mae: 0.0561\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0061 - mae: 0.0586 - val_loss: 0.0053 - val_mae: 0.0545\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0058 - mae: 0.0570 - val_loss: 0.0051 - val_mae: 0.0532\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0056 - mae: 0.0558 - val_loss: 0.0049 - val_mae: 0.0520\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0048 - val_mae: 0.0508\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0052 - mae: 0.0536 - val_loss: 0.0046 - val_mae: 0.0497\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0043 - val_mae: 0.0482\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0044 - mae: 0.0500 - val_loss: 0.0036 - val_mae: 0.0457\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0035 - mae: 0.0451 - val_loss: 0.0034 - val_mae: 0.0437\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0034 - mae: 0.0446 - val_loss: 0.0033 - val_mae: 0.0426\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0033 - mae: 0.0432 - val_loss: 0.0033 - val_mae: 0.0421\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0032 - mae: 0.0428 - val_loss: 0.0032 - val_mae: 0.0420\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0032 - mae: 0.0428 - val_loss: 0.0031 - val_mae: 0.0418\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0031 - mae: 0.0423 - val_loss: 0.0030 - val_mae: 0.0418\n",
      "\n",
      "âœ… Model and scaler saved for site 4273.\n",
      "4321\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.1700 - mae: 0.3284 - val_loss: 0.0462 - val_mae: 0.1770\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0359 - mae: 0.1530 - val_loss: 0.0210 - val_mae: 0.1089\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0188 - mae: 0.1000 - val_loss: 0.0142 - val_mae: 0.0919\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0141 - mae: 0.0926 - val_loss: 0.0131 - val_mae: 0.0863\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0127 - mae: 0.0850 - val_loss: 0.0092 - val_mae: 0.0678\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0093 - mae: 0.0706 - val_loss: 0.0092 - val_mae: 0.0719\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0088 - mae: 0.0706 - val_loss: 0.0066 - val_mae: 0.0581\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0328 - mae: 0.0967 - val_loss: 0.0324 - val_mae: 0.1349\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0331 - mae: 0.1396 - val_loss: 0.0245 - val_mae: 0.1262\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0231 - mae: 0.1240 - val_loss: 0.0187 - val_mae: 0.1101\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0182 - mae: 0.1030 - val_loss: 0.0142 - val_mae: 0.0950\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0181 - mae: 0.1031 - val_loss: 0.0222 - val_mae: 0.1137\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0222 - mae: 0.1128 - val_loss: 0.0125 - val_mae: 0.0869\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0124 - mae: 0.0905 - val_loss: 0.0088 - val_mae: 0.0757\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0129 - mae: 0.0899 - val_loss: 0.0148 - val_mae: 0.0933\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0150 - mae: 0.0940 - val_loss: 0.0130 - val_mae: 0.0870\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0130 - mae: 0.0872 - val_loss: 0.0105 - val_mae: 0.0785\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0101 - mae: 0.0774 - val_loss: 0.0077 - val_mae: 0.0631\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0081 - mae: 0.0650 - val_loss: 0.0070 - val_mae: 0.0591\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0074 - mae: 0.0619 - val_loss: 0.0066 - val_mae: 0.0566\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0070 - mae: 0.0598 - val_loss: 0.0063 - val_mae: 0.0558\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0067 - mae: 0.0586 - val_loss: 0.0062 - val_mae: 0.0565\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0064 - mae: 0.0575 - val_loss: 0.0058 - val_mae: 0.0544\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0059 - mae: 0.0553 - val_loss: 0.0046 - val_mae: 0.0501\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0045 - mae: 0.0497 - val_loss: 0.0043 - val_mae: 0.0505\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0036 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0032 - mae: 0.0438 - val_loss: 0.0036 - val_mae: 0.0449\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0029 - mae: 0.0415 - val_loss: 0.0026 - val_mae: 0.0387\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0024 - mae: 0.0375 - val_loss: 0.0023 - val_mae: 0.0361\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0030 - mae: 0.0423 - val_loss: 0.0036 - val_mae: 0.0449\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0398 - val_loss: 0.0036 - val_mae: 0.0455\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0029 - mae: 0.0402 - val_loss: 0.0023 - val_mae: 0.0352\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0023 - mae: 0.0367 - val_loss: 0.0023 - val_mae: 0.0364\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0370 - val_loss: 0.0022 - val_mae: 0.0353\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0374 - val_loss: 0.0042 - val_mae: 0.0544\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0029 - val_mae: 0.0409\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0022 - val_mae: 0.0352\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0021 - mae: 0.0351 - val_loss: 0.0021 - val_mae: 0.0337\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0346 - val_loss: 0.0021 - val_mae: 0.0341\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0020 - mae: 0.0342 - val_loss: 0.0021 - val_mae: 0.0342\n",
      "\n",
      "âœ… Model and scaler saved for site 4321.\n",
      "4324\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1381 - mae: 0.2986 - val_loss: 0.0277 - val_mae: 0.1352\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0211 - mae: 0.1155 - val_loss: 0.0131 - val_mae: 0.0874\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0124 - mae: 0.0837 - val_loss: 0.0096 - val_mae: 0.0720\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0098 - mae: 0.0730 - val_loss: 0.0080 - val_mae: 0.0648\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0082 - mae: 0.0664 - val_loss: 0.0076 - val_mae: 0.0654\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0619 - val_loss: 0.0067 - val_mae: 0.0619\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0604 - val_loss: 0.0060 - val_mae: 0.0586\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0058 - mae: 0.0560 - val_loss: 0.0049 - val_mae: 0.0513\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0048 - mae: 0.0510 - val_loss: 0.0093 - val_mae: 0.0812\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0096 - mae: 0.0797 - val_loss: 0.0057 - val_mae: 0.0537\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0057 - mae: 0.0536 - val_loss: 0.0046 - val_mae: 0.0512\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0045 - mae: 0.0509 - val_loss: 0.0044 - val_mae: 0.0509\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0039 - mae: 0.0462 - val_loss: 0.0037 - val_mae: 0.0485\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0034 - mae: 0.0431 - val_loss: 0.0027 - val_mae: 0.0396\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0029 - mae: 0.0395 - val_loss: 0.0030 - val_mae: 0.0392\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0031 - mae: 0.0403 - val_loss: 0.0034 - val_mae: 0.0474\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0030 - mae: 0.0419 - val_loss: 0.0030 - val_mae: 0.0449\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0401 - val_loss: 0.0021 - val_mae: 0.0353\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0352 - val_loss: 0.0021 - val_mae: 0.0360\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0353 - val_loss: 0.0026 - val_mae: 0.0415\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0366 - val_loss: 0.0027 - val_mae: 0.0424\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0370 - val_loss: 0.0022 - val_mae: 0.0369\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0349 - val_loss: 0.0025 - val_mae: 0.0403\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0361 - val_loss: 0.0021 - val_mae: 0.0367\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0021 - mae: 0.0346 - val_loss: 0.0022 - val_mae: 0.0370\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0021 - mae: 0.0347 - val_loss: 0.0021 - val_mae: 0.0364\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0021 - mae: 0.0346 - val_loss: 0.0020 - val_mae: 0.0349\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0339 - val_loss: 0.0021 - val_mae: 0.0358\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0021 - mae: 0.0342 - val_loss: 0.0020 - val_mae: 0.0348\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0337 - val_loss: 0.0019 - val_mae: 0.0339\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0020 - val_mae: 0.0353\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0336 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0333 - val_loss: 0.0019 - val_mae: 0.0340\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0019 - val_mae: 0.0340\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0019 - mae: 0.0328 - val_loss: 0.0019 - val_mae: 0.0338\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0019 - mae: 0.0328 - val_loss: 0.0019 - val_mae: 0.0335\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0327 - val_loss: 0.0018 - val_mae: 0.0332\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0326 - val_loss: 0.0018 - val_mae: 0.0331\n",
      "\n",
      "âœ… Model and scaler saved for site 4324.\n",
      "4335\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.2364 - mae: 0.3968 - val_loss: 0.0503 - val_mae: 0.1968\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0483 - mae: 0.1852 - val_loss: 0.0339 - val_mae: 0.1535\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0285 - mae: 0.1403 - val_loss: 0.0202 - val_mae: 0.1113\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0173 - mae: 0.1026 - val_loss: 0.0156 - val_mae: 0.0950\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0141 - mae: 0.0894 - val_loss: 0.0125 - val_mae: 0.0819\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0777 - val_loss: 0.0106 - val_mae: 0.0744\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0099 - mae: 0.0732 - val_loss: 0.0098 - val_mae: 0.0739\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0092 - mae: 0.0712 - val_loss: 0.0085 - val_mae: 0.0670\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0082 - mae: 0.0665 - val_loss: 0.0073 - val_mae: 0.0601\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0590 - val_loss: 0.0065 - val_mae: 0.0603\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0058 - mae: 0.0547 - val_loss: 0.0054 - val_mae: 0.0532\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0051 - mae: 0.0518 - val_loss: 0.0048 - val_mae: 0.0502\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0050 - mae: 0.0523 - val_loss: 0.0043 - val_mae: 0.0489\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0042 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0464\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0040 - mae: 0.0465 - val_loss: 0.0035 - val_mae: 0.0450\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0037 - mae: 0.0453 - val_loss: 0.0034 - val_mae: 0.0437\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0036 - mae: 0.0435 - val_loss: 0.0031 - val_mae: 0.0408\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0033 - mae: 0.0417 - val_loss: 0.0032 - val_mae: 0.0431\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0034 - mae: 0.0421 - val_loss: 0.0036 - val_mae: 0.0432\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0033 - mae: 0.0417 - val_loss: 0.0036 - val_mae: 0.0441\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0031 - mae: 0.0404 - val_loss: 0.0031 - val_mae: 0.0408\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0030 - mae: 0.0396 - val_loss: 0.0029 - val_mae: 0.0384\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0030 - mae: 0.0394 - val_loss: 0.0026 - val_mae: 0.0373\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0031 - mae: 0.0397 - val_loss: 0.0034 - val_mae: 0.0419\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0032 - mae: 0.0408 - val_loss: 0.0026 - val_mae: 0.0369\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0031 - mae: 0.0400 - val_loss: 0.0026 - val_mae: 0.0371\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0031 - mae: 0.0399 - val_loss: 0.0025 - val_mae: 0.0364\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0031 - mae: 0.0399 - val_loss: 0.0024 - val_mae: 0.0363\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0030 - mae: 0.0397 - val_loss: 0.0024 - val_mae: 0.0364\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0029 - mae: 0.0391 - val_loss: 0.0024 - val_mae: 0.0359\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0389 - val_loss: 0.0024 - val_mae: 0.0365\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0390 - val_loss: 0.0024 - val_mae: 0.0358\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0029 - mae: 0.0391 - val_loss: 0.0024 - val_mae: 0.0357\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0386 - val_loss: 0.0024 - val_mae: 0.0357\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0387 - val_loss: 0.0024 - val_mae: 0.0358\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0029 - mae: 0.0387 - val_loss: 0.0024 - val_mae: 0.0356\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0385 - val_loss: 0.0024 - val_mae: 0.0357\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0029 - mae: 0.0384 - val_loss: 0.0024 - val_mae: 0.0355\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0382 - val_loss: 0.0023 - val_mae: 0.0355\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0028 - mae: 0.0382 - val_loss: 0.0023 - val_mae: 0.0355\n",
      "\n",
      "âœ… Model and scaler saved for site 4335.\n",
      "4812\n",
      "Epoch 1/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.2012 - mae: 0.3655 - val_loss: 0.0448 - val_mae: 0.1677\n",
      "Epoch 2/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0417 - mae: 0.1683 - val_loss: 0.0238 - val_mae: 0.1225\n",
      "Epoch 3/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0240 - mae: 0.1227 - val_loss: 0.0167 - val_mae: 0.0978\n",
      "Epoch 4/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0160 - mae: 0.0921 - val_loss: 0.0131 - val_mae: 0.0916\n",
      "Epoch 5/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0165 - mae: 0.1017 - val_loss: 0.0213 - val_mae: 0.1167\n",
      "Epoch 6/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0223 - mae: 0.1207 - val_loss: 0.0172 - val_mae: 0.1066\n",
      "Epoch 7/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0170 - mae: 0.1049 - val_loss: 0.0137 - val_mae: 0.0932\n",
      "Epoch 8/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0138 - mae: 0.0935 - val_loss: 0.0117 - val_mae: 0.0837\n",
      "Epoch 9/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0118 - mae: 0.0854 - val_loss: 0.0105 - val_mae: 0.0782\n",
      "Epoch 10/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0806 - val_loss: 0.0096 - val_mae: 0.0752\n",
      "Epoch 11/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0095 - mae: 0.0768 - val_loss: 0.0088 - val_mae: 0.0720\n",
      "Epoch 12/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0080 - val_mae: 0.0681\n",
      "Epoch 13/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0076 - mae: 0.0675 - val_loss: 0.0071 - val_mae: 0.0637\n",
      "Epoch 14/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0619 - val_loss: 0.0064 - val_mae: 0.0596\n",
      "Epoch 15/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0057 - mae: 0.0565 - val_loss: 0.0060 - val_mae: 0.0583\n",
      "Epoch 16/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0049 - mae: 0.0528 - val_loss: 0.0057 - val_mae: 0.0580\n",
      "Epoch 17/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0043 - mae: 0.0507 - val_loss: 0.0051 - val_mae: 0.0556\n",
      "Epoch 18/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0047 - val_mae: 0.0538\n",
      "Epoch 19/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0045 - val_mae: 0.0521\n",
      "Epoch 20/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0034 - mae: 0.0453 - val_loss: 0.0042 - val_mae: 0.0500\n",
      "Epoch 21/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0032 - mae: 0.0441 - val_loss: 0.0041 - val_mae: 0.0489\n",
      "Epoch 22/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0031 - mae: 0.0432 - val_loss: 0.0039 - val_mae: 0.0477\n",
      "Epoch 23/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0030 - mae: 0.0425 - val_loss: 0.0038 - val_mae: 0.0465\n",
      "Epoch 24/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0029 - mae: 0.0418 - val_loss: 0.0036 - val_mae: 0.0455\n",
      "Epoch 25/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0411 - val_loss: 0.0035 - val_mae: 0.0446\n",
      "Epoch 26/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0027 - mae: 0.0405 - val_loss: 0.0034 - val_mae: 0.0435\n",
      "Epoch 27/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0398 - val_loss: 0.0032 - val_mae: 0.0425\n",
      "Epoch 28/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0031 - val_mae: 0.0413\n",
      "Epoch 29/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0029 - val_mae: 0.0399\n",
      "Epoch 30/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0378 - val_loss: 0.0027 - val_mae: 0.0385\n",
      "Epoch 31/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 0.0027 - val_mae: 0.0377\n",
      "Epoch 32/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0362 - val_loss: 0.0026 - val_mae: 0.0376\n",
      "Epoch 33/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0359 - val_loss: 0.0026 - val_mae: 0.0371\n",
      "Epoch 34/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0022 - mae: 0.0357 - val_loss: 0.0026 - val_mae: 0.0368\n",
      "Epoch 35/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0355 - val_loss: 0.0025 - val_mae: 0.0365\n",
      "Epoch 36/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0353 - val_loss: 0.0025 - val_mae: 0.0362\n",
      "Epoch 37/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0350 - val_loss: 0.0025 - val_mae: 0.0362\n",
      "Epoch 38/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0022 - mae: 0.0349 - val_loss: 0.0025 - val_mae: 0.0358\n",
      "Epoch 39/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0021 - mae: 0.0346 - val_loss: 0.0025 - val_mae: 0.0358\n",
      "Epoch 40/40\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0021 - mae: 0.0345 - val_loss: 0.0024 - val_mae: 0.0355\n",
      "\n",
      "âœ… Model and scaler saved for site 4812.\n",
      "4821\n",
      "Epoch 1/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.2319 - mae: 0.3915 - val_loss: 0.0499 - val_mae: 0.1905\n",
      "Epoch 2/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0429 - mae: 0.1759 - val_loss: 0.0276 - val_mae: 0.1457\n",
      "Epoch 3/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0256 - mae: 0.1359 - val_loss: 0.0166 - val_mae: 0.1042\n",
      "Epoch 4/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0167 - mae: 0.1036 - val_loss: 0.0131 - val_mae: 0.0908\n",
      "Epoch 5/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0136 - mae: 0.0924 - val_loss: 0.0107 - val_mae: 0.0807\n",
      "Epoch 6/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0111 - mae: 0.0808 - val_loss: 0.0085 - val_mae: 0.0688\n",
      "Epoch 7/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0088 - mae: 0.0687 - val_loss: 0.0065 - val_mae: 0.0576\n",
      "Epoch 8/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0640 - val_loss: 0.0059 - val_mae: 0.0586\n",
      "Epoch 9/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0633 - val_loss: 0.0055 - val_mae: 0.0550\n",
      "Epoch 10/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0582 - val_loss: 0.0047 - val_mae: 0.0517\n",
      "Epoch 11/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0052 - mae: 0.0546 - val_loss: 0.0040 - val_mae: 0.0476\n",
      "Epoch 12/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0044 - mae: 0.0498 - val_loss: 0.0042 - val_mae: 0.0520\n",
      "Epoch 13/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0043 - mae: 0.0514 - val_loss: 0.0032 - val_mae: 0.0430\n",
      "Epoch 14/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0037 - mae: 0.0470 - val_loss: 0.0031 - val_mae: 0.0425\n",
      "Epoch 15/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0034 - mae: 0.0449 - val_loss: 0.0028 - val_mae: 0.0408\n",
      "Epoch 16/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 0.0025 - val_mae: 0.0378\n",
      "Epoch 17/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0415 - val_loss: 0.0024 - val_mae: 0.0376\n",
      "Epoch 18/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0390 - val_loss: 0.0021 - val_mae: 0.0351\n",
      "Epoch 19/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0022 - val_mae: 0.0370\n",
      "Epoch 20/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0389 - val_loss: 0.0019 - val_mae: 0.0335\n",
      "Epoch 21/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0361 - val_loss: 0.0023 - val_mae: 0.0388\n",
      "Epoch 22/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0029 - val_mae: 0.0433\n",
      "Epoch 23/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0031 - mae: 0.0431 - val_loss: 0.0022 - val_mae: 0.0361\n",
      "Epoch 24/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0024 - mae: 0.0376 - val_loss: 0.0018 - val_mae: 0.0316\n",
      "Epoch 25/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0021 - mae: 0.0349 - val_loss: 0.0017 - val_mae: 0.0310\n",
      "Epoch 26/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0344 - val_loss: 0.0017 - val_mae: 0.0305\n",
      "Epoch 27/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0343 - val_loss: 0.0017 - val_mae: 0.0302\n",
      "Epoch 28/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0341 - val_loss: 0.0017 - val_mae: 0.0301\n",
      "Epoch 29/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0338 - val_loss: 0.0017 - val_mae: 0.0299\n",
      "Epoch 30/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0337 - val_loss: 0.0017 - val_mae: 0.0297\n",
      "Epoch 31/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0020 - mae: 0.0335 - val_loss: 0.0016 - val_mae: 0.0295\n",
      "Epoch 32/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0333 - val_loss: 0.0016 - val_mae: 0.0294\n",
      "Epoch 33/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0019 - mae: 0.0332 - val_loss: 0.0016 - val_mae: 0.0293\n",
      "Epoch 34/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0330 - val_loss: 0.0016 - val_mae: 0.0292\n",
      "Epoch 35/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0019 - mae: 0.0329 - val_loss: 0.0016 - val_mae: 0.0291\n",
      "Epoch 36/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0328 - val_loss: 0.0016 - val_mae: 0.0290\n",
      "Epoch 37/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0327 - val_loss: 0.0016 - val_mae: 0.0289\n",
      "Epoch 38/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0019 - mae: 0.0327 - val_loss: 0.0016 - val_mae: 0.0289\n",
      "Epoch 39/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0325 - val_loss: 0.0016 - val_mae: 0.0288\n",
      "Epoch 40/40\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0324 - val_loss: 0.0016 - val_mae: 0.0288\n",
      "\n",
      "âœ… Model and scaler saved for site 4821.\n"
     ]
    }
   ],
   "source": [
    "for id in sites:\n",
    "    print(id)\n",
    "    site_data = final_dataset[final_dataset['site_id'] == id].sort_values(\"timestamp\")\n",
    "    \n",
    "    replace_outliers_iqr(site_data, 'volume')\n",
    "    \n",
    "    # Scale Data\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    site_data['volume'] = scaler.fit_transform(site_data[['volume']])\n",
    "    \n",
    "    site_data = np.array(site_data['volume'])\n",
    "    \n",
    "    x, y = generating_sequences(site_data)\n",
    "    \n",
    "    # Split into training and testing\n",
    "    split = int(len(x) * 0.8)\n",
    "    X_train, X_test = x[:split], x[split:]\n",
    "    Y_train, Y_test = y[:split], y[split:]\n",
    "    \n",
    "    # Define the LSTM model\n",
    "    model = Sequential([\n",
    "        Input(shape=(96, 1)),\n",
    "        LSTM(64, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        X_train, Y_train,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        epochs=40,\n",
    "        batch_size=96\n",
    "        # callbacks = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    )\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(f\"../models/LSTM_model/models/lstm_model_site_{id}.keras\")  # New format\n",
    "\n",
    "    joblib.dump(scaler, f\"../models/LSTM_model/scalers/scaler_site_{id}.save\")\n",
    "\n",
    "    print(f\"\\nâœ… Model and scaler saved for site {id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54596e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš¦ Loading model and scaler for site 970...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Accuracy: 75.65%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "113.42299\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 2000...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Accuracy: 50.43%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "231.74132\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 2200...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Accuracy: 58.03%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "68.67694\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 2820...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Accuracy: 78.38%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "47.959145\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 2825...\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x35a970d60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Accuracy: 94.73%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "35.16667\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 2827...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x358d1cae0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Accuracy: 75.39%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "104.64549\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 2846...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Accuracy: 43.32%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "134.05196\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3001...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Accuracy: 49.30%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "180.06134\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3002...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Accuracy: 45.74%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "82.35804\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3120...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Accuracy: 81.27%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "194.3304\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3122...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Accuracy: 59.71%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "61.70283\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3126...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Accuracy: 62.03%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "86.422195\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3127...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Accuracy: 45.78%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "57.14396\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3180...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Accuracy: 13.82%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "33.30538\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3662...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Accuracy: 97.96%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "169.14847\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3682...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Accuracy: 12.95%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "139.2872\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3685...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Accuracy: -14.60%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "310.12308\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3804...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Accuracy: -3.19%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "84.69409\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3812...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Accuracy: 34.41%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "50.31385\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4030...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Accuracy: 78.58%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "87.95439\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4032...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Accuracy: 61.60%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "89.973175\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4034...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Accuracy: 70.47%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "99.50734\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4035...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Accuracy: 87.96%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "112.45541\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4040...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Accuracy: 80.42%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "154.67197\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4043...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Accuracy: 92.43%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "136.74399\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4051...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Accuracy: 35.72%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "38.09528\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4057...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Accuracy: 29.54%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "41.768173\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4063...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Accuracy: 93.65%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "37.552914\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4262...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Accuracy: 91.05%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "46.505474\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4263...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Accuracy: 75.11%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "109.85084\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4264...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Accuracy: 89.41%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "97.838554\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4266...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Accuracy: 97.73%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "100.8175\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4270...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Accuracy: 99.12%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "104.26885\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4272...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Accuracy: 20.90%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "116.10996\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4273...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Accuracy: 90.67%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "39.550045\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4321...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Accuracy: 49.91%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "67.500374\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4324...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Accuracy: 83.99%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "43.183395\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4335...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Accuracy: 21.72%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "48.673195\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4812...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Accuracy: 59.51%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "67.43379\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4821...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Accuracy: 75.91%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "78.96896\n"
     ]
    }
   ],
   "source": [
    "# Replace outliers using IQR\n",
    "replace_outliers_iqr(final_dataset, 'volume')\n",
    "\n",
    "for id in sites:\n",
    "    # Load the model and scaler\n",
    "    model = load_model(f\"../models/LSTM_model/models/lstm_model_site_{id}.keras\")\n",
    "    scaler = joblib.load(f\"../models/LSTM_model/scalers/scaler_site_{id}.save\")\n",
    "    print(f\"\\nğŸš¦ Loading model and scaler for site {id}...\")\n",
    "    \n",
    "    # Filter data for this site\n",
    "    site_data = final_dataset[final_dataset['site_id'] == id].sort_values(\"timestamp\")\n",
    "    \n",
    "    site_data['volume'] = scaler.transform(site_data[['volume']])\n",
    "    \n",
    "    # Predictions for the next time step\n",
    "    last_site_data = np.array(site_data['volume'][-96:]).reshape(-1, 96, 1)\n",
    "   \n",
    "    # Make predictions on the test set\n",
    "    last_test_site_data = np.array(site_data['volume'][:97])\n",
    "    \n",
    "    testX, testY = generating_sequences(last_test_site_data)\n",
    "    \n",
    "    testX = testX.reshape(-1, 96, 1)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(testX)\n",
    "\n",
    "    # Reverse scaling if necessary\n",
    "    y_test_actual = scaler.inverse_transform(testY.reshape(-1, 1))\n",
    "    y_pred_actual = scaler.inverse_transform(y_pred)\n",
    "\n",
    "    smape = 100 * abs(y_pred_actual - y_test_actual) / ((abs(y_pred_actual) + abs(y_test_actual)) / 2)\n",
    "    accuracy = 100 - smape\n",
    "    accuracy = np.mean(accuracy)\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    pred_scaled = model.predict(last_site_data)\n",
    "    pred_volume = scaler.inverse_transform(pred_scaled)[0][0]\n",
    "\n",
    "    # print(f\"Predicted volume for the next time step: {pred_volume:.2f}\")\n",
    "    # print(pred_scaled)\n",
    "    print(pred_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3844b0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(site_data['timestamp'], site_data['volume'], label='Actual Volume', color='blue')\n",
    "plt.plot(site_data['timestamp'][:len(y_pred)], pred_volume, label='Predicted Volume', color='red')\n",
    "\n",
    "# plt.plot(site_data['timestamp'], y_pred_actual, label='Predicted Volume', color='red')\n",
    "plt.title(f'Volume Prediction for Site {id}')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Volume')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef4cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "traffic_based_guidance_solution",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
