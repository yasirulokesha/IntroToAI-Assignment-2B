{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7378b7",
   "metadata": {},
   "source": [
    "# Traffic-based Route Guidance Solution\n",
    "\n",
    "## Import the Dependancies and Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34243419",
   "metadata": {
    "id": "34243419"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70369816",
   "metadata": {
    "id": "70369816"
   },
   "source": [
    "## Data Preprocessing & Analyzing\n",
    "\n",
    "1. Load the VicRoads Boroondara dataset (.csv)\n",
    "\n",
    "2. Clean and preprocess:\n",
    "    * Convert timestamps\n",
    "\n",
    "    * Handle missing values\n",
    "\n",
    "    * Normalize/scale traffic flow values\n",
    "\n",
    "3. Reshape for time-series forecasting (e.g., sequences of past 1-2 hours to predict next 15-min slot)\n",
    "\n",
    "### Import the Dataset for analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eac413ca",
   "metadata": {
    "id": "eac413ca",
    "outputId": "f405c51b-e0cf-4cbe-b075-4dbc952cbbcf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_dataset = pd.read_csv('https://raw.githubusercontent.com/yasirulokesha/IntroToAI-Assignment-2B/refs/heads/main/TBRGS/data/raw/Scats%20Data%20October%202006.csv', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb1782",
   "metadata": {},
   "source": [
    "### Cluster and Make the Train and Test the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7_Vx9OK6Hzgw",
   "metadata": {
    "id": "7_Vx9OK6Hzgw"
   },
   "outputs": [],
   "source": [
    "# Create time mapping for V00â€“V95 (15-minute intervals)\n",
    "time_labels = [f\"{h:02}:{m:02}:00\" for h in range(24) for m in range(0, 60, 15)]\n",
    "v_columns = [f\"V{str(i).zfill(2)}\" for i in range(96)]\n",
    "time_map = dict(zip(v_columns, time_labels))\n",
    "\n",
    "# Melt the V columns into long format\n",
    "df_melted = main_dataset.melt(\n",
    "    id_vars=[\"SCATS Number\", \"Location\", \"Date\"],\n",
    "    value_vars=v_columns,\n",
    "    var_name=\"time_code\",\n",
    "    value_name=\"volume\"\n",
    ")\n",
    "\n",
    "# Map time codes to actual time strings\n",
    "df_melted['time_str'] = df_melted['time_code'].map(time_map)\n",
    "\n",
    "# Combine Date and Time into a full timestamp\n",
    "df_melted['timestamp'] = pd.to_datetime(df_melted['Date'] + ' ' + df_melted['time_str'], dayfirst=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_melted = df_melted.rename(columns={\n",
    "    \"SCATS Number\": \"site_id\",\n",
    "    \"Location\": \"location\"\n",
    "})\n",
    "\n",
    "# Select and reorder important columns\n",
    "df_traffic = df_melted[[\"site_id\", \"location\", \"timestamp\", \"volume\"]]\n",
    "\n",
    "# ğŸ” AGGREGATE: Sum volume over all directions at each site per timestamp\n",
    "final_dataset = df_melted.groupby(['site_id', 'timestamp'])['volume'].sum().reset_index()\n",
    "\n",
    "sites = final_dataset['site_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca94c7",
   "metadata": {},
   "source": [
    "### Scaling the dataset using MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c2600",
   "metadata": {},
   "source": [
    "### Breakdown the dataset for unique sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb038e7",
   "metadata": {},
   "source": [
    "### Data processing for ML\n",
    "\n",
    "#### Create Time Series Sequences for Training and Testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4a35749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for creating sequences\n",
    "def create_sequences(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd61da",
   "metadata": {},
   "source": [
    "### Make the unique sequences for different sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63bf9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_sequences(data_set):\n",
    "    x, y = create_sequences(data_set, 96)\n",
    "    x = x.reshape(-1, 96, 1)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e44ab",
   "metadata": {},
   "source": [
    "### Drop Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "18ccd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace outliers using IQR\n",
    "def replace_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)  # First quartile (25th percentile)\n",
    "    Q3 = df[column].quantile(0.75)  # Third quartile (75th percentile)\n",
    "    IQR = Q3 - Q1  # Interquartile range\n",
    "\n",
    "    # Define bounds for outliers\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Replace outliers with the median\n",
    "    median = df[column].median()\n",
    "    df[column] = df[column].apply(lambda x: median if x < lower_bound or x > upper_bound else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277b0f53",
   "metadata": {},
   "source": [
    "## - Generating the models and save for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae54790a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.2023 - mae: 0.3558 - val_loss: 0.0461 - val_mae: 0.1802\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0397 - mae: 0.1638 - val_loss: 0.0218 - val_mae: 0.1142\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0206 - mae: 0.1124 - val_loss: 0.0154 - val_mae: 0.0967\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0154 - mae: 0.0980 - val_loss: 0.0114 - val_mae: 0.0799\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0115 - mae: 0.0818 - val_loss: 0.0147 - val_mae: 0.1019\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0168 - mae: 0.1063 - val_loss: 0.0142 - val_mae: 0.0956\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0131 - mae: 0.0904 - val_loss: 0.0096 - val_mae: 0.0761\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0093 - mae: 0.0750 - val_loss: 0.0076 - val_mae: 0.0659\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0075 - mae: 0.0652 - val_loss: 0.0062 - val_mae: 0.0604\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0062 - mae: 0.0594 - val_loss: 0.0052 - val_mae: 0.0570\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0562 - val_loss: 0.0045 - val_mae: 0.0530\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0045 - mae: 0.0523 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0035 - val_mae: 0.0457\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0035 - mae: 0.0459 - val_loss: 0.0031 - val_mae: 0.0430\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0031 - mae: 0.0425 - val_loss: 0.0027 - val_mae: 0.0399\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0027 - mae: 0.0403 - val_loss: 0.0023 - val_mae: 0.0365\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0026 - mae: 0.0390 - val_loss: 0.0022 - val_mae: 0.0357\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0023 - mae: 0.0366 - val_loss: 0.0020 - val_mae: 0.0336\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0022 - mae: 0.0361 - val_loss: 0.0022 - val_mae: 0.0355\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0371 - val_loss: 0.0024 - val_mae: 0.0357\n",
      "\n",
      "âœ… Model and scaler saved for site 970.\n",
      "2000\n",
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1690 - mae: 0.3264 - val_loss: 0.0454 - val_mae: 0.1787\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0414 - mae: 0.1706 - val_loss: 0.0262 - val_mae: 0.1355\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0278 - mae: 0.1364 - val_loss: 0.0173 - val_mae: 0.1060\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0191 - mae: 0.1103 - val_loss: 0.0131 - val_mae: 0.0916\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0157 - mae: 0.1001 - val_loss: 0.0181 - val_mae: 0.1077\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0202 - mae: 0.1142 - val_loss: 0.0144 - val_mae: 0.1008\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0153 - mae: 0.1044 - val_loss: 0.0106 - val_mae: 0.0841\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0108 - mae: 0.0859 - val_loss: 0.0078 - val_mae: 0.0707\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 71.0801 - mae: 0.1862 - val_loss: 0.0310 - val_mae: 0.1384\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0495 - mae: 0.1747 - val_loss: 0.0724 - val_mae: 0.2222\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0722 - mae: 0.2150 - val_loss: 0.0691 - val_mae: 0.2134\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0675 - mae: 0.2043 - val_loss: 0.0629 - val_mae: 0.2011\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0615 - mae: 0.1932 - val_loss: 0.0572 - val_mae: 0.1909\n",
      "\n",
      "âœ… Model and scaler saved for site 2000.\n",
      "2200\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.2338 - mae: 0.3876 - val_loss: 0.0524 - val_mae: 0.1910\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0409 - mae: 0.1631 - val_loss: 0.0182 - val_mae: 0.0943\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0168 - mae: 0.0880 - val_loss: 0.0131 - val_mae: 0.0913\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0127 - mae: 0.0878 - val_loss: 0.0096 - val_mae: 0.0722\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0108 - mae: 0.0783 - val_loss: 0.0110 - val_mae: 0.0813\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0103 - mae: 0.0762 - val_loss: 0.0081 - val_mae: 0.0679\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0085 - mae: 0.0702 - val_loss: 0.0110 - val_mae: 0.0873\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0096 - mae: 0.0773 - val_loss: 0.0080 - val_mae: 0.0710\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0081 - mae: 0.0688 - val_loss: 0.0101 - val_mae: 0.0835\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0090 - mae: 0.0740 - val_loss: 0.0059 - val_mae: 0.0559\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0060 - mae: 0.0573 - val_loss: 0.0048 - val_mae: 0.0518\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0051 - mae: 0.0536 - val_loss: 0.0052 - val_mae: 0.0562\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0045 - mae: 0.0509 - val_loss: 0.0039 - val_mae: 0.0495\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0038 - mae: 0.0472 - val_loss: 0.0030 - val_mae: 0.0443\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0033 - val_mae: 0.0474\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0033 - mae: 0.0433 - val_loss: 0.0039 - val_mae: 0.0469\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0040 - mae: 0.0468 - val_loss: 0.0035 - val_mae: 0.0450\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0036 - mae: 0.0454 - val_loss: 0.0023 - val_mae: 0.0354\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0027 - mae: 0.0394 - val_loss: 0.0022 - val_mae: 0.0368\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0023 - val_mae: 0.0385\n",
      "\n",
      "âœ… Model and scaler saved for site 2200.\n",
      "2820\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.1452 - mae: 0.2992 - val_loss: 0.0235 - val_mae: 0.1318\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0239 - mae: 0.1334 - val_loss: 0.0127 - val_mae: 0.0920\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0149 - mae: 0.0965 - val_loss: 0.0075 - val_mae: 0.0674\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0095 - mae: 0.0746 - val_loss: 0.0065 - val_mae: 0.0641\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0078 - mae: 0.0662 - val_loss: 0.0060 - val_mae: 0.0621\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0633 - val_loss: 0.0052 - val_mae: 0.0568\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0058 - mae: 0.0569 - val_loss: 0.0051 - val_mae: 0.0571\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0051 - mae: 0.0541 - val_loss: 0.0049 - val_mae: 0.0567\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0045 - mae: 0.0503 - val_loss: 0.0042 - val_mae: 0.0520\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0047 - mae: 0.0514 - val_loss: 0.0041 - val_mae: 0.0517\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0043 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0510\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0043 - mae: 0.0485 - val_loss: 0.0037 - val_mae: 0.0489\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0040 - mae: 0.0464 - val_loss: 0.0038 - val_mae: 0.0490\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0036 - mae: 0.0443 - val_loss: 0.0032 - val_mae: 0.0433\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0040 - mae: 0.0464 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0043 - mae: 0.0489 - val_loss: 0.0034 - val_mae: 0.0462\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0039 - mae: 0.0459 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0037 - mae: 0.0451 - val_loss: 0.0034 - val_mae: 0.0465\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0036 - mae: 0.0444 - val_loss: 0.0032 - val_mae: 0.0454\n",
      "\n",
      "âœ… Model and scaler saved for site 2820.\n",
      "2825\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1263 - mae: 0.2797 - val_loss: 0.0308 - val_mae: 0.1422\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0271 - mae: 0.1297 - val_loss: 0.0177 - val_mae: 0.0998\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0177 - mae: 0.0982 - val_loss: 0.0119 - val_mae: 0.0801\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0130 - mae: 0.0870 - val_loss: 0.0097 - val_mae: 0.0735\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0114 - mae: 0.0812 - val_loss: 0.0098 - val_mae: 0.0749\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0101 - mae: 0.0740 - val_loss: 0.0077 - val_mae: 0.0663\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0081 - mae: 0.0678 - val_loss: 0.0131 - val_mae: 0.0959\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0154 - mae: 0.0971 - val_loss: 0.0129 - val_mae: 0.0866\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0126 - mae: 0.0866 - val_loss: 0.0089 - val_mae: 0.0705\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0094 - mae: 0.0725 - val_loss: 0.0076 - val_mae: 0.0636\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0082 - mae: 0.0665 - val_loss: 0.0069 - val_mae: 0.0608\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0075 - mae: 0.0638 - val_loss: 0.0063 - val_mae: 0.0589\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0610 - val_loss: 0.0057 - val_mae: 0.0562\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0061 - mae: 0.0581 - val_loss: 0.0058 - val_mae: 0.0604\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0050 - mae: 0.0504 - val_loss: 0.0037 - val_mae: 0.0438\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0050 - mae: 0.0503 - val_loss: 0.0043 - val_mae: 0.0458\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0044 - mae: 0.0471 - val_loss: 0.0037 - val_mae: 0.0454\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0037 - mae: 0.0436 - val_loss: 0.0037 - val_mae: 0.0466\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0034 - mae: 0.0435 - val_loss: 0.0036 - val_mae: 0.0465\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0033 - mae: 0.0427 - val_loss: 0.0032 - val_mae: 0.0428\n",
      "\n",
      "âœ… Model and scaler saved for site 2825.\n",
      "2827\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1883 - mae: 0.3480 - val_loss: 0.0348 - val_mae: 0.1613\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0376 - mae: 0.1633 - val_loss: 0.0220 - val_mae: 0.1273\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0222 - mae: 0.1253 - val_loss: 0.0122 - val_mae: 0.0878\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0132 - mae: 0.0901 - val_loss: 0.0085 - val_mae: 0.0759\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0092 - mae: 0.0775 - val_loss: 0.0069 - val_mae: 0.0681\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0072 - mae: 0.0676 - val_loss: 0.0051 - val_mae: 0.0573\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0052 - mae: 0.0562 - val_loss: 0.0043 - val_mae: 0.0527\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0045 - mae: 0.0518 - val_loss: 0.0033 - val_mae: 0.0443\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0037 - mae: 0.0469 - val_loss: 0.0027 - val_mae: 0.0397\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 0.0033 - val_mae: 0.0485\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0027 - mae: 0.0406 - val_loss: 0.0025 - val_mae: 0.0396\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0029 - mae: 0.0419 - val_loss: 0.0025 - val_mae: 0.0383\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0406 - val_loss: 0.0023 - val_mae: 0.0399\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0351 - val_loss: 0.0024 - val_mae: 0.0420\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0355 - val_loss: 0.0030 - val_mae: 0.0477\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 0.0016 - val_mae: 0.0310\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0344 - val_loss: 0.0015 - val_mae: 0.0298\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0327 - val_loss: 0.0023 - val_mae: 0.0416\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0021 - mae: 0.0355 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0314 - val_loss: 0.0016 - val_mae: 0.0323\n",
      "\n",
      "âœ… Model and scaler saved for site 2827.\n",
      "2846\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1152 - mae: 0.2627 - val_loss: 0.0303 - val_mae: 0.1412\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0291 - mae: 0.1337 - val_loss: 0.0216 - val_mae: 0.1162\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0212 - mae: 0.1130 - val_loss: 0.0144 - val_mae: 0.0880\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0145 - mae: 0.0898 - val_loss: 0.0120 - val_mae: 0.0839\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0121 - mae: 0.0838 - val_loss: 0.0102 - val_mae: 0.0806\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0112 - mae: 0.0820 - val_loss: 0.0090 - val_mae: 0.0713\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0091 - mae: 0.0698 - val_loss: 0.0059 - val_mae: 0.0598\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0062 - mae: 0.0566 - val_loss: 0.0043 - val_mae: 0.0516\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0123 - mae: 0.0800 - val_loss: 0.0148 - val_mae: 0.0894\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0142 - mae: 0.0910 - val_loss: 0.0111 - val_mae: 0.0850\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0114 - mae: 0.0844 - val_loss: 0.0093 - val_mae: 0.0736\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0098 - mae: 0.0744 - val_loss: 0.0080 - val_mae: 0.0668\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0087 - mae: 0.0685 - val_loss: 0.0071 - val_mae: 0.0612\n",
      "\n",
      "âœ… Model and scaler saved for site 2846.\n",
      "3001\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.1294 - mae: 0.2957 - val_loss: 0.0333 - val_mae: 0.1556\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0257 - mae: 0.1301 - val_loss: 0.0208 - val_mae: 0.1181\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0185 - mae: 0.1079 - val_loss: 0.0167 - val_mae: 0.1006\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0152 - mae: 0.0935 - val_loss: 0.0143 - val_mae: 0.0907\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0131 - mae: 0.0874 - val_loss: 0.0132 - val_mae: 0.0874\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0119 - mae: 0.0839 - val_loss: 0.0121 - val_mae: 0.0815\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 462250.6562 - mae: 19.7408 - val_loss: 0.0194 - val_mae: 0.0991\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0217 - mae: 0.1066 - val_loss: 0.0268 - val_mae: 0.1177\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0260 - mae: 0.1183 - val_loss: 0.0257 - val_mae: 0.1145\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0233 - mae: 0.1118 - val_loss: 0.0131 - val_mae: 0.0894\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0121 - mae: 0.0837 - val_loss: 0.0122 - val_mae: 0.0839\n",
      "\n",
      "âœ… Model and scaler saved for site 3001.\n",
      "3002\n",
      "Epoch 1/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.2447 - mae: 0.4070 - val_loss: 0.0696 - val_mae: 0.2048\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0582 - mae: 0.1989 - val_loss: 0.0288 - val_mae: 0.1445\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0293 - mae: 0.1395 - val_loss: 0.0160 - val_mae: 0.0872\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0167 - mae: 0.0901 - val_loss: 0.0144 - val_mae: 0.0990\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0166 - mae: 0.1027 - val_loss: 0.0135 - val_mae: 0.0932\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0138 - mae: 0.0901 - val_loss: 0.0106 - val_mae: 0.0787\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0108 - mae: 0.0786 - val_loss: 0.0093 - val_mae: 0.0758\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0092 - mae: 0.0734 - val_loss: 0.0078 - val_mae: 0.0700\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0074 - mae: 0.0658 - val_loss: 0.0135 - val_mae: 0.0987\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0155 - mae: 0.1032 - val_loss: 0.0151 - val_mae: 0.1038\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0152 - mae: 0.1018 - val_loss: 0.0101 - val_mae: 0.0820\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0100 - mae: 0.0795 - val_loss: 0.0067 - val_mae: 0.0578\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0072 - mae: 0.0648 - val_loss: 0.0060 - val_mae: 0.0608\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0060 - mae: 0.0591 - val_loss: 0.0054 - val_mae: 0.0572\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0618 - val_loss: 0.0094 - val_mae: 0.0786\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0105 - mae: 0.0824 - val_loss: 0.0080 - val_mae: 0.0689\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0084 - mae: 0.0700 - val_loss: 0.0063 - val_mae: 0.0598\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0065 - mae: 0.0610 - val_loss: 0.0050 - val_mae: 0.0526\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0050 - mae: 0.0533 - val_loss: 0.0043 - val_mae: 0.0482\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0043 - mae: 0.0496 - val_loss: 0.0037 - val_mae: 0.0446\n",
      "\n",
      "âœ… Model and scaler saved for site 3002.\n",
      "3120\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1991 - mae: 0.3667 - val_loss: 0.0375 - val_mae: 0.1580\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0302 - mae: 0.1399 - val_loss: 0.0189 - val_mae: 0.1089\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0181 - mae: 0.1051 - val_loss: 0.0122 - val_mae: 0.0834\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0125 - mae: 0.0859 - val_loss: 0.0110 - val_mae: 0.0841\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0109 - mae: 0.0835 - val_loss: 0.0073 - val_mae: 0.0661\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0071 - mae: 0.0643 - val_loss: 0.0043 - val_mae: 0.0502\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0106 - mae: 0.0806 - val_loss: 0.0114 - val_mae: 0.0864\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0108 - mae: 0.0835 - val_loss: 0.0065 - val_mae: 0.0631\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0064 - mae: 0.0628 - val_loss: 0.0047 - val_mae: 0.0524\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0047 - mae: 0.0532 - val_loss: 0.0036 - val_mae: 0.0474\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0029 - val_mae: 0.0430\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0027 - val_mae: 0.0396\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0027 - mae: 0.0403 - val_loss: 0.0026 - val_mae: 0.0390\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0026 - mae: 0.0393 - val_loss: 0.0024 - val_mae: 0.0369\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0024 - mae: 0.0380 - val_loss: 0.0024 - val_mae: 0.0373\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0024 - mae: 0.0377 - val_loss: 0.0025 - val_mae: 0.0383\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0024 - mae: 0.0379 - val_loss: 0.0022 - val_mae: 0.0353\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.0022 - val_mae: 0.0357\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0022 - mae: 0.0361 - val_loss: 0.0021 - val_mae: 0.0362\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0022 - mae: 0.0360 - val_loss: 0.0022 - val_mae: 0.0374\n",
      "\n",
      "âœ… Model and scaler saved for site 3120.\n",
      "3122\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.2399 - mae: 0.3827 - val_loss: 0.0344 - val_mae: 0.1551\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0337 - mae: 0.1508 - val_loss: 0.0213 - val_mae: 0.1172\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0213 - mae: 0.1146 - val_loss: 0.0141 - val_mae: 0.0933\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0152 - mae: 0.0973 - val_loss: 0.0137 - val_mae: 0.0954\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0142 - mae: 0.0957 - val_loss: 0.0099 - val_mae: 0.0769\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0107 - mae: 0.0801 - val_loss: 0.0121 - val_mae: 0.0914\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0122 - mae: 0.0908 - val_loss: 0.0087 - val_mae: 0.0740\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0086 - mae: 0.0714 - val_loss: 0.0059 - val_mae: 0.0599\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0061 - mae: 0.0618 - val_loss: 0.0052 - val_mae: 0.0569\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0574 - val_loss: 0.0041 - val_mae: 0.0502\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0044 - mae: 0.0531 - val_loss: 0.0036 - val_mae: 0.0470\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0032 - val_mae: 0.0441\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0034 - mae: 0.0464 - val_loss: 0.0031 - val_mae: 0.0425\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0033 - mae: 0.0450 - val_loss: 0.0027 - val_mae: 0.0402\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0029 - mae: 0.0423 - val_loss: 0.0026 - val_mae: 0.0387\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0029 - mae: 0.0417 - val_loss: 0.0024 - val_mae: 0.0374\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0027 - mae: 0.0402 - val_loss: 0.0022 - val_mae: 0.0362\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0022 - val_mae: 0.0354\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0021 - val_mae: 0.0343\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0024 - mae: 0.0379 - val_loss: 0.0020 - val_mae: 0.0339\n",
      "\n",
      "âœ… Model and scaler saved for site 3122.\n",
      "3126\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1165 - mae: 0.2709 - val_loss: 0.0268 - val_mae: 0.1339\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0271 - mae: 0.1331 - val_loss: 0.0200 - val_mae: 0.1115\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0197 - mae: 0.1090 - val_loss: 0.0135 - val_mae: 0.0874\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0144 - mae: 0.0928 - val_loss: 0.0111 - val_mae: 0.0821\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0119 - mae: 0.0858 - val_loss: 0.0083 - val_mae: 0.0702\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0091 - mae: 0.0726 - val_loss: 0.0063 - val_mae: 0.0581\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0072 - mae: 0.0633 - val_loss: 0.0095 - val_mae: 0.0784\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0092 - mae: 0.0744 - val_loss: 0.0058 - val_mae: 0.0551\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0064 - mae: 0.0590 - val_loss: 0.0043 - val_mae: 0.0484\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0047 - mae: 0.0513 - val_loss: 0.0031 - val_mae: 0.0432\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0037 - mae: 0.0459 - val_loss: 0.0025 - val_mae: 0.0389\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0035 - mae: 0.0439 - val_loss: 0.0025 - val_mae: 0.0380\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0031 - mae: 0.0412 - val_loss: 0.0024 - val_mae: 0.0391\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0022 - val_mae: 0.0353\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0028 - mae: 0.0388 - val_loss: 0.0021 - val_mae: 0.0344\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0027 - mae: 0.0381 - val_loss: 0.0020 - val_mae: 0.0335\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0025 - mae: 0.0365 - val_loss: 0.0019 - val_mae: 0.0324\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0024 - mae: 0.0354 - val_loss: 0.0019 - val_mae: 0.0322\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0031 - mae: 0.0402 - val_loss: 0.0034 - val_mae: 0.0425\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0040 - mae: 0.0472 - val_loss: 0.0027 - val_mae: 0.0409\n",
      "\n",
      "âœ… Model and scaler saved for site 3126.\n",
      "3127\n",
      "Epoch 1/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.2515 - mae: 0.4067 - val_loss: 0.0555 - val_mae: 0.2025\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0523 - mae: 0.1924 - val_loss: 0.0229 - val_mae: 0.1206\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0240 - mae: 0.1126 - val_loss: 0.0144 - val_mae: 0.0902\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0162 - mae: 0.0933 - val_loss: 0.0104 - val_mae: 0.0793\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0137 - mae: 0.0881 - val_loss: 0.0196 - val_mae: 0.1097\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0225 - mae: 0.1167 - val_loss: 0.0136 - val_mae: 0.0905\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0157 - mae: 0.0926 - val_loss: 0.0107 - val_mae: 0.0763\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0128 - mae: 0.0821 - val_loss: 0.0093 - val_mae: 0.0707\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0113 - mae: 0.0788 - val_loss: 0.0085 - val_mae: 0.0691\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0103 - mae: 0.0763 - val_loss: 0.0079 - val_mae: 0.0669\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0094 - mae: 0.0724 - val_loss: 0.0072 - val_mae: 0.0634\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0084 - mae: 0.0675 - val_loss: 0.0063 - val_mae: 0.0586\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0073 - mae: 0.0620 - val_loss: 0.0054 - val_mae: 0.0551\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0062 - mae: 0.0581 - val_loss: 0.0067 - val_mae: 0.0678\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0570 - val_loss: 0.0044 - val_mae: 0.0531\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0048 - mae: 0.0522 - val_loss: 0.0037 - val_mae: 0.0488\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0045 - mae: 0.0515 - val_loss: 0.0041 - val_mae: 0.0437\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0045 - mae: 0.0484 - val_loss: 0.0045 - val_mae: 0.0537\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0045 - mae: 0.0501 - val_loss: 0.0039 - val_mae: 0.0513\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0033 - mae: 0.0440 - val_loss: 0.0029 - val_mae: 0.0406\n",
      "\n",
      "âœ… Model and scaler saved for site 3127.\n",
      "3180\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.1288 - mae: 0.2802 - val_loss: 0.0322 - val_mae: 0.1479\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0266 - mae: 0.1291 - val_loss: 0.0167 - val_mae: 0.0916\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0156 - mae: 0.0872 - val_loss: 0.0114 - val_mae: 0.0772\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0114 - mae: 0.0787 - val_loss: 0.0102 - val_mae: 0.0764\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0100 - mae: 0.0742 - val_loss: 0.0082 - val_mae: 0.0655\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0088 - mae: 0.0694 - val_loss: 0.0079 - val_mae: 0.0663\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0079 - mae: 0.0659 - val_loss: 0.0063 - val_mae: 0.0594\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0603 - val_loss: 0.0107 - val_mae: 0.0849\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0123 - mae: 0.0865 - val_loss: 0.0098 - val_mae: 0.0722\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0093 - mae: 0.0679 - val_loss: 0.0074 - val_mae: 0.0589\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0074 - mae: 0.0597 - val_loss: 0.0065 - val_mae: 0.0558\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0065 - mae: 0.0564 - val_loss: 0.0057 - val_mae: 0.0521\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0521 - val_loss: 0.0049 - val_mae: 0.0478\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0049 - mae: 0.0483 - val_loss: 0.0041 - val_mae: 0.0443\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0041 - mae: 0.0470 - val_loss: 0.0038 - val_mae: 0.0452\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0041 - mae: 0.0465 - val_loss: 0.0035 - val_mae: 0.0434\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0033 - mae: 0.0423 - val_loss: 0.0033 - val_mae: 0.0411\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0034 - mae: 0.0424 - val_loss: 0.0035 - val_mae: 0.0456\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0035 - mae: 0.0458 - val_loss: 0.0030 - val_mae: 0.0388\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0029 - val_mae: 0.0388\n",
      "\n",
      "âœ… Model and scaler saved for site 3180.\n",
      "3662\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.2272 - mae: 0.3940 - val_loss: 0.0474 - val_mae: 0.1864\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0486 - mae: 0.1808 - val_loss: 0.0299 - val_mae: 0.1389\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0257 - mae: 0.1254 - val_loss: 0.0173 - val_mae: 0.0925\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0161 - mae: 0.0937 - val_loss: 0.0135 - val_mae: 0.0900\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0149 - mae: 0.0931 - val_loss: 0.0342 - val_mae: 0.1461\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0346 - mae: 0.1505 - val_loss: 0.0263 - val_mae: 0.1337\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0240 - mae: 0.1282 - val_loss: 0.0203 - val_mae: 0.1163\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0189 - mae: 0.1111 - val_loss: 0.0165 - val_mae: 0.1006\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0155 - mae: 0.0964 - val_loss: 0.0135 - val_mae: 0.0843\n",
      "\n",
      "âœ… Model and scaler saved for site 3662.\n",
      "3682\n",
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0978 - mae: 0.2353 - val_loss: 0.0251 - val_mae: 0.1296\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0278 - mae: 0.1308 - val_loss: 0.0177 - val_mae: 0.1089\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0193 - mae: 0.1102 - val_loss: 0.0118 - val_mae: 0.0857\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0133 - mae: 0.0922 - val_loss: 0.0094 - val_mae: 0.0783\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0104 - mae: 0.0817 - val_loss: 0.0070 - val_mae: 0.0654\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0128 - mae: 0.0695 - val_loss: 0.0088 - val_mae: 0.0751\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0114 - mae: 0.0839 - val_loss: 0.0099 - val_mae: 0.0812\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0116 - mae: 0.0858 - val_loss: 0.0084 - val_mae: 0.0728\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0096 - mae: 0.0756 - val_loss: 0.0059 - val_mae: 0.0590\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 8.0514 - mae: 0.2508 - val_loss: 0.0276 - val_mae: 0.1245\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0279 - mae: 0.1222 - val_loss: 0.0217 - val_mae: 0.1103\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0219 - mae: 0.1105 - val_loss: 0.0165 - val_mae: 0.1003\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0176 - mae: 0.1030 - val_loss: 0.0137 - val_mae: 0.0949\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0154 - mae: 0.0995 - val_loss: 0.0125 - val_mae: 0.0926\n",
      "\n",
      "âœ… Model and scaler saved for site 3682.\n",
      "3685\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.2497 - mae: 0.4022 - val_loss: 0.0140 - val_mae: 0.0998\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0487 - mae: 0.1819 - val_loss: 0.0109 - val_mae: 0.0880\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0244 - mae: 0.1248 - val_loss: 0.0105 - val_mae: 0.0917\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0157 - mae: 0.0974 - val_loss: 0.0094 - val_mae: 0.0858\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0130 - mae: 0.0872 - val_loss: 0.0103 - val_mae: 0.0911\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0121 - mae: 0.0875 - val_loss: 0.0061 - val_mae: 0.0680\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0103 - mae: 0.0775 - val_loss: 0.0067 - val_mae: 0.0725\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0085 - mae: 0.0716 - val_loss: 0.0055 - val_mae: 0.0644\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0079 - mae: 0.0689 - val_loss: 0.0068 - val_mae: 0.0749\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0063 - mae: 0.0614 - val_loss: 0.0044 - val_mae: 0.0564\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0091 - mae: 0.0771 - val_loss: 0.0028 - val_mae: 0.0423\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0057 - mae: 0.0550 - val_loss: 0.0043 - val_mae: 0.0578\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0274 - mae: 0.0643 - val_loss: 0.0050 - val_mae: 0.0592\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0453 - mae: 0.1652 - val_loss: 0.0084 - val_mae: 0.0809\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0520 - mae: 0.1827 - val_loss: 0.0090 - val_mae: 0.0813\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0412 - mae: 0.1676 - val_loss: 0.0112 - val_mae: 0.0881\n",
      "\n",
      "âœ… Model and scaler saved for site 3685.\n",
      "3804\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1871 - mae: 0.3412 - val_loss: 0.0494 - val_mae: 0.1842\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0401 - mae: 0.1653 - val_loss: 0.0248 - val_mae: 0.1258\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0222 - mae: 0.1132 - val_loss: 0.0147 - val_mae: 0.0897\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0143 - mae: 0.0905 - val_loss: 0.0125 - val_mae: 0.0839\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0118 - mae: 0.0810 - val_loss: 0.0148 - val_mae: 0.1005\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0149 - mae: 0.0975 - val_loss: 0.0116 - val_mae: 0.0799\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0110 - mae: 0.0766 - val_loss: 0.0089 - val_mae: 0.0685\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0084 - mae: 0.0663 - val_loss: 0.0072 - val_mae: 0.0604\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0067 - mae: 0.0609 - val_loss: 0.0064 - val_mae: 0.0608\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0060 - mae: 0.0597 - val_loss: 0.0049 - val_mae: 0.0525\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0044 - mae: 0.0513 - val_loss: 0.0046 - val_mae: 0.0538\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0038 - val_mae: 0.0483\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0038 - mae: 0.0464 - val_loss: 0.0166 - val_mae: 0.1077\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0204 - mae: 0.1175 - val_loss: 0.0158 - val_mae: 0.1037\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0141 - mae: 0.0960 - val_loss: 0.0097 - val_mae: 0.0696\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0095 - mae: 0.0697 - val_loss: 0.0076 - val_mae: 0.0611\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0072 - mae: 0.0624 - val_loss: 0.0052 - val_mae: 0.0524\n",
      "\n",
      "âœ… Model and scaler saved for site 3804.\n",
      "3812\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.1001 - mae: 0.2442 - val_loss: 0.0299 - val_mae: 0.1485\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0272 - mae: 0.1352 - val_loss: 0.0204 - val_mae: 0.1185\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0199 - mae: 0.1124 - val_loss: 0.0162 - val_mae: 0.1013\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0163 - mae: 0.0966 - val_loss: 0.0141 - val_mae: 0.0905\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0143 - mae: 0.0890 - val_loss: 0.0125 - val_mae: 0.0868\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0125 - mae: 0.0832 - val_loss: 0.0125 - val_mae: 0.0911\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0120 - mae: 0.0807 - val_loss: 0.0108 - val_mae: 0.0808\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0106 - mae: 0.0759 - val_loss: 0.0097 - val_mae: 0.0735\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0283 - mae: 0.0738 - val_loss: 0.0156 - val_mae: 0.0980\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0187 - mae: 0.1010 - val_loss: 0.0216 - val_mae: 0.1094\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0204 - mae: 0.1056 - val_loss: 0.0176 - val_mae: 0.1037\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0168 - mae: 0.0987 - val_loss: 0.0152 - val_mae: 0.0974\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0147 - mae: 0.0917 - val_loss: 0.0134 - val_mae: 0.0887\n",
      "\n",
      "âœ… Model and scaler saved for site 3812.\n",
      "4030\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.2147 - mae: 0.3829 - val_loss: 0.0438 - val_mae: 0.1867\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0355 - mae: 0.1685 - val_loss: 0.0274 - val_mae: 0.1492\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0260 - mae: 0.1439 - val_loss: 0.0226 - val_mae: 0.1345\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0220 - mae: 0.1309 - val_loss: 0.0190 - val_mae: 0.1215\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0185 - mae: 0.1177 - val_loss: 0.0143 - val_mae: 0.1011\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0130 - mae: 0.0931 - val_loss: 0.0090 - val_mae: 0.0758\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0089 - mae: 0.0758 - val_loss: 0.0073 - val_mae: 0.0673\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0075 - mae: 0.0695 - val_loss: 0.0061 - val_mae: 0.0623\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0073 - mae: 0.0705 - val_loss: 0.0065 - val_mae: 0.0632\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0064 - mae: 0.0634 - val_loss: 0.0054 - val_mae: 0.0580\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0055 - mae: 0.0588 - val_loss: 0.0051 - val_mae: 0.0564\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0574 - val_loss: 0.0050 - val_mae: 0.0560\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0050 - mae: 0.0560 - val_loss: 0.0048 - val_mae: 0.0545\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0048 - mae: 0.0547 - val_loss: 0.0046 - val_mae: 0.0534\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0046 - mae: 0.0535 - val_loss: 0.0044 - val_mae: 0.0521\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0044 - mae: 0.0521 - val_loss: 0.0042 - val_mae: 0.0508\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0042 - mae: 0.0509 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0037 - val_mae: 0.0472\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0036 - val_mae: 0.0466\n",
      "\n",
      "âœ… Model and scaler saved for site 4030.\n",
      "4032\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1318 - mae: 0.2920 - val_loss: 0.0281 - val_mae: 0.1401\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0245 - mae: 0.1284 - val_loss: 0.0153 - val_mae: 0.1006\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0151 - mae: 0.0965 - val_loss: 0.0098 - val_mae: 0.0742\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0103 - mae: 0.0777 - val_loss: 0.0083 - val_mae: 0.0722\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0093 - mae: 0.0768 - val_loss: 0.0070 - val_mae: 0.0656\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0078 - mae: 0.0689 - val_loss: 0.0059 - val_mae: 0.0595\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0614 - val_loss: 0.0053 - val_mae: 0.0574\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0055 - mae: 0.0581 - val_loss: 0.0035 - val_mae: 0.0452\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0051 - mae: 0.0567 - val_loss: 0.0037 - val_mae: 0.0477\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0049 - mae: 0.0549 - val_loss: 0.0045 - val_mae: 0.0535\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0048 - mae: 0.0540 - val_loss: 0.0034 - val_mae: 0.0436\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0035 - mae: 0.0449 - val_loss: 0.0045 - val_mae: 0.0570\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0051 - mae: 0.0584 - val_loss: 0.0041 - val_mae: 0.0512\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0044 - mae: 0.0519 - val_loss: 0.0033 - val_mae: 0.0437\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0037 - mae: 0.0466 - val_loss: 0.0029 - val_mae: 0.0418\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0032 - mae: 0.0439 - val_loss: 0.0024 - val_mae: 0.0385\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0397 - val_loss: 0.0019 - val_mae: 0.0332\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0340 - val_loss: 0.0019 - val_mae: 0.0356\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0019 - mae: 0.0328 - val_loss: 0.0017 - val_mae: 0.0323\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0322 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "\n",
      "âœ… Model and scaler saved for site 4032.\n",
      "4034\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1902 - mae: 0.3559 - val_loss: 0.0372 - val_mae: 0.1566\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0280 - mae: 0.1354 - val_loss: 0.0184 - val_mae: 0.1065\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0172 - mae: 0.1005 - val_loss: 0.0117 - val_mae: 0.0790\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0120 - mae: 0.0825 - val_loss: 0.0106 - val_mae: 0.0796\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0110 - mae: 0.0811 - val_loss: 0.0082 - val_mae: 0.0664\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0084 - mae: 0.0696 - val_loss: 0.0065 - val_mae: 0.0608\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0078 - mae: 0.0684 - val_loss: 0.0088 - val_mae: 0.0759\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0087 - mae: 0.0735 - val_loss: 0.0064 - val_mae: 0.0569\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0061 - mae: 0.0587 - val_loss: 0.0044 - val_mae: 0.0511\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0050 - mae: 0.0552 - val_loss: 0.0042 - val_mae: 0.0467\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0042 - mae: 0.0502 - val_loss: 0.0034 - val_mae: 0.0436\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0034 - mae: 0.0458 - val_loss: 0.0030 - val_mae: 0.0420\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0034 - mae: 0.0462 - val_loss: 0.0033 - val_mae: 0.0444\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0033 - mae: 0.0445 - val_loss: 0.0024 - val_mae: 0.0371\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0388 - val_loss: 0.0021 - val_mae: 0.0348\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0021 - mae: 0.0357 - val_loss: 0.0020 - val_mae: 0.0345\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0391 - val_loss: 0.0023 - val_mae: 0.0395\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0341 - val_loss: 0.0018 - val_mae: 0.0346\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0346 - val_loss: 0.0016 - val_mae: 0.0314\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0018 - mae: 0.0328 - val_loss: 0.0015 - val_mae: 0.0302\n",
      "\n",
      "âœ… Model and scaler saved for site 4034.\n",
      "4035\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.2646 - mae: 0.4236 - val_loss: 0.0441 - val_mae: 0.1714\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0345 - mae: 0.1493 - val_loss: 0.0218 - val_mae: 0.1183\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0195 - mae: 0.1092 - val_loss: 0.0136 - val_mae: 0.0840\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0129 - mae: 0.0848 - val_loss: 0.0139 - val_mae: 0.0954\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0149 - mae: 0.0979 - val_loss: 0.0117 - val_mae: 0.0855\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0111 - mae: 0.0831 - val_loss: 0.0085 - val_mae: 0.0716\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0087 - mae: 0.0731 - val_loss: 0.0132 - val_mae: 0.0892\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0151 - mae: 0.0974 - val_loss: 0.0124 - val_mae: 0.0877\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0119 - mae: 0.0842 - val_loss: 0.0091 - val_mae: 0.0732\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0092 - mae: 0.0732 - val_loss: 0.0078 - val_mae: 0.0678\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0081 - mae: 0.0695 - val_loss: 0.0071 - val_mae: 0.0655\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0074 - mae: 0.0672 - val_loss: 0.0066 - val_mae: 0.0634\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0649 - val_loss: 0.0062 - val_mae: 0.0614\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0628 - val_loss: 0.0057 - val_mae: 0.0591\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0059 - mae: 0.0604 - val_loss: 0.0052 - val_mae: 0.0567\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0054 - mae: 0.0575 - val_loss: 0.0048 - val_mae: 0.0541\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0546 - val_loss: 0.0043 - val_mae: 0.0514\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0045 - mae: 0.0517 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0041 - mae: 0.0494 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0038 - mae: 0.0475 - val_loss: 0.0034 - val_mae: 0.0447\n",
      "\n",
      "âœ… Model and scaler saved for site 4035.\n",
      "4040\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.1465 - mae: 0.3151 - val_loss: 0.0274 - val_mae: 0.1331\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0255 - mae: 0.1286 - val_loss: 0.0178 - val_mae: 0.1013\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0164 - mae: 0.0977 - val_loss: 0.0116 - val_mae: 0.0827\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0111 - mae: 0.0823 - val_loss: 0.0107 - val_mae: 0.0821\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0107 - mae: 0.0822 - val_loss: 0.0087 - val_mae: 0.0744\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0082 - mae: 0.0718 - val_loss: 0.0067 - val_mae: 0.0656\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0063 - mae: 0.0636 - val_loss: 0.0052 - val_mae: 0.0572\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0551 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0040 - mae: 0.0491 - val_loss: 0.0035 - val_mae: 0.0465\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0036 - mae: 0.0466 - val_loss: 0.0031 - val_mae: 0.0441\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0032 - mae: 0.0444 - val_loss: 0.0029 - val_mae: 0.0420\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0030 - mae: 0.0423 - val_loss: 0.0028 - val_mae: 0.0413\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0401 - val_loss: 0.0025 - val_mae: 0.0392\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0025 - mae: 0.0389 - val_loss: 0.0028 - val_mae: 0.0414\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0025 - mae: 0.0384 - val_loss: 0.0023 - val_mae: 0.0375\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0024 - mae: 0.0370 - val_loss: 0.0027 - val_mae: 0.0416\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0024 - mae: 0.0378 - val_loss: 0.0024 - val_mae: 0.0382\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0023 - val_mae: 0.0377\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0359 - val_loss: 0.0023 - val_mae: 0.0375\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0356 - val_loss: 0.0023 - val_mae: 0.0381\n",
      "\n",
      "âœ… Model and scaler saved for site 4040.\n",
      "4043\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.3534 - mae: 0.4951 - val_loss: 0.0615 - val_mae: 0.2085\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0588 - mae: 0.2045 - val_loss: 0.0368 - val_mae: 0.1631\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0356 - mae: 0.1574 - val_loss: 0.0246 - val_mae: 0.1304\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0237 - mae: 0.1269 - val_loss: 0.0161 - val_mae: 0.1022\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0169 - mae: 0.1058 - val_loss: 0.0115 - val_mae: 0.0847\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0121 - mae: 0.0879 - val_loss: 0.0150 - val_mae: 0.1044\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0153 - mae: 0.1062 - val_loss: 0.0105 - val_mae: 0.0836\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0111 - mae: 0.0851 - val_loss: 0.0080 - val_mae: 0.0701\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0087 - mae: 0.0741 - val_loss: 0.0068 - val_mae: 0.0656\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0076 - mae: 0.0696 - val_loss: 0.0110 - val_mae: 0.0877\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0104 - mae: 0.0865 - val_loss: 0.0067 - val_mae: 0.0644\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0668 - val_loss: 0.0058 - val_mae: 0.0603\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0063 - mae: 0.0635 - val_loss: 0.0051 - val_mae: 0.0563\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0055 - mae: 0.0594 - val_loss: 0.0045 - val_mae: 0.0533\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0050 - mae: 0.0567 - val_loss: 0.0040 - val_mae: 0.0506\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0043 - mae: 0.0525 - val_loss: 0.0035 - val_mae: 0.0470\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0031 - val_mae: 0.0437\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0034 - mae: 0.0460 - val_loss: 0.0029 - val_mae: 0.0409\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0032 - mae: 0.0438 - val_loss: 0.0028 - val_mae: 0.0395\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0032 - mae: 0.0435 - val_loss: 0.0032 - val_mae: 0.0417\n",
      "\n",
      "âœ… Model and scaler saved for site 4043.\n",
      "4051\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.1731 - mae: 0.3300 - val_loss: 0.0419 - val_mae: 0.1674\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0301 - mae: 0.1381 - val_loss: 0.0204 - val_mae: 0.1097\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0182 - mae: 0.1012 - val_loss: 0.0145 - val_mae: 0.0872\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0135 - mae: 0.0864 - val_loss: 0.0146 - val_mae: 0.0959\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0193 - mae: 0.1097 - val_loss: 0.0263 - val_mae: 0.1300\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0239 - mae: 0.1253 - val_loss: 0.0210 - val_mae: 0.1182\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0195 - mae: 0.1150 - val_loss: 0.0186 - val_mae: 0.1110\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0175 - mae: 0.1082 - val_loss: 0.0170 - val_mae: 0.1044\n",
      "\n",
      "âœ… Model and scaler saved for site 4051.\n",
      "4057\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1975 - mae: 0.3475 - val_loss: 0.0417 - val_mae: 0.1682\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0397 - mae: 0.1624 - val_loss: 0.0275 - val_mae: 0.1312\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0259 - mae: 0.1277 - val_loss: 0.0183 - val_mae: 0.1001\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0180 - mae: 0.0988 - val_loss: 0.0136 - val_mae: 0.0830\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0138 - mae: 0.0863 - val_loss: 0.0145 - val_mae: 0.0968\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0149 - mae: 0.0954 - val_loss: 0.0110 - val_mae: 0.0724\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0109 - mae: 0.0728 - val_loss: 0.0091 - val_mae: 0.0708\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0139 - mae: 0.0918 - val_loss: 0.0153 - val_mae: 0.0960\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0144 - mae: 0.0926 - val_loss: 0.0109 - val_mae: 0.0729\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0109 - mae: 0.0742 - val_loss: 0.0089 - val_mae: 0.0678\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0090 - mae: 0.0681 - val_loss: 0.0072 - val_mae: 0.0613\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0075 - mae: 0.0618 - val_loss: 0.0062 - val_mae: 0.0580\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0065 - mae: 0.0579 - val_loss: 0.0053 - val_mae: 0.0533\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0056 - mae: 0.0538 - val_loss: 0.0046 - val_mae: 0.0500\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0513 - val_loss: 0.0040 - val_mae: 0.0477\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0488 - val_loss: 0.0036 - val_mae: 0.0455\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0037 - mae: 0.0469 - val_loss: 0.0033 - val_mae: 0.0436\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0034 - mae: 0.0448 - val_loss: 0.0030 - val_mae: 0.0413\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0037 - mae: 0.0469 - val_loss: 0.0033 - val_mae: 0.0439\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0033 - mae: 0.0433 - val_loss: 0.0027 - val_mae: 0.0398\n",
      "\n",
      "âœ… Model and scaler saved for site 4057.\n",
      "4063\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.2045 - mae: 0.3632 - val_loss: 0.0392 - val_mae: 0.1738\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0356 - mae: 0.1632 - val_loss: 0.0231 - val_mae: 0.1266\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0203 - mae: 0.1147 - val_loss: 0.0135 - val_mae: 0.0904\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0141 - mae: 0.0923 - val_loss: 0.0111 - val_mae: 0.0817\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0112 - mae: 0.0804 - val_loss: 0.0085 - val_mae: 0.0692\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0103 - mae: 0.0784 - val_loss: 0.0083 - val_mae: 0.0662\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0085 - mae: 0.0676 - val_loss: 0.0070 - val_mae: 0.0671\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0093 - mae: 0.0781 - val_loss: 0.0104 - val_mae: 0.0823\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0098 - mae: 0.0783 - val_loss: 0.0070 - val_mae: 0.0633\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0074 - mae: 0.0649 - val_loss: 0.0064 - val_mae: 0.0622\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0066 - mae: 0.0632 - val_loss: 0.0057 - val_mae: 0.0581\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0059 - mae: 0.0587 - val_loss: 0.0050 - val_mae: 0.0544\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0497\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0044 - mae: 0.0506 - val_loss: 0.0035 - val_mae: 0.0467\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0028 - val_mae: 0.0412\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0034 - mae: 0.0457 - val_loss: 0.0062 - val_mae: 0.0618\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0061 - mae: 0.0606 - val_loss: 0.0043 - val_mae: 0.0482\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - mae: 0.0496 - val_loss: 0.0035 - val_mae: 0.0456\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0036 - mae: 0.0462 - val_loss: 0.0031 - val_mae: 0.0429\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0031 - mae: 0.0433 - val_loss: 0.0028 - val_mae: 0.0396\n",
      "\n",
      "âœ… Model and scaler saved for site 4063.\n",
      "4262\n",
      "Epoch 1/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0807 - mae: 0.2285 - val_loss: 0.0233 - val_mae: 0.1277\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0199 - mae: 0.1151 - val_loss: 0.0120 - val_mae: 0.0892\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0126 - mae: 0.0891 - val_loss: 0.0093 - val_mae: 0.0720\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0104 - mae: 0.0753 - val_loss: 0.0084 - val_mae: 0.0697\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0094 - mae: 0.0714 - val_loss: 0.0079 - val_mae: 0.0667\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0088 - mae: 0.0681 - val_loss: 0.0076 - val_mae: 0.0642\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0084 - mae: 0.0651 - val_loss: 0.0073 - val_mae: 0.0617\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0081 - mae: 0.0633 - val_loss: 0.0071 - val_mae: 0.0613\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0078 - mae: 0.0619 - val_loss: 0.0069 - val_mae: 0.0596\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0076 - mae: 0.0604 - val_loss: 0.0067 - val_mae: 0.0568\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0074 - mae: 0.0592 - val_loss: 0.0065 - val_mae: 0.0539\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0072 - mae: 0.0585 - val_loss: 0.0064 - val_mae: 0.0522\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0071 - mae: 0.0576 - val_loss: 0.0062 - val_mae: 0.0510\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0070 - mae: 0.0568 - val_loss: 0.0061 - val_mae: 0.0503\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0560 - val_loss: 0.0062 - val_mae: 0.0501\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0552 - val_loss: 0.0061 - val_mae: 0.0495\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0068 - mae: 0.0542 - val_loss: 0.0061 - val_mae: 0.0497\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0067 - mae: 0.0533 - val_loss: 0.0061 - val_mae: 0.0503\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0066 - mae: 0.0523 - val_loss: 0.0061 - val_mae: 0.0497\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0065 - mae: 0.0517 - val_loss: 0.0060 - val_mae: 0.0490\n",
      "\n",
      "âœ… Model and scaler saved for site 4262.\n",
      "4263\n",
      "Epoch 1/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1537 - mae: 0.3113 - val_loss: 0.0385 - val_mae: 0.1591\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0354 - mae: 0.1525 - val_loss: 0.0234 - val_mae: 0.1236\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0248 - mae: 0.1242 - val_loss: 0.0167 - val_mae: 0.0996\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0172 - mae: 0.0964 - val_loss: 0.0119 - val_mae: 0.0792\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0120 - mae: 0.0790 - val_loss: 0.0101 - val_mae: 0.0781\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0114 - mae: 0.0819 - val_loss: 0.0094 - val_mae: 0.0720\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0095 - mae: 0.0712 - val_loss: 0.0085 - val_mae: 0.0706\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0084 - mae: 0.0673 - val_loss: 0.0141 - val_mae: 0.0954\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0158 - mae: 0.0992 - val_loss: 0.0124 - val_mae: 0.0879\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0127 - mae: 0.0859 - val_loss: 0.0097 - val_mae: 0.0743\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0103 - mae: 0.0758 - val_loss: 0.0082 - val_mae: 0.0689\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0086 - mae: 0.0711 - val_loss: 0.0070 - val_mae: 0.0633\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0072 - mae: 0.0654 - val_loss: 0.0061 - val_mae: 0.0575\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0063 - mae: 0.0600 - val_loss: 0.0054 - val_mae: 0.0539\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0055 - mae: 0.0560 - val_loss: 0.0048 - val_mae: 0.0505\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0048 - mae: 0.0521 - val_loss: 0.0041 - val_mae: 0.0475\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0488 - val_loss: 0.0037 - val_mae: 0.0452\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0038 - mae: 0.0461 - val_loss: 0.0033 - val_mae: 0.0432\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0034 - mae: 0.0439 - val_loss: 0.0030 - val_mae: 0.0409\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0417 - val_loss: 0.0027 - val_mae: 0.0390\n",
      "\n",
      "âœ… Model and scaler saved for site 4263.\n",
      "4264\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1849 - mae: 0.3592 - val_loss: 0.0241 - val_mae: 0.1256\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0270 - mae: 0.1316 - val_loss: 0.0123 - val_mae: 0.0853\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0144 - mae: 0.0877 - val_loss: 0.0075 - val_mae: 0.0651\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0097 - mae: 0.0728 - val_loss: 0.0068 - val_mae: 0.0615\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0090 - mae: 0.0696 - val_loss: 0.0058 - val_mae: 0.0563\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0075 - mae: 0.0630 - val_loss: 0.0053 - val_mae: 0.0549\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0557 - val_loss: 0.0053 - val_mae: 0.0586\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0050 - mae: 0.0539 - val_loss: 0.0069 - val_mae: 0.0665\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0090 - mae: 0.0738 - val_loss: 0.0048 - val_mae: 0.0497\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0061 - mae: 0.0561 - val_loss: 0.0038 - val_mae: 0.0462\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0047 - mae: 0.0507 - val_loss: 0.0033 - val_mae: 0.0427\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0038 - mae: 0.0458 - val_loss: 0.0028 - val_mae: 0.0395\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0032 - mae: 0.0427 - val_loss: 0.0025 - val_mae: 0.0373\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0028 - mae: 0.0403 - val_loss: 0.0021 - val_mae: 0.0338\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0024 - mae: 0.0383 - val_loss: 0.0021 - val_mae: 0.0350\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0023 - mae: 0.0374 - val_loss: 0.0019 - val_mae: 0.0329\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0021 - mae: 0.0357 - val_loss: 0.0016 - val_mae: 0.0297\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0022 - mae: 0.0365 - val_loss: 0.0020 - val_mae: 0.0352\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0020 - mae: 0.0347 - val_loss: 0.0017 - val_mae: 0.0316\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0019 - mae: 0.0331 - val_loss: 0.0014 - val_mae: 0.0283\n",
      "\n",
      "âœ… Model and scaler saved for site 4264.\n",
      "4266\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.2593 - mae: 0.4199 - val_loss: 0.0586 - val_mae: 0.1933\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0432 - mae: 0.1707 - val_loss: 0.0237 - val_mae: 0.1227\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0206 - mae: 0.1115 - val_loss: 0.0146 - val_mae: 0.0868\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0143 - mae: 0.0886 - val_loss: 0.0112 - val_mae: 0.0763\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0108 - mae: 0.0770 - val_loss: 0.0087 - val_mae: 0.0678\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0081 - mae: 0.0677 - val_loss: 0.0070 - val_mae: 0.0660\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0079 - mae: 0.0672 - val_loss: 0.0221 - val_mae: 0.1228\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0215 - mae: 0.1220 - val_loss: 0.0157 - val_mae: 0.1012\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0136 - mae: 0.0929 - val_loss: 0.0100 - val_mae: 0.0767\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0093 - mae: 0.0733 - val_loss: 0.0079 - val_mae: 0.0650\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0076 - mae: 0.0646 - val_loss: 0.0066 - val_mae: 0.0601\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0062 - mae: 0.0591 - val_loss: 0.0052 - val_mae: 0.0543\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0047 - mae: 0.0518 - val_loss: 0.0034 - val_mae: 0.0441\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0424 - val_loss: 0.0027 - val_mae: 0.0389\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0039 - val_mae: 0.0461\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0038 - mae: 0.0442 - val_loss: 0.0033 - val_mae: 0.0420\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0393 - val_loss: 0.0024 - val_mae: 0.0374\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0022 - mae: 0.0355 - val_loss: 0.0021 - val_mae: 0.0351\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0019 - mae: 0.0338 - val_loss: 0.0019 - val_mae: 0.0334\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0017 - mae: 0.0325 - val_loss: 0.0018 - val_mae: 0.0321\n",
      "\n",
      "âœ… Model and scaler saved for site 4266.\n",
      "4270\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.2565 - mae: 0.4248 - val_loss: 0.0635 - val_mae: 0.2095\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0475 - mae: 0.1825 - val_loss: 0.0271 - val_mae: 0.1352\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0229 - mae: 0.1219 - val_loss: 0.0137 - val_mae: 0.0911\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0142 - mae: 0.0952 - val_loss: 0.0103 - val_mae: 0.0792\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0105 - mae: 0.0820 - val_loss: 0.0100 - val_mae: 0.0785\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0137 - mae: 0.0933 - val_loss: 0.0229 - val_mae: 0.1281\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0205 - mae: 0.1222 - val_loss: 0.0125 - val_mae: 0.0938\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0113 - mae: 0.0895 - val_loss: 0.0084 - val_mae: 0.0740\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0085 - mae: 0.0740 - val_loss: 0.0069 - val_mae: 0.0638\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0071 - mae: 0.0652 - val_loss: 0.0062 - val_mae: 0.0606\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0064 - mae: 0.0625 - val_loss: 0.0058 - val_mae: 0.0587\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0060 - mae: 0.0604 - val_loss: 0.0055 - val_mae: 0.0574\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0058 - mae: 0.0590 - val_loss: 0.0052 - val_mae: 0.0559\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0055 - mae: 0.0574 - val_loss: 0.0050 - val_mae: 0.0545\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0558 - val_loss: 0.0048 - val_mae: 0.0530\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0542 - val_loss: 0.0045 - val_mae: 0.0513\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0047 - mae: 0.0525 - val_loss: 0.0043 - val_mae: 0.0497\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0044 - mae: 0.0508 - val_loss: 0.0040 - val_mae: 0.0480\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0041 - mae: 0.0490 - val_loss: 0.0038 - val_mae: 0.0463\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0039 - mae: 0.0472 - val_loss: 0.0036 - val_mae: 0.0448\n",
      "\n",
      "âœ… Model and scaler saved for site 4270.\n",
      "4272\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.1807 - mae: 0.3372 - val_loss: 0.0360 - val_mae: 0.1551\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0336 - mae: 0.1508 - val_loss: 0.0275 - val_mae: 0.1331\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0255 - mae: 0.1299 - val_loss: 0.0217 - val_mae: 0.1159\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0199 - mae: 0.1123 - val_loss: 0.0171 - val_mae: 0.1006\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0153 - mae: 0.0983 - val_loss: 0.0139 - val_mae: 0.0917\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0125 - mae: 0.0901 - val_loss: 0.0117 - val_mae: 0.0838\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0819 - val_loss: 0.0099 - val_mae: 0.0765\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0085 - mae: 0.0725 - val_loss: 0.0072 - val_mae: 0.0633\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1977487589376.0000 - mae: 156514.3594 - val_loss: 0.0282 - val_mae: 0.1246\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0284 - mae: 0.1253 - val_loss: 0.0319 - val_mae: 0.1333\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0295 - mae: 0.1281 - val_loss: 0.0291 - val_mae: 0.1270\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0258 - mae: 0.1207 - val_loss: 0.0213 - val_mae: 0.1119\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0187 - mae: 0.1094 - val_loss: 0.0177 - val_mae: 0.1027\n",
      "\n",
      "âœ… Model and scaler saved for site 4272.\n",
      "4273\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.1402 - mae: 0.2914 - val_loss: 0.0304 - val_mae: 0.1453\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0260 - mae: 0.1272 - val_loss: 0.0170 - val_mae: 0.1020\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0175 - mae: 0.1022 - val_loss: 0.0128 - val_mae: 0.0875\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0136 - mae: 0.0920 - val_loss: 0.0101 - val_mae: 0.0800\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0107 - mae: 0.0824 - val_loss: 0.0077 - val_mae: 0.0684\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0083 - mae: 0.0697 - val_loss: 0.0153 - val_mae: 0.0914\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0169 - mae: 0.0977 - val_loss: 0.0097 - val_mae: 0.0797\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0098 - mae: 0.0775 - val_loss: 0.0065 - val_mae: 0.0608\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 33992489304064.0000 - mae: 465248.7812 - val_loss: 0.0253 - val_mae: 0.1151\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0308 - mae: 0.1296 - val_loss: 0.0256 - val_mae: 0.1159\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0264 - mae: 0.1199 - val_loss: 0.0126 - val_mae: 0.0923\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0119 - mae: 0.0855 - val_loss: 0.0075 - val_mae: 0.0661\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0082 - mae: 0.0671 - val_loss: 0.0079 - val_mae: 0.0663\n",
      "\n",
      "âœ… Model and scaler saved for site 4273.\n",
      "4321\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.1700 - mae: 0.3284 - val_loss: 0.0462 - val_mae: 0.1770\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0359 - mae: 0.1530 - val_loss: 0.0210 - val_mae: 0.1089\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0188 - mae: 0.1000 - val_loss: 0.0142 - val_mae: 0.0919\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0141 - mae: 0.0926 - val_loss: 0.0131 - val_mae: 0.0863\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0127 - mae: 0.0850 - val_loss: 0.0092 - val_mae: 0.0678\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0093 - mae: 0.0706 - val_loss: 0.0092 - val_mae: 0.0719\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0088 - mae: 0.0706 - val_loss: 0.0066 - val_mae: 0.0581\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0328 - mae: 0.0967 - val_loss: 0.0324 - val_mae: 0.1349\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0331 - mae: 0.1396 - val_loss: 0.0245 - val_mae: 0.1262\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0231 - mae: 0.1240 - val_loss: 0.0187 - val_mae: 0.1101\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0182 - mae: 0.1030 - val_loss: 0.0142 - val_mae: 0.0950\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0181 - mae: 0.1031 - val_loss: 0.0222 - val_mae: 0.1137\n",
      "\n",
      "âœ… Model and scaler saved for site 4321.\n",
      "4324\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1381 - mae: 0.2986 - val_loss: 0.0277 - val_mae: 0.1352\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0211 - mae: 0.1155 - val_loss: 0.0131 - val_mae: 0.0874\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0124 - mae: 0.0837 - val_loss: 0.0096 - val_mae: 0.0720\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0098 - mae: 0.0730 - val_loss: 0.0080 - val_mae: 0.0648\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0082 - mae: 0.0664 - val_loss: 0.0076 - val_mae: 0.0654\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0073 - mae: 0.0619 - val_loss: 0.0067 - val_mae: 0.0619\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0066 - mae: 0.0604 - val_loss: 0.0060 - val_mae: 0.0586\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0058 - mae: 0.0560 - val_loss: 0.0049 - val_mae: 0.0513\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0048 - mae: 0.0510 - val_loss: 0.0093 - val_mae: 0.0812\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0096 - mae: 0.0797 - val_loss: 0.0057 - val_mae: 0.0537\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0057 - mae: 0.0536 - val_loss: 0.0046 - val_mae: 0.0512\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0045 - mae: 0.0509 - val_loss: 0.0044 - val_mae: 0.0509\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0039 - mae: 0.0462 - val_loss: 0.0037 - val_mae: 0.0485\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0034 - mae: 0.0431 - val_loss: 0.0027 - val_mae: 0.0396\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0029 - mae: 0.0395 - val_loss: 0.0030 - val_mae: 0.0392\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0031 - mae: 0.0403 - val_loss: 0.0034 - val_mae: 0.0474\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0030 - mae: 0.0419 - val_loss: 0.0030 - val_mae: 0.0449\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0027 - mae: 0.0401 - val_loss: 0.0021 - val_mae: 0.0353\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0022 - mae: 0.0352 - val_loss: 0.0021 - val_mae: 0.0360\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0022 - mae: 0.0353 - val_loss: 0.0026 - val_mae: 0.0415\n",
      "\n",
      "âœ… Model and scaler saved for site 4324.\n",
      "4335\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.2364 - mae: 0.3968 - val_loss: 0.0503 - val_mae: 0.1968\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0483 - mae: 0.1852 - val_loss: 0.0339 - val_mae: 0.1535\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0285 - mae: 0.1403 - val_loss: 0.0202 - val_mae: 0.1113\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0173 - mae: 0.1026 - val_loss: 0.0156 - val_mae: 0.0950\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0141 - mae: 0.0894 - val_loss: 0.0125 - val_mae: 0.0819\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0777 - val_loss: 0.0106 - val_mae: 0.0744\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0099 - mae: 0.0732 - val_loss: 0.0098 - val_mae: 0.0739\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0092 - mae: 0.0712 - val_loss: 0.0085 - val_mae: 0.0670\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0082 - mae: 0.0665 - val_loss: 0.0073 - val_mae: 0.0601\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0068 - mae: 0.0590 - val_loss: 0.0065 - val_mae: 0.0603\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0058 - mae: 0.0547 - val_loss: 0.0054 - val_mae: 0.0532\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0051 - mae: 0.0518 - val_loss: 0.0048 - val_mae: 0.0502\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0050 - mae: 0.0523 - val_loss: 0.0043 - val_mae: 0.0489\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0042 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0464\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - mae: 0.0465 - val_loss: 0.0035 - val_mae: 0.0450\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0037 - mae: 0.0453 - val_loss: 0.0034 - val_mae: 0.0437\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0036 - mae: 0.0435 - val_loss: 0.0031 - val_mae: 0.0408\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0417 - val_loss: 0.0032 - val_mae: 0.0431\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0034 - mae: 0.0421 - val_loss: 0.0036 - val_mae: 0.0432\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0417 - val_loss: 0.0036 - val_mae: 0.0441\n",
      "\n",
      "âœ… Model and scaler saved for site 4335.\n",
      "4812\n",
      "Epoch 1/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.2012 - mae: 0.3655 - val_loss: 0.0448 - val_mae: 0.1677\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0417 - mae: 0.1683 - val_loss: 0.0238 - val_mae: 0.1225\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0240 - mae: 0.1227 - val_loss: 0.0167 - val_mae: 0.0978\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0160 - mae: 0.0921 - val_loss: 0.0131 - val_mae: 0.0916\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0165 - mae: 0.1017 - val_loss: 0.0213 - val_mae: 0.1167\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0223 - mae: 0.1207 - val_loss: 0.0172 - val_mae: 0.1066\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0170 - mae: 0.1049 - val_loss: 0.0137 - val_mae: 0.0932\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0138 - mae: 0.0935 - val_loss: 0.0117 - val_mae: 0.0837\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0118 - mae: 0.0854 - val_loss: 0.0105 - val_mae: 0.0782\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0105 - mae: 0.0806 - val_loss: 0.0096 - val_mae: 0.0752\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0095 - mae: 0.0768 - val_loss: 0.0088 - val_mae: 0.0720\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0080 - val_mae: 0.0681\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0076 - mae: 0.0675 - val_loss: 0.0071 - val_mae: 0.0637\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0066 - mae: 0.0619 - val_loss: 0.0064 - val_mae: 0.0596\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0565 - val_loss: 0.0060 - val_mae: 0.0583\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0528 - val_loss: 0.0057 - val_mae: 0.0580\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0043 - mae: 0.0507 - val_loss: 0.0051 - val_mae: 0.0556\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0047 - val_mae: 0.0538\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0045 - val_mae: 0.0521\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0034 - mae: 0.0453 - val_loss: 0.0042 - val_mae: 0.0500\n",
      "\n",
      "âœ… Model and scaler saved for site 4812.\n",
      "4821\n",
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.2319 - mae: 0.3915 - val_loss: 0.0499 - val_mae: 0.1905\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0429 - mae: 0.1759 - val_loss: 0.0276 - val_mae: 0.1457\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0256 - mae: 0.1359 - val_loss: 0.0166 - val_mae: 0.1042\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0167 - mae: 0.1036 - val_loss: 0.0131 - val_mae: 0.0908\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0136 - mae: 0.0924 - val_loss: 0.0107 - val_mae: 0.0807\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0111 - mae: 0.0808 - val_loss: 0.0085 - val_mae: 0.0688\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0088 - mae: 0.0687 - val_loss: 0.0065 - val_mae: 0.0576\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0073 - mae: 0.0640 - val_loss: 0.0059 - val_mae: 0.0586\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0067 - mae: 0.0633 - val_loss: 0.0055 - val_mae: 0.0550\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0582 - val_loss: 0.0047 - val_mae: 0.0517\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0052 - mae: 0.0546 - val_loss: 0.0040 - val_mae: 0.0476\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0044 - mae: 0.0498 - val_loss: 0.0042 - val_mae: 0.0520\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0043 - mae: 0.0514 - val_loss: 0.0032 - val_mae: 0.0430\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0037 - mae: 0.0470 - val_loss: 0.0031 - val_mae: 0.0425\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0034 - mae: 0.0449 - val_loss: 0.0028 - val_mae: 0.0408\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 0.0025 - val_mae: 0.0378\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0029 - mae: 0.0415 - val_loss: 0.0024 - val_mae: 0.0376\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0026 - mae: 0.0390 - val_loss: 0.0021 - val_mae: 0.0351\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0022 - val_mae: 0.0370\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0025 - mae: 0.0389 - val_loss: 0.0019 - val_mae: 0.0335\n",
      "\n",
      "âœ… Model and scaler saved for site 4821.\n"
     ]
    }
   ],
   "source": [
    "for id in sites:\n",
    "    print(id)\n",
    "    site_data = final_dataset[final_dataset['site_id'] == id].sort_values(\"timestamp\")\n",
    "    \n",
    "    replace_outliers_iqr(site_data, 'volume')\n",
    "    \n",
    "    # Scale Data\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    site_data['volume'] = scaler.fit_transform(site_data[['volume']])\n",
    "    \n",
    "    site_data = np.array(site_data['volume'])\n",
    "    \n",
    "    x, y = generating_sequences(site_data)\n",
    "    \n",
    "    # Split into training and testing\n",
    "    split = int(len(x) * 0.8)\n",
    "    X_train, X_test = x[:split], x[split:]\n",
    "    Y_train, Y_test = y[:split], y[split:]\n",
    "    \n",
    "    # Define the LSTM model\n",
    "    model = Sequential([\n",
    "        Input(shape=(96, 1)),\n",
    "        LSTM(64, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        X_train, Y_train,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        epochs=20,\n",
    "        batch_size=96,\n",
    "        callbacks = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    )\n",
    "    \n",
    "    # Save the model\n",
    "    model.save(f\"../models/LSTM_models/lstm_model_site_{id}.keras\")  # New format\n",
    "\n",
    "    joblib.dump(scaler, f\"../models/Scalers/scaler_site_{id}.save\")\n",
    "\n",
    "    print(f\"\\nâœ… Model and scaler saved for site {id}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54596e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš¦ Loading model and scaler for site 970...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Accuracy: 68.11%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "113.06418\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 2000...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Accuracy: 62.64%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "252.54424\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 2200...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Accuracy: 58.68%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "63.15565\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 2820...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Accuracy: 72.38%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "44.789646\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 2825...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Accuracy: 85.91%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "40.268204\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 2827...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "Accuracy: 72.80%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "107.27153\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 2846...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Accuracy: 49.62%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "64.56724\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3001...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Accuracy: 83.88%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "211.55528\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3002...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Accuracy: 87.55%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "143.0939\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3120...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Accuracy: 80.73%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "205.98848\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3122...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Accuracy: 39.64%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "79.95712\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3126...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: 61.43%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "81.95888\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3127...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Accuracy: 29.34%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "62.07917\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3180...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Accuracy: 33.89%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "25.335741\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3662...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Accuracy: 8.33%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "227.83871\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3682...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Accuracy: 16.08%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "121.79398\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3685...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Accuracy: 63.83%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "109.299286\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3804...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: -5.97%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "83.06598\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 3812...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Accuracy: 31.22%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "58.418285\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4030...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Accuracy: 63.27%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "68.31179\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4032...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Accuracy: 62.57%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "86.64395\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4034...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: 75.69%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "86.8662\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4035...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: 97.45%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "127.96177\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4040...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: 79.09%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "165.94864\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4043...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: 72.22%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "167.66054\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4051...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: -18.43%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "45.252033\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4057...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: 42.91%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "48.94264\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4063...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Accuracy: 90.76%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "59.009373\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4262...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: 78.98%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "41.27393\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4263...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: 87.75%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "142.45557\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4264...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: 96.40%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "87.139175\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4266...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: 99.31%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "94.234795\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4270...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Accuracy: 88.67%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "148.44557\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4272...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Accuracy: 40.54%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "71.22142\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4273...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: 26.64%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "63.8193\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4321...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Accuracy: 1.01%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "66.26758\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4324...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Accuracy: 85.36%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "38.464954\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4335...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Accuracy: 30.62%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "46.134785\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4812...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Accuracy: 53.80%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "54.463806\n",
      "\n",
      "ğŸš¦ Loading model and scaler for site 4821...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Accuracy: 50.72%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "82.085335\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replace outliers using IQR\n",
    "replace_outliers_iqr(final_dataset, 'volume')\n",
    "\n",
    "for id in sites:\n",
    "    # Load the model and scaler\n",
    "    model = load_model(f\"../models/LSTM_models/lstm_model_site_{id}.keras\")\n",
    "    scaler = joblib.load(f\"../models/Scalers/scaler_site_{id}.save\")\n",
    "    print(f\"\\nğŸš¦ Loading model and scaler for site {id}...\")\n",
    "    \n",
    "    # Filter data for this site\n",
    "    site_data = final_dataset[final_dataset['site_id'] == id].sort_values(\"timestamp\")\n",
    "    \n",
    "    site_data['volume'] = scaler.transform(site_data[['volume']])\n",
    "    \n",
    "    # Predictions for the next time step\n",
    "    last_site_data = np.array(site_data['volume'][-96:]).reshape(-1, 96, 1)\n",
    "   \n",
    "    # Make predictions on the test set\n",
    "    last_test_site_data = np.array(site_data['volume'][:97])\n",
    "    \n",
    "    testX, testY = generating_sequences(last_test_site_data)\n",
    "    \n",
    "    testX = testX.reshape(-1, 96, 1)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(testX)\n",
    "\n",
    "    # Reverse scaling if necessary\n",
    "    y_test_actual = scaler.inverse_transform(testY.reshape(-1, 1))\n",
    "    y_pred_actual = scaler.inverse_transform(y_pred)\n",
    "\n",
    "    smape = 100 * abs(y_pred_actual - y_test_actual) / ((abs(y_pred_actual) + abs(y_test_actual)) / 2)\n",
    "    accuracy = 100 - smape\n",
    "    accuracy = np.mean(accuracy)\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    pred_scaled = model.predict(last_site_data)\n",
    "    pred_volume = scaler.inverse_transform(pred_scaled)[0][0]\n",
    "\n",
    "    # print(f\"Predicted volume for the next time step: {pred_volume:.2f}\")\n",
    "    # print(pred_scaled)\n",
    "    print(pred_volume)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844b0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW4AAAKyCAYAAABFb0fEAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAgfxJREFUeJzt3QeYXVX1N+CdAKGG0HuVjjRp0v70pliQKiogIooF6QJKB+kWqihSVVApCoJ06VWKgqgRpUqoSgi9JPd7fme+O0wmkzCTzNw5mbzv89xkbt/3nHXaOuvsPajRaDQKAAAAAAC1Mbi/GwAAAAAAwNgkbgEAAAAAakbiFgAAAACgZiRuAQAAAABqRuIWAAAAAKBmJG4BAAAAAGpG4hYAAAAAoGYkbgEAAAAAakbiFgAAAACgZiRuAQBa7IknniiDBg0q5513Xn83ZbK0/vrrV7e+nJ6LLLJI+eIXv1j6w5/+9Key1lprlRlnnLH6XX/+859LHac7AAB9S+IWAGACPvWpT5UZZpihvPrqq+N9zec///kyZMiQ8t///rcMdDfffHOVTGzepplmmvKhD32o7LTTTuWxxx4rk5M777yzHH744WXkyJGlLt59992y7bbblv/973/lhz/8Yfn5z39eFl544T79ziS+d9lll7LYYouV6aabrswzzzxl3XXXLYcddtgE3zdixIhq+vV1Yvn2229vj7eXXnppnOdvuOGGssEGG5Q55pijzDLLLGX11VevpltHTz/9dDniiCOq52adddbqtUlC572dPfvss+XAAw+sPnPo0KHV9ybuAQBabeqWfyMAwGQkSdnf//735be//W2VnOzsjTfeKJdffnnZfPPNy+yzz16mFN/61rfKaqutViUaH3jggfLTn/60XHXVVeXhhx8u8803X0vbksTmm2++WSWRe5q4TTIvlbVJ+HU0fPjwMnhw62sc/v3vf5cnn3yynHXWWeXLX/5yn3/fv/71r2o+Tj/99OVLX/pSVWmcxGXm6fHHH19Nn6brrrtunMRtns97VlpppT5p35gxY8oee+xRVR+//vrr4zx/xRVXlC233LKsueaaVRI5Sdbf/OY31bKaJO/ee+9dvS7LaH5PXrvzzjuX9957r1xwwQVlk002Keecc06VuO447/PaJZZYoiy//PLlrrvu6pPfBgDwQSRuAQA+oOI2VXcXXnhhl4nbJISSUEqCd0ryf//3f2Wbbbap/k7Sa8kll6ySueeff3456KCDunxPplMScL0tybpUivamaaedtvSHF154ofq/cyJ5Ukxouqeq97XXXquqZjtX9jbb0pSq8lbLCYFUyyaJffLJJ4/z/GmnnVbmnXfe8sc//rF9nn31q18tSy+9dNV1RjNxm+rZp556qqq0bdp9992rhPOhhx46VuJ2lVVWqarnZ5tttnLJJZdUFdAAAP1BVwkAABOQSsStttqq3HjjjeMksiIJ3SR2k+CNdBeQRE+SPuliYY011qgqUSe2/9BUg6aisXN/rieddFI5/fTTq24K8j2bbrppleBqNBrlqKOOKgsssEDV9k9/+tPVZfedXX311VXyNQm9tH+LLbYojzzySJlYG264YfX/448/Xv3frH7829/+Vj73uc9Vl6evs8467a//xS9+USXI0sZMq89+9rNV+7tK3OUS/rwul7nfdttt47xmfH3c/uMf/yjbbbddmXPOOav3L7XUUuW73/1ue/v233//6u9FF120/VL8fNb4+rjtzrxtdiWRqs/vfe971XxIUnmjjTaqqlsnJN+33nrrVX/ne/I5HWMiycnmPEtiN/P273//+1if8UHTvasK37Sxq+4Y5pprrvHGaH5nKnUjSc/m9Os4D+65556qEn3YsGHV9Mpvu+OOO0p3JW4PPvjgcuSRR443kT1q1KjqN3ZMtE899dRVgjbzvOnDH/7wWEnbyHs+/vGPl//85z9jdYWS5SHzGACgv0ncAgB8gFTT5tLqJOM6J5auvfba8pnPfKZKEj3//PPVoFJ57Otf/3qVuHvrrbeqpG66WuhNv/zlL8sZZ5xRXUa+7777lltuuaVKUibRdc0115QDDjigfOUrX6m6edhvv/3Gem/6/0yidqaZZqouCT/kkEOqRF8SfM3EZU8lARidu4tIAjLdSRxzzDFlt912qx7LdEn1ci5F/8EPflD22muvKjGeflU79jd79tlnV9WT6XP1hBNOKGuvvXY1LbtK8Hb20EMPlY9+9KNVsjPfm2rNXCaf6RFJxu+www7V382+ZHNLkrcrPZ23xx13XPV4pn0qkO++++4PrMrOb/3Od75T/Z3q5bSnmWhOX6ybbbZZdfIgydl99tmn6uoh06SredbVdO9KEraZnplOPbHMMstUCdVInDWnX+Zh5PPydxKr6Ss37ci8TYL/3nvv7dZ3JC4z7zNdxieJ5JxwyGuTGE8c5sTFfffdV7797W9/4Hc899xzVVI5NwCA2mkAADBB7733XmPeeedtrLnmmmM9fuaZZzayO3XttddW9/faa6/q/m233db+mldffbWx6KKLNhZZZJHG6NGjq8cef/zx6nXnnntu++vWW2+96tbZzjvv3Fh44YXb7zffO+ecczZGjhzZ/vhBBx1UPb7iiis23n333fbHd9hhh8aQIUMab731Vnt7ZplllsZuu+021vc899xzjWHDho3zeGc33XRT9T3nnHNO48UXX2yMGDGicdVVV1W/b9CgQY0//elP1esOO+yw6nX5/o6eeOKJxlRTTdX43ve+N9bjDz/8cGPqqaduf/ydd95pzDXXXI2VVlqp8fbbb7e/7qc//Wn1uR2nVVfTc911120MHTq08eSTT471PWPGjGn/+8QTT6zel/d3lmmead/U3XnbnD7LLLPMWO0++eSTq8fzO7szfS+++OKxHs90yPT473//2/7YX/7yl8bgwYMbO+20U/tj45vu4/PXv/61Mf3001fvyXfsueeejd/97neN119/fZzXdo7RzOvO0705jZdYYonGZpttNtb0fuONN6rptckmm3xgu/LbEifNZav5uxJzHb322muN7bbbroq9PJ/bDDPMUP2GD/Loo482pptuusaOO+443tdkPuQzM18AAFpNxS0AwAeYaqqpqkv5M0hRx+rGdJMw99xzV5fBxx/+8Ifqcv6Ol6anqjUViXlfqlp7Syoqcwl6U6pL4wtf+EJ1qXjHx995553yzDPPVPevv/76qvIx1aYZvKl5y2/Ma2+66aZufX8Gskp1agYiS/Vu+lFN/7arrrrqWK9LP6IdXXbZZdWAU6kO7vj9qaxMBW7z+1MxmerSvL9j36rpTqDj7+7Kiy++WG699daqjQsttNBYz+Vy/onR03mb7gM6tjtdHDS7W+ipDBaWPmjz2ztewr/CCitUg2ulbZ11nu7jky4E8tmJm/yOZmVy4joDpE2MfN6jjz5addWQvmKb8zgxkmUl8yYxMCGpOP7Yxz5WdQEyIenuIP0rp7/liy66qOqCIzGY35Mq5/FJNXKWoVTKpzoaAKCODE4GANANucw9l9QnWZvL2dMvZvpbTYIpSc948skn2xOonS8rbz6/3HLL9Up7Oickm8nMBRdcsMvHX3755er/JNQ69knb2cwzz9yt78+ATklG5ren79D8xo4J46b0H9tRvj/98CZJ25VpppmmfVpF59fl+fTrOyHN5GhvTeuJmbed50/6Ye04H3r63ZE+erv6/nTf0HkAss7TfUKS+Ew3B6NHj64S0FdeeWXVNUWS0vmcjTfeuEftbcbYzjvvPN7XvPLKK+3TpLNf//rXVTcQf/3rXz/wu775zW9WCdoHHnigDB7cVpOSkwJJSO+5555VP7ud5XfmREx+a/p6zskHAIA6krgFAOiGDKSVkepT1ZfEbf5PAvKD+i3trlSC5vO6SjJ1pZks7u7jzc9uVjomUZcq1866Sr52Zfnll+9WQq/jAFHN789vTcKsq7aminUg+KD50Nc6T/futjnzNbc111yzbLDBBlVfyj1N3DZj7MQTTywrrbRSl6+Z0HzOoHGphk3FcrPCvdn3cfrjTQV5kq35P/0gpy/bZtK2mdxPte5pp51WvaZj5XOkz98kp/PbxncCAwCgDiRuAQC6KUnaDIKUga9SeZtq0NVWW22sgZ6GDx8+zvv+8Y9/tD8/Pqk+7Ooy+ma1ZW9ZbLHFqv/nmmuuHifkeuv7k7xMJWcqPcenOa1Svdkxufbuu++Wxx9/vKy44orjfW+zIveDKjZ70m3CpMzbSdX87PF9fyqeO1bb9oZmlxfppqGn068ZY6nenpgYS3I2y1duna288srVvE93DOmGIYMGdnVyI3GSBHLn55IUPvfcc8uPfvSj9sHpAADqSh+3AADd1KyuTTcBSRx1rrb9+Mc/Xu69996qL9ymXML+05/+tCyyyCJl2WWXHe9nJ9mVJFz6Z236y1/+Uu64445e/Q2bbbZZlVA75phjquRWZx2/vy9stdVWVWXnEUccMU71ae4nGddMHKYP3TPPPLOqmmw677zz2qsvxyfvW3fddcs555xTnnrqqXG+o6mZ7Pygz5vUeTup5p133qpyNX0Id2xrEtPXXXdd1baJle4+uoqDZr+5XXXP8EHTL9XpieeTTjqpvPbaaz2Osd/+9rfj3LbffvvquQsuuKDqsqR58mGWWWapnu8YI/nO3//+91WFfMfK41QAp02pmE83CgAAdafiFgCgm1IlutZaa5XLL7+8ut85cXvggQdWXSjkMu30fZuBpJJsS4XopZdeOtbl3J1lIK0f/OAHVWJ11113rQbmStIyfXWOGjWq135DkrY//vGPy4477lhVL6avzyQ6k+C86qqrytprr11dYt5XktA7+uijy0EHHVRdBp+BsIYOHVpNoyTg0q/qfvvtV13untd99atfrSpuk7jLa1It+UF93MYpp5xSDSSW39jsqzXfl9+YpHszwRjf/e53q+mQ7/zkJz/ZZfXqpMzb3pCkY747XRgkPt58881y6qmnVn0YH3744RP9uccff3y5//77q4R6BjuL9BebBGl+41577TXBeZnEaeI08zDTLf0AZ1r/7Gc/q9qb+M1AbfPPP381QF4Gn0sMJrE6PomJzprzLJ+ZCuPICYDEysEHH1zWWGONstNOO1UVtuk+IX1QZ6CypsRWulRIlXz6Be74XGSQtwzI1pTYi0ceeaS9a5Hbb7+9+jvfBwDQChK3AAA9kGRtBk5affXVy+KLLz7Wc0n85LkDDjigSqq99dZbVTIsSaottthigp+bZFKSZanm3WeffaoKziSLcrn4zTff3Ku/4XOf+1zVR+hxxx1XJQTffvvtKrGWwcaSZOtrSYKmm4RUTqbytjmo2qabblo+9alPtb8uCdck4tLGXOKevlevuOKKqruKD5LL6TNoVV6bRHXmRbocyMBVTenm4qijjqoSj9dcc011aX0SsV0lbidl3vaGdDmQNh522GFVjCTJvN5661WJ154MRNZZqk8TY7fcckvV5+sbb7xRVfgmkZ1pN6HPThuSvE4Sfvfdd6+6LUhiPe9Zf/31q+rkTN+cCEgVbPpUTmI3yfjekqR7vu/kk0+uYimxnPlyySWXlK233nqs6vVm1xs5adFZEsodE7edYyzV200StwBAqwxqtGqEBAAAAAAAukUftwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDNTlwFuzJgxZcSIEWXo0KFl0KBB/d0cAAAAAGAK1Wg0yquvvlrmm2++Mnjw4Ck7cZuk7YILLtjfzQAAAAAAqDz99NNlgQUWKFN04jaVts2JMfPMM/d3cwAAAACAKdSoUaOqItNmznKKTtw2u0dI0lbiFgAAAADob93p0tXgZAAAAAAANSNxCwAAAABQMxK3AAAAAAA1M+D7uAUAAABgYBk9enR59913+7sZMI5pppmmTDXVVKU3SNwCAAAAMFloNBrlueeeKyNHjuzvpsB4zTLLLGWeeebp1gBkEyJxCwAAAMBkoZm0nWuuucoMM8wwyYkx6O0TC2+88UZ54YUXqvvzzjvvJH2exC0AAAAAk0X3CM2k7eyzz97fzYEuTT/99NX/Sd4mViel2wSDkwEAAABQe80+bVNpC3XWjNFJ7YdZ4hYAAACAyYbuEZhSYlTiFgAAAACgZiRuAQAAAGAKrg793e9+16ffscgii5Qf/ehHffodA5HELQAAAAD0sbvuuqsaqGqLLbaYbBKfn/zkJ8vmm2/e5XO33XZblfR96KGHWt6uKYXELQAAAAD0sbPPPrvsscce5dZbby0jRowok4Ndd921XH/99eU///nPOM+de+65ZdVVVy0rrLBCv7RtSiBxCwAAAAB96LXXXiu//vWvy9e+9rWq4va8884b5zW///3vy2qrrVamm266Msccc5TPfOYz1ePrr79+efLJJ8vee+9dVbg2B746/PDDy0orrTTWZ6QqN9W5TX/605/KJptsUn3esGHDynrrrVceeOCBbrf7E5/4RJlzzjnHaW9+z8UXX1wlduPSSy8tH/7wh8u0005bff/3v//98X7mE088Uf2GP//5z+2PjRw5snrs5ptvru7n/0GDBpVrr722fOQjHynTTz992XDDDcsLL7xQrr766rLMMsuUmWeeuXzuc58rb7zxRvvnjBkzphx77LFl0UUXrd6z4oorlksuuaRMriRuAQAAAJjsNBqlvP56/9zy3T3xm9/8piy99NJlqaWWKl/4whfKOeecUxodPuSqq66qErUf//jHy4MPPlhuvPHGsvrqq1fPXXbZZWWBBRYoRx55ZHn22WerW3e9+uqrZeeddy633357ufvuu8sSSyxRfUce746pp5667LTTTlXitmN7k7QdPXp02WGHHcr9999ftttuu/LZz362PPzww1VC+ZBDDukyOd1Thx9+eDnttNPKnXfeWZ5++unqe5KcvvDCC6tpdt1115VTTz21/fVJ2l5wwQXlzDPPLI888kiV7M70vuWWW8rkaOr+bgAAAAAA9FQKLWeaqX+++7XXSplxxp51k5AEYqTP2FdeeaVKJqaaNr73ve9Vic8jjjii/T2pFo3ZZput6ht36NChZZ555ulRO1Ol2tFPf/rTMssss1TfnWra7vjSl75UTjzxxLHam24Stt5666qK9wc/+EHZaKONqmRtLLnkkuVvf/tb9Z4vfvGLZVIcffTRZe21167+TnXvQQcdVP7973+XD33oQ9Vj22yzTbnpppvKAQccUN5+++1yzDHHlBtuuKGsueaa1fN5XZLWP/nJT6pq48mNilsAAAAA6CPDhw8v9957b1Wd2qxi3X777atkblO6DUjys7c9//zzZbfddqsqbZNkTfcC6ebgqaee6vZnpFJ4rbXWqqqE41//+lc1MFmzm4S///3v7cnVptx/9NFHq6rcSbFCh/5z55577jLDDDO0J22bj6X7hGa70m1CuoaYaaaZ2m+pwE2yd3Kk4hYAAACAyc4MM7RVvvbXd3dXErTvvfdemW+++dofS7cD6Q823QAkoZr+WHtq8ODBY3VfEO++++5Y99NNwn//+99y8sknl4UXXrj6zlSjvvPOOz36riRpM7Da6aefXlXbLrbYYhNdwZp2R8e2d2530zTTTNP+d/q87Xi/+Vj6tY0kpCNdKMw///xjvS6/e3IkcQsAAADAZCdjdPWku4L+kIRtKj4zWNemm2461nNbbrllueiii8ruu+9eVZamX9tddtmly88ZMmTIONWrGTTsueeeqxKgzQHLOg74FXfccUc544wzqn5tI/3EvvTSSz3+Helbds8996z6ls3vySBrze/MQGH5ns7fmy4T0sVDZ2l3pK/eDDzWVbsnxrLLLlslaFNNPDl2i9AViVsAAAAA6ANXXnllefnll6uK1VTWdpQ+YlONm8TtYYcdVnWVkErW9HWbhO8f/vCHqu/WWGSRRcqtt95aPZfk5BxzzFH1N/viiy+WE044oerr9ZprrilXX3111R1CU7pI+PnPf15WXXXVMmrUqLL//vtPVHVvuhxI9w7pYzaf07Hv2n333besttpq5aijjqpec9ddd1WVxEkYdyXfv8Yaa5TjjjuuLLroolVXBwcffHCZVEOHDi377bdfNSBZqnDXWWedqi/hJJEzTVJ9PLnRxy0AAAAA9IEkZjfeeONxkrbNxO19991XHnrooSoJe/HFF5crrriirLTSStWgYukXt+nII48sTzzxRJXYbVasptI1ydF0X5CBzPL6JC47f38SxyuvvHLZcccdy7e+9a0y11xzTdRvSfI5n7XZZpuN1e1DPvs3v/lN+dWvflWWW265cuihh1btndDAZOkvN8npVVZZpey1117VIGS94aijjqoGSTv22GOr6ZOB4NJ1QhLEk6NBjc6dYQwwOQuQhSMZ9o5nHAAAAACYfLz11lvl8ccfr5Jw0003XX83ByYqVnuSq1RxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAz/Zq4HT16dDnkkEPKoosuWqaffvqy2GKLlaOOOqo0Go321+TvQw89tMw777zVazbeeOPy6KOP9mezAQAAAKB2vvjFL5Ytt9yy/f76669f9tprr5a34+abby6DBg0qI0eO7LPveOKJJ6rv+POf/1wGqn5N3B5//PHlxz/+cTnttNPK3//+9+r+CSecUE499dT21+T+KaecUs4888xyzz33lBlnnLFsttlm5a233urPpgMAAABAt5KpSTDmNmTIkLL44ouXI488srz33nt9/t2XXXZZVSRZl2RrvPPOO2WOOeYoxx13XJfPp71zzz13effdd8uUrl8Tt3feeWf59Kc/XbbYYouyyCKLlG222aZsuumm5d57722vtv3Rj35UDj744Op1K6ywQrngggvKiBEjyu9+97v+bDoAAAAAdMvmm29enn322eoq8n333bccfvjh5cQTTxxvYrO3zDbbbGXo0KGlTpK8/sIXvlDOPffccZ5LLvC8884rO+20U5lmmmnKlK5fE7drrbVWufHGG8s///nP6v5f/vKXcvvtt5ePfexj1f3HH3+8PPfcc1X3CE3Dhg0rH/3oR8tdd93V5We+/fbbZdSoUWPdAAAAAKC/TDvttGWeeeYpCy+8cPna175W5bquuOKKsbo3+N73vlfmm2++stRSS1WPP/3002W77bYrs8wyS5WATVFjugfo2AXpPvvsUz0/++yzl29/+9tjdT/aVVcJyZsdcMABZcEFF6zalOrfs88+u/rcDTbYoHrNrLPOWlXepl0xZsyYcuyxx7Z3dbriiiuWSy65ZKzv+cMf/lCWXHLJ6vl8Tsd2dmXXXXet8oHJA3Z0yy23lMcee6x6fsyYMVVl8gILLFC1daWVVirXXHPNeD8zCd9Mi45S+Jnf0pSEeT7nnHPOKQsttFCZaaaZyte//vVqWuaq/8yjueaaq5oXHaUK+ctf/nKZc845y8wzz1w23HDDKo/Z16Yu/ejAAw+sEqtLL710mWqqqaqJlAnz+c9/vno+SdtIeXRHud98rrME0hFHHNGC1gMAAADQb5KkfOON/vnuGWYopUNCsKeS4Pzvf//bfj+FjUkIXn/99dX9dBOQrkLXXHPNctttt5Wpp566HH300VXl7kMPPVRVrX7/+9+vkpVJQi6zzDLV/d/+9rdVUnF8UsmaYsh0S5oEbIomX3rppSqRe+mll5att966DB8+vGpL2tjMtf3iF7+oujFdYoklyq233lpVzCaJud5661UJ5q222qp84xvfKF/5ylfKfffdV1UVT8jyyy9fVltttart66yzTvvjqcJNoWdyhT/84Q+r3/STn/ykfOQjH6le+6lPfao88sgjVTsm1r///e9y9dVXV0ng/J0eAJIsTuI5ieP0EPClL32pSq6neDS23XbbanrkfSkqTZs22mijKvmcpPqATNz+5je/Kb/85S/LhRdeWD784Q9XnQnnLEDOLuy8884T9ZkHHXRQdbahKYnhBB8AAAAAA0iStjPN1D/f/dprpcw4Y4/florYJGmvvfbasscee7Q/njGdfvazn1UJ2UiiNBWneaxZMZqkZipK0xdtuhpN96LJgyVpGkms5nPHJ0nG5OKSHG5e3f6hD32o/flmAjIVp83K1VToHnPMMeWGG26oksjN96RSNsnLJG4zftViiy1WJVkjFcMPP/xwNZbVhKSqdr/99quSyKl8ffXVV6tK3tyPk046qaoO/uxnP1vdz+fddNNN1e8+/fTTy8TKdE0SOF1ILLvsslWFcJLVqRoePHhw1f7mdyVxm9+abl1feOGFqvK32bZU86a9SVYPyMTt/vvvX1XdNmdAsu1PPvlklclP4jblyfH888+Xeeedt/19uZ+y5q5kAjYnIgAAAAD0tyuvvLJKTqaSNonDz33uc9Vl+03JiTWTtpHL8P/1r3+N0z/tW2+9VVWJvvLKK1Wfuc2K0EhV7qqrrjpOdwlNKZjMFe9JtnZX2vDGG2+UTTbZZJx+eFMFG3//+9/Hakc0k7wTssMOO5S99967SianwvXXv/51lTjdfvvtq0LMESNGlLXXXnus9+T+pHZRkHG2Ok7XXNmf6ZLv7vhYErWR73vttdeq7ig6evPNN6t50Zf6NXGbGd9xokQmVAI40ndGkrc5E9FM1GbG3XPPPVV/IAAAAABModJdQSpf++u7eyBVnalMTXI2V5onydpRKm47SqJwlVVWqa5U7yxdFEyMZtcHPZF2xFVXXVXmn3/+sZ6b1MLJdMeQbgpSSZzEbf5Pn75JcE/MmFWDBw8eJ2mdRHlnnQc9S0VzV48185OZBikoTaVzZ5371B1QidtPfvKTVZ+26Qw4XSU8+OCD5Qc/+EE1s5oTKV0npA+P9F2RRO4hhxxSBXg6bQYAAABgCpUuBCaiu4L+kMRsBgLrrpVXXrmqQE23BUlwdiXJxBQ3rrvuutX99957r9x///3Ve7uSqt4kI9OPa7OrhI6aFb8Zg6opXQkkQfvUU0+Nt1I3/es2B1pruvvuu7v1O9NdQgZQS0Vy+pY98cQTq8fzm+ebb75yxx13jPW9ub/66qt3+VlJaKe7hddff709EZ4q40mV6ZmxtpJsT7VuK41d7tpip556apVZz+htmcnp1+KrX/1qOeqoo9pfkxHx0udH+otIp8XJcqfz4Ommm64/mw4AAAAAfeLzn/98mWOOOcqnP/3panCyDCKWis9vfetb5T//+U/1mj333LMcd9xxVV+r//jHP6r82siRI8f7mUk6pmvSFEzmPc3PTFcFsfDCC1dFlEmivvjii1UOLl0KJF+XLg3OP//8qmuABx54oMrp5X7svvvu5dFHH626RE1fsRnLKoOmdUeSzkloZ9C0DEiWgcma9t9//6qv2SSw87npbjWJ2PzurqS7hhlmmKF85zvfqdrZk3ZMSJLc6fohRaTXXXddeeKJJ6ok83e/+91qILYBm7jNzE+HwunXttkvRKprO/bpkYA58sgjq8x2+vFIZ8gZ5Q0AAAAABqIkIG+99dbqKvUMPpaCx1SnJjfWrMDdd999y4477lglY5NYTJ7tM5/5zAQ/N901NIsokyjdbbfdqgrVSFcIRxxxRJUgTR+v3/zmN6vHU2CZK+AzJlXasfnmm1ddJ+TK+EgbL7300ioZvOKKK1aDpGVAs+5I3i+J5Jdffrn9Cvymb33rW2WfffapfmeqhVPImcreXJXflQyulkHdMshYXn/RRReN1Y/wxEob85lJMu+yyy5VXjLjdSWfmenUlwY1xtdj8QCRPjGGDRtWddo8vtJyAAAAAOotSctUiSZh6EpsJtdY7Umusl8rbgEAAAAAGJfELQAAAABAzUjcAgAAAADUjMQtAAAAAEDNSNwCAAAAANSMxC0AAAAAk40xY8b0dxOgJTE6da98CgAAAAD0oSFDhpTBgweXESNGlDnnnLO6P2jQoP5uFrRrNBrlnXfeKS+++GIVq4nRSSFxCwAAAEDtJRG26KKLlmeffbZK3kJdzTDDDGWhhRaqYnZSSNwCAAAAMFlIBWMSYu+9914ZPXp0fzcHxjHVVFOVqaeeuleqwSVuAQAAAJhsJCE2zTTTVDcYyAxOBgAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADXT74nbZ555pnzhC18os88+e5l++unL8ssvX+6777725xuNRjn00EPLvPPOWz2/8cYbl0cffbRf2wwAAAAAMGATty+//HJZe+21yzTTTFOuvvrq8re//a18//vfL7POOmv7a0444YRyyimnlDPPPLPcc889ZcYZZyybbbZZeeutt/qz6QAAAAAAfWZQIyWt/eTAAw8sd9xxR7ntttu6fD5Nm2+++cq+++5b9ttvv+qxV155pcw999zlvPPOK5/97Gc/8DtGjRpVhg0bVr1v5pln7vXfAAAAAADQHT3JVfZrxe0VV1xRVl111bLtttuWueaaq3zkIx8pZ511Vvvzjz/+eHnuueeq7hGa8sM++tGPlrvuuqvLz3z77berCdDxBgAAAAAwOenXxO1jjz1WfvzjH5cllliiXHvtteVrX/ta+da3vlXOP//86vkkbSMVth3lfvO5zo499tgqudu8Lbjggi34JQAAAAAAAyRxO2bMmLLyyiuXY445pqq2/cpXvlJ22223qj/biXXQQQdVpcbN29NPP92rbQYAAAAAGNCJ23nnnbcsu+yyYz22zDLLlKeeeqr6e5555qn+f/7558d6Te43n+ts2mmnrfqH6HgDAAAAAJic9Gvidu211y7Dhw8f67F//vOfZeGFF67+XnTRRasE7Y033tj+fPqsveeee8qaa67Z8vYCAAAAALTC1KUf7b333mWttdaqukrYbrvtyr333lt++tOfVrcYNGhQ2WuvvcrRRx9d9YObRO4hhxxS5ptvvrLlllv2Z9MBAAAAAAZm4na11VYrv/3tb6t+aY888sgqMfujH/2ofP7zn29/zbe//e3y+uuvV/3fjhw5sqyzzjrlmmuuKdNNN11/Nh0AAAAAoM8MajQajTKApWuFYcOGVQOV6e8WAAAAAJgccpX92sctAAAAAADjkrgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAABgIidvbbrutfOELXyhrrrlmeeaZZ6rHfv7zn5fbb7+9t9sHAAAAADDF6XHi9tJLLy2bbbZZmX766cuDDz5Y3n777erxV155pRxzzDF90UYAAAAAgClKjxO3Rx99dDnzzDPLWWedVaaZZpr2x9dee+3ywAMP9Hb7AAAAAACmOD1O3A4fPrysu+664zw+bNiwMnLkyN5qFwAAAADAFKvHidt55pmn/Otf/xrn8fRv+6EPfai32gUAAAAAMMXqceJ2t912K3vuuWe55557yqBBg8qIESPKL3/5y7LffvuVr33ta33TSgAAAACAKcjUPX3DgQceWMaMGVM22mij8sYbb1TdJkw77bRV4naPPfbom1YCAAAAAExBBjUajcbEvPGdd96pukx47bXXyrLLLltmmmmmUkejRo2q+t995ZVXyswzz9zfzQEAAAAAplCjepCr7HHFbdOQIUOqhC0AAAAAAL2rx4nbt956q5x66qnlpptuKi+88ELVbUJHDzzwQG+2DwAAAABgitPjxO2uu+5arrvuurLNNtuU1VdfvRqgDAAAAACAfkzcXnnlleUPf/hDWXvttXuxGQAAAAAANA0uPTT//POXoUOH9vRtAAAAAAD0VeL2+9//fjnggAPKk08+2dO3AgAAAADQF10lrLrqqtUAZR/60IfKDDPMUKaZZpqxnv/f//7X048EAAAAAGBSErc77LBDeeaZZ8oxxxxT5p57boOTAQAAAAD0d+L2zjvvLHfddVdZccUVe7stAAAAAABMTB+3Sy+9dHnzzTf7pjUAAAAAAPQ8cXvccceVfffdt9x8883lv//9bxk1atRYNwAAAAAAJs2gRqPR6MkbBg9uy/V27ts2H5PHRo8eXeokyeRhw4aVV155pcw888z93RwAAAAAYAo1qge5yh73cXvTTTdNStsAAAAAAPgAPU7crrfeej19CwAAAAAAfZm4vfXWWyf4/LrrrtvTjwQAAAAAYFISt+uvv/44j3Xs77ZufdwCAAAAAExu2kYa64GXX355rNsLL7xQrrnmmrLaaquV6667rm9aCQAAAAAwBelx4jajnnW8zTHHHGWTTTYpxx9/fPn2t7890Q057rjjqsrdvfbaq/2xt956q3zjG98os88+e5lpppnK1ltvXZ5//vmJ/g4AAAAAgAGZuB2fueeeuwwfPnyi3vunP/2p/OQnPykrrLDCWI/vvffe5fe//325+OKLyy233FJGjBhRttpqq15qMQAAAADAAOnj9qGHHhrrfqPRKM8++2xVMbvSSiv1uAGvvfZa+fznP1/OOuuscvTRR7c//sorr5Szzz67XHjhhWXDDTesHjv33HPLMsssU+6+++6yxhpr9Pi7AAAAAAAGZOI2ydl0aZCEbUdJpJ5zzjk9bkC6Qthiiy3KxhtvPFbi9v777y/vvvtu9XjT0ksvXRZaaKFy1113SdwCAAAAAANWjxO3jz/++Fj3Bw8eXOacc84y3XTT9fjLf/WrX5UHHnig6iqhs+eee64MGTKkzDLLLON0yZDnxuftt9+ubk2jRo3qcbsAAAAAACarxO3CCy/cK1/89NNPlz333LNcf/31E5X0HZ9jjz22HHHEEb32eQAAAAAAtUzcnnLKKd3+wG9961vdel26QnjhhRfKyiuv3P7Y6NGjy6233lpOO+20cu2115Z33nmnjBw5cqyq2+eff77MM8884/3cgw46qOyzzz5jVdwuuOCC3W4/AAAAAEB/G9To3FltFxZddNHufdigQeWxxx7r1mtfffXV8uSTT4712C677FL1Y3vAAQdUydZ0wXDRRReVrbfeunp++PDh1fM96eM2idthw4ZVg53NPPPM3XoPAAAAAEBv60mucuqJ6de2NwwdOrQst9xyYz0244wzltlnn7398V133bWqnp1tttmqH7LHHnuUNddc08BkAAAAAMCA1uM+bjtqFuum0rYv/PCHP6wGP0vFbQYc22yzzcoZZ5zRJ98FAAAAADBZdZXQ2QUXXFBOPPHE8uijj1b3l1xyybL//vuXHXfcsdSNrhIAAAAAgAHZVUJHP/jBD8ohhxxSvvnNb5a11167euz2228vu+++e3nppZfK3nvvPfEtBwAAAACg5xW3GajsiCOOKDvttNNYj59//vnl8MMP75P+cCeFilsAAAAAYHLLVQ7u6Yc/++yzZa211hrn8TyW5wAAAAAAmDQ9Ttwuvvji5Te/+c04j//6178uSyyxxCQ2BwAAAACAbvdx+9e//rUst9xy5cgjjyzbbbddufXWW9v7uL3jjjvKjTfe2GVCFwAAAACAPqq4XWGFFcpHP/rRagCyP/7xj2WOOeYov/vd76pb/r733nvLZz7zmR5+PQAAAAAAE11xe8stt5Rzzz237LfffmXMmDFl6623Lj/84Q/Luuuu292PAAAAAACgNytu/+///q+cc8451QBkp556anniiSfKBhtsUJZccsly/PHHl+eee667HwUAAAAAQG8OTjbjjDOWXXbZparAHT58eNl2223L6aefXhZaaKHyqU99qqcfBwAAAABAJ4MajUajTILXX3+9/PKXvywHHXRQGTlyZBk9enSpk1GjRpVhw4aVV155pcw888z93RwAAAAAYAo1qge5ym73cdvZrbfeWnWdcOmll5bBgweX7bbbruy6664T+3EAAAAAAExM4nbEiBHlvPPOq27/+te/ylprrVVOOeWUKmmbLhQAAAAAAGhh4vZjH/tYueGGG8occ8xRdtppp/KlL32pLLXUUr3QBAAAAAAAJipxO80005RLLrmkfOITnyhTTTVVd98GAAAAAEBfJW6vuOKKnn42AAAAAAATYfDEvAkAAAAAgL4jcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAzErcAAAAAADUjcQsAAAAAUDMStwAAAAAANSNxCwAAAABQMxK3AAAAAAA1I3ELAAAAAFAz/Zq4PfbYY8tqq61Whg4dWuaaa66y5ZZbluHDh4/1mrfeeqt84xvfKLPPPnuZaaaZytZbb12ef/75fmszAAAAAMCATtzecsstVVL27rvvLtdff3159913y6abblpef/319tfsvffe5fe//325+OKLq9ePGDGibLXVVv3ZbAAAAACAPjWo0Wg0Sk28+OKLVeVtErTrrrtueeWVV8qcc85ZLrzwwrLNNttUr/nHP/5RlllmmXLXXXeVNdZY4wM/c9SoUWXYsGHVZ80888wt+BUAAAAAAJOWq6xVH7dpcMw222zV//fff39Vhbvxxhu3v2bppZcuCy20UJW4BQAAAAAYiKYuNTFmzJiy1157lbXXXrsst9xy1WPPPfdcGTJkSJllllnGeu3cc89dPdeVt99+u7p1zGIDAAAAAExOalNxm75u//rXv5Zf/epXkzzgWcqNm7cFF1yw19oIAAAAADDFJG6/+c1vliuvvLLcdNNNZYEFFmh/fJ555invvPNOGTly5Fivf/7556vnunLQQQdVXS40b08//XSftx8AAAAAYMAkbjMuWpK2v/3tb8sf//jHsuiii471/CqrrFKmmWaacuONN7Y/Nnz48PLUU0+VNddcs8vPnHbaaauOfTveAAAAAAAmJ1P3d/cIF154Ybn88svL0KFD2/utTRcH008/ffX/rrvuWvbZZ59qwLIkYffYY48qabvGGmv0Z9MBAAAAAPrMoEbKXvvJoEGDunz83HPPLV/84herv996662y7777losuuqgadGyzzTYrZ5xxxni7Sugsg5MlAZxuE1TfAgAAAAD9pSe5yn5N3LaCxC0AAAAAMLnlKmsxOBkAAAAAAO+TuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsGrHffLWXUqP5uBQAAANTHO+/0dwuA7pK4ZUBKwnbVVUuZf/5SHnus776n0ej5e95+u5Qrryzlttsm7v3dkc9+4omev+/uu0v57ndLOfLIUl56qffb9dprbb/9X//q2W8fM6aUY48t5aMfLeWrXy3l2WdLrfzpT6V885ul7LNPKf/7X3+3hnjrrVIuuKCUU04pZeTInr33iitK+d73SvnlL/tmOYjHHy/lzTd7/r4f/aiU1Vcv5etfL+XOO3u/XQ89VMpPf1rKtdf2/L0PPljKOeeU8o9/lD7x4oul/PWvpbz8cs/e9/TTpXzyk6XsvXcpzz3XN23LdibLfk/X6Xn9739fyvnn9932gJ7LvLzllrbY6elB8EEHlbLLLqXcfHPvt+uVV0q5//5SRo/u+XuzHU2cZft+++0T9xnd8cILpbz+es/e88wzpWywQdt2NO2sk6ynL764lJNO6rtigEyviVl3/OY3pXz2s6Xsv38p//5337SNnsu8SfHIxPjd70rZbLO2/ZC+kHXUxGxr8nsuvLCUX/964n/bhLz3XimPPFLKww+3/d3TY56s137+87Z9q96W47a0a2Km2003lfLxj5ey+eZtv6+33XFH2+/uaduynj3rrFKmnbaUueZq27+iHq67rpSrr27bLvZEjvu/+MW2fZARI0qtXHVV23bq4IPbcgFMpMYA98orr2RVVv1Pz4wZ02j897+Nxs9/3mh8//uNxqGHNhrf+U6j8ctfNhpXXdVoXHddpm/fffdRRzUaw4ZlU9RorLJKozFq1PvPv/NO22s6Gj260bjhhkbj+OPb3tPxdt55vde2l19uND75yUZj6NBGY9ppG41ttmk0/ve/8b/+vffapuGppzYaW2/daCywwPvtyu+7777ea1umwQEHvP/5X//6uNMpMt9efLHRePrpRuOppxqNP/yh0dhzz7Gn2SKLNBovvNB7bTvxxLE//6tfHfc1aWum5XPPNRqPPdZo3HRTo/HZz447P3NLDPaWxx9vNLbY4v3Pvv/+sZ9Pm669ttF4++1G4y9/aTQuu6zR2GefRmO77RqNueYau13LLttovPlmo0+99VajceSRjcaCC7Z95wwzNBqbbNK2fP7xj43GM880Gk880bY8JP76Q+Lriiva4urLX240Dj+80dhvv0bjuOPa2v7FLzYaw4f3zXcnflZf/f158n//N+HXZ3m4/fZG43vfazR23HHs+fmhD7Ut873l+efHjpkdduh6Gc1jzcezHr7ggkbjm98cu22zzda2Luwtv//92J9/443jviaxffHFjcY//tFovPZa27Q755xxl4P992/0qgsvbDSmnvr9z//zn8dtV+fpmOX2G98Yd92x1VaNxrvv9k678p1nntloDBrU9tkrrtg2T7Jeba4HXn+90XjggbblMstF2n7aaY3GeuuN3a411mg0fvzjvl9/3H132zK5xBKNxpprNhobb9xofO1rbbcsN3PM0WgsumijcfDBjcb11zca//xno6X+859G48ADG4111200Nt+80Zh++kZj000bjaWWalsel1uu0fjd7ya83Z0Uzz7baCy00PvzJeuuzjrH2pNPtm0bll567Hma9vdWrMVaa73/2dmXyPa+q/VHs425ZT177LHjLgfrr9+2z9Ab8j2J6WyL8tlZVh99dMLtGjGibb8y78t87bjOTdz1lmy3P//599cf2UZP6POz7N57b6Nx2GHjTrP55280br2199qWdfu227Z9dpa7I454f55kvZFl4a9/bTTuuqvtuY9/vG27P++8jcZKK43dtmmmaWt3X3r11bZ9s+z/NL/3Ix9pNHbeuW0ZzTbq5JPb1iXZll599fjjs69k/XnJJY3GD3/YdhyRdeqll7Ztk/J/2p95mP2o3pb9raxbs85qTp/sX3eluf2MtCXzbsstxz4++Ne/erdtu+zy/udnn3FCx3DNOEyMZlrmmKf53qwfH36499qW7WK2nc3Pz/54x7jJ9ElbTzml7VgixyaZrl/5yrjLaKZ95/2DSZHlb6aZ3v/8bJc673cl5jI/M82y/chxcvZxs23t2Lasg7KP3lsyDTouh9mP7Sj7HFkec8yS7f4ttzQaBx3Utp0fPHjstq28cu8e83Ul8zHrss98pm0939xvXGyxRmPmmdviKr8j29Ef/KB39297Ivv8P/tZo3H66Y3Gb37Tti3I8VWmY46rMi17c7veUX53x/mSfe2uZPlIvI0c2dbOj31s7PdlfynbkN6S5W+FFdo+e8MN2/YpEvPjk3l3zTWNxjHHtO2zdWxbciit3i4MlFzlZJG4Pe200xoLL7xwY9ppp22svvrqjXvuuafb75W47bms2E86adwFravbfPO17bBl4exNZ5017nclSbHXXu8nq+aZp9FYZ51GY5llPrid2aG97bbeadvnPjfu5y+8cNuBQefHO+7ojO8244xtB3yTKjsOO+007ucPGdK2QV511bb7nTfWH3TrjR2g7Mg0D+g636aaqq2N2Wj3pF253XzzpLftpZfa5l9Xn//Rj7bFeHfakiR+8+8ll2xLZvX2hv1Pf2pLqPdkGs06a9vJhSS+sgPelxvLfPaddzYae+89dpJtQrcvfantQKo3JSHR+XtyUHnuuW0Hv0m4Z8cjjyV59UFt3HXX3mlXdmRyEqqr9VNiMMtodvSzw5XHm8nACd0yb3MwPamSIEhSYkLflQR4T2IvO2y9IQf/neMpy1t2VGeZ5f2TYVk2sj7JY0nOTGhdl4PWN97o/Z3szrcPmqbju/XmDncz9pK4mJi25JaEUV8nhXIQ8tvfdr9N2SfICeTeXKflQGTxxcf9rhywbLZZ2/LWXGfMPXdbnH34wxNu5wkn9E7bkijp6vOTwEuyKAe8zX2jHBBnWejq9R23xTlx1BuSHOvqu7J/mIPy/N38v7u3H/1o0tuV2PjUp8b/HZlWSRZkXiZx2p3ta9Y9ORnfGzbYYOKXyfHdkjDKwXxvyiFUTrZPTHuyXctJoL5IlHaUE0w5wd6TfaTvfrf3Tl7E+ed3/T05bsh+UZLZ2V51XAbHt5zmltjMiYTeWA52223C0yIJz5wYyn5R80TKhLahOXmQpGZvnFjJvvb4lrWsY7u7P9m8Zf2XgoxJle1w55NxuWV9kX225Zf/4PV/V8d8vVGwk+KMro4xs287KeuP7NP0tpzE65xY7O4tJzOS7G2FJK6zLe3ucXJXJ3UnRU4odv6OHBuneG733dtiMfsi2VY1n59QW7O+6Y31Wz5jfPuyyS9kWcjzzRPeHU90jO+W/am+LlKYXAyoxO2vfvWrxpAhQxrnnHNO45FHHmnstttujVlmmaXxfMqWukHitvty8J8zKN1JFmRnt+P9vCdn2HujMifJrlT75HP33betUnViVvap9MtKeM45339sUqs4crat+VlJIqfqs6c7FM1kaKpdm1WB2TnJWeQkcCe2QrK5U5adwBwo9qQ92fjnbHeqX3Lg+pOfjP18drqT8EqbJ0az6i3zNdWs3UmW5ZaEbjOpmjPrWcmnyqrjRiHT7gtfmLid2xxIbLRR2+fMPvvYVVbdueWsYXbIzzijbcOW+JhuurFf8+lPt+3c5rsmNsGQ93aslOg4fbIRzwFxkpX5rg86WZAz3Tm4SDVzbyY8OsdMc+c2B6ZJHqet4ztwTwImO4u9kUjLMtlMhibWJvZgMyePUpXTXB8mwTGx8d+56jyfmbP5zUqr7tzynpwcynTOdOqcMEwc5mqDVP71dB2SdW52vvI5mVeJj47rze7ekqTJlRGJw+ZjWb5SYZJld2Lmb9ZHOUBszoNU/kzM/Mw6MfHeebqttlrbdmZ8VQ0Tkvc0T9h8+9tt68metClxn+U6FR3//ve41TmZ3xdd1NbuHNxO7PKa7U3HSs3cktzOgVSSY4mbrENTfZs46urER/OWqvQcMKZasmlSl9usO1ONn3Vw5+9Lmz5oOuY1vVXZl0rffGa2MX/7W1vCuifzNMmP7Bskyd2M29wSY5OSSMgJxubJ9My37CvssUfPl4MkMZOM+Na33n8s+1iptu94VVNPZPvW3O5lffurX3Wd/B7fLUmbJLVycJ+Ti5/4xPvPZb8jV25M7ImMjhVpSWjmoHxCibKubkli5TemKrBzUjBJpVR1Tsx+29lnt31G2pPlsCdtyn5n4iwVpJlu2f9JW5rPJ/YSH5mvk7pcpHo129OO35/9xcynVNhm3z8nQ7MvknXYhOZ9Xv/gg+8nE7JdyDyfFFn/dLXO6ngyvblsdt4/yy0nU3ujijr7ac2KtCwHmT89XT4z/XKCJpW2zSKV7DdleZ+U+ZirZJpJnlQONk/ydPeWaZnflu1R1v3NdVGqglMUkGV+YhPMqbhvbg///vdxr877oFvel/V04ijr2OYxQxKkWe9mGZiYIopM72YxTBLtueopSe3urjOyb5ErLnKSJ+uH7Mt03MZn3zhXFGaa9rR9ORHbvGIn8yKFSakEHl97sm3NNr+5vknRU+Zb1mv5nUkkZ3+943vStkzTpE8mNvayfGfbnnnR8bOzDcu+egpccgVUTqBkeUl8rr1218nI5B2So8jVS9kf6i1ZF2Va5ArVjidUso5NbCVJmgKx5vTpnJRMcnRS12HNbXyzUCjbxI7bwe7ccnyddUX2hTpu9/JYptmkyDau43dNzPFBCgeSZ+p8VXTWv71ZhT45GlCJ21TYfiNZn/9v9OjRjfnmm69xbJbebpiSErdZ+eQALWemenIJYVbIWWl1PpuSg8asAJo7pB0PzvKeVGh1lSDM2bGsqHM7+ui2NvXkcoeswPM5WVk2d9ZzYJGNcTZQWXlmY5rEbBIFueWMZ3ZEsvHp6hLGju1LYiu/LQdoOVvW3YOp/N7mhi87Pk2Z3jnoTeKjeTYsVYS5zDjVh7l0JZWhaVcOeDue/cqKuqud3BxcJEHT3bDNjnDzYCRJgMj3ZYc73TOkTdlJyE5rLpPJTlYOLNOu8V2KlURC55315g5JDjK6u+HMd3W+9Do7uLnkKZVC2UDlzFtiJfGUyzpzwJx4G9/GMAm5rhJb2bDnYKU7l/skJrNT1dwpa1Y9J97Ttp/+tC15l4OrtDvxnMdTPZzXji9usuM5oR3MtC+Vs91ZJnJxQTaYnQ8Wk+x56KHxvy/TN+uATIfsGCXh1XnHKbfmZUrZEUnSOp/761+3xXp3d9QSox2TAM0NcS4f7/gZzb+zk5oDvezE/uIXbRULHc8sZ1k65JC26Z/EWM7RdfegPQfWzZNKuZSzKZ+V5E6SV6m0zHNZ9nMyIMtZloFU+nWVgMrJjI6/LQdTuYwvbe/JZuWOO96/fDLzpCkVQomt7EhnXZad1/z+rONSIZwdmry+q3OVaXNXJ44SL0l4dOdAKvOleUlwkrbNuM7jSS7ngDzPZUc63VzktTkQSncXWZdceeW4FdOZnuNbBrIez2Vd3V1/NHdes1ParNjKzl8q/LLOz45uDmBS3Zs2Zac/699cSp91WJbnzrGcEy1dtS3VlFneunMQlUvpmrGbg7nmdzQPPHNQkljPujK3HIwn8Z/3NeOmc7InBzldVTUkbrJ+z/o4BzmJiQ9qY56//PL3EwnNW5b1zNfuyHKXbVTme1fTq3kVR25Zv2S7lW3whC6f6ywVs50TLNkuZBswIVn/Zb3TMRGTg6us6xKXiYfOl41+kI4HO1m+IzGXbUD2MTIPUnWekweJoSRD8rqsM7NdyPq2Y/Iz2/os0x1/W+ZHkpQ5OdKT/bTmFT3ZL8r6uRk/mTdZRnOQnXVaTiZmHZqD0LQx+wDpOibbzI77HomPjt0DNW/ZDuTxxEh3KiSzHWsmzbIcNGM6y3emU7PKKgd6Sdpl3qTrqlxKnPVyV1cLZFnq2OVTx7ZlXflBsdGU9jcTTHlfU9ZXSehkHZtplWqmbOOzjs4+UbYJOQmTedpZlt3mPmrHW9adOXmebXt3PPLI++9tHuJk/mQfKOuhzNPmPnSWqSRY8vyEtoWZF+Orqmx2N5IkeHf2j/KaxH0zeZhb9r2zLst2pzvryMRCfmdOFnc1vTpWKmY+ZZ88r+9uEjxxkrZ0vMQ+t8Rj9jubXXIkxrIM5O+sYzMNs2+R9VXn7WeWryT4s/3IeqwnCavEVDNJ1txe5wR5TnblmCHzM/s+2c/KPm/iLtuILBdpb7YZHadrtl/NIpaOt+237/4yEPntzatSOh67ZH+pY1cDWWdmXZb93CynOe7K+rmreMl7s63t2K7sI6QoIycxs53rznYg28vm1XZZXzVlP6S5H5Rjq8RGLvnP/E5cZpnI8VRXsqx0rEhs3hJv+Zzudn3Vseuo7Kc1Zb2QdX/2I7M8ZDub45bM8xQHTWi7k/VH53htHoMk+dzdbVbmY3O72+xyLMtNlu+sP/JctlfZPnVcniZU4ZhpPr79tqx7EytZP3Znuch6sPN6Mst41nXd7SItJ6QSj9kedbWfm/355rFRjr2TEOzOvlFH2ZZ2TsbnmDzr4a6O0ZrTL/vW2ddovifTOon67B9k3Z1lPieDursvlHV79u06d3GQ7XYKvJonI/J7M0+Ts8m2PtupxExX39Nx+qd9ibuse7LPML5ujMa3r9X8nCyDzfZ27FYu8yLHHLlaO8t/loN0J5Fjqq6Ok9LdROcTqNlHyDo0x919fXVG3fQkVzko/5Saeuedd8oMM8xQLrnkkrLlllu2P77zzjuXkSNHlssvv/wDP2PUqFFl2LBh5ZVXXikzzzxzGcjSWfyQIe/fn3feUtZYo5R55mnrWH2BBUqZY462ReS//23rwP3RR9sGpGpacMFSDj+8lB13LGWaabr3vRngIp3pH3bY+Dten2WWUrbeupS11y5lvvlKmX32UgYPfv+WgRnSppNPLuWGG9rec955mdelV2QAhy9/ue17Og98McMMpXznO6Usu2zb9Mlt0KBSXn21rQPt/P+f/5Sy335tg1Qss0wpDzxQynTT9U7b8h2Z5vntnTvkHzq0bbploIIMtDbTTG23tCnTPQMwZRChE09sG3Bg441Luf760msyL77ylVKeemrcgUwy3bJYrrNOKR/6UClTTdUWP4m1N95oG9wlHaznd0XmZeZpb8lASPnsDFSW7+kcb9tu29auRRZp63i/Od/TrsTc6ae/P3hMBlvYbrvea1s6X8+AAQst1Na28Q2IlFj68IfbpmX+nn76UmacsW3wtkz7DELTlOcyQMoWW0z8+uGyy9oG7MpAShnIZEIDTCTOll++lFlnLWXOOUtZeum2x7IM/P3vbYP2ZDCDv/zl/ffssEMpxxzTNs27K8vkaae1zY/xDQSUabLbbm2D02X5zPojy1/maW7Dh7fFQzYJWQdlWmbaZZr1hrvuahsAJstBZ4n/DKqT6TPbbG2xljbmdzXXH4mzTJcsQxtt1BYTicHekFhJ2zrGSkcZJCnTbaml2tbpw4a1bQOyvsiyk0Etsn5sDny255690658x89+1jaIWlcDjSy5ZNsyutxybfMy24Xm9isDAGWZycByWY4yrf7wh7b1YG+1LYPPJeYS412tM7O9yLYz8zPr3mb7Ml//9rdSDjywbdC7LBMZMG3hhXunbYnnfO6NN7YNIPWTn7StU7uSmFt55bY4X2GFUqaeum26PflkKddc0zZIVGTdnPXG8ce3vWdiB8XKNLnkku69PtuCbO/TpkybbN+zXUgM5vdk/yPztqPEygkntC3v3ZXfm0Gjfvzjts/vLNMm8zgDw2R/KAOxpE2ZJvk/y2TWGVmnZXuS6b/rrm2x21uy3Uu8PP/8uG1ba622eZhb1ptZ32b/I8tMc/2aAYHuuaftPVl3bLJJ77Qr6/IM9pl1wPjsvnvbOmvuudu2q9mNzjotsZV1T9YZmXZZhrNcLLpo7y2jidesm7L/1XngnMTWJz7R1p7s26Z9Wd9mvmYZzfoig6FkWUi7s73L+rm3ZOC6o49um6dZ/jseSWUZW3/9Uj7ykbZ1SGIucZ/1WF6feDvqqLbX5jX33dd724PIgJrZVzjjjLa2dZa2ZF2a5TIxl21Cvj/xmPZl3ZN1YsfR5jNo3A9+0P3jgs5yrJHBWzM47QdJOzJdsv+UZTTrkqwTsmxk/y3zMr8x7WwO8JlpnIF1s++V5ae7sh7aY4+2WOlK4ipxttpqbduBHFclxiLrikyv7Ldceun7+6HZD/nUp7rfhg9qX/Z98ls7yzFLls1VVmmbh4nz3DL9sm+X9WHm/7e/3bb+zX5m9mGy/9QbcvyRefqLX7StEzrL9yVusixk3mUdkfVa5lmW1QwolkGHI+voLAcdj2EnRfYh8tnHHTfuc2nH//1f237Riiu2xVbirLldyLom+3zf/37b63t7e5D1UwYkvffetnVv5wFwF1+8lK22aluvJeYyTTL98r5sh/OevD+y7/yNb5RelWUh+0eZBuOTdUfma7afib+sWzPtsl3IoHqdB+a86KK2Y6yJXc9lPZ5lOwNBZ39/QjJvs+7ItjPHAlkmsn7ILbJMZBCv7DtkejZlHy/H4l/4QvePHTKAWAYDa+5rdZZ1Ufa90qbmsWgzzrJ8JE4zmG/mYwYGzvo1OZnsD0yqbJNOPbVtUN6uBvzMMUHWs8kbZDqlPR1l/ZH9jizjkW1Gfm9P1q8TknVa1m1dDSaYuM8+W9rfW8dxddajXGWjxp555pkqA31nyhY72H///atK3K689dZbVca6eXv66aenmIrbyNnxVPWN76zZ+G45m5XqlUntmDxnWXIWJmeVm2ePJuaWiqm+6IszZ2LzO3NGqLuXvHSuWuhuRcXEDgaXs/Cp0unJpYbN6qdUF/eVnAHMGeicle/cVcYH3VKB0JsDPHUl1Ww5Y9/T7g5yWXdfd5Ke6oic2U37UlnZ3f6TslxmwKKc2e/tAYJydj3Vk1lWU1WRfqrzPTkr3tNLSVMtkDPjkyJncHM2P2eQs/znss90r9DTZTRV8alA722pMMn8S0VsKvu606VM51vm5cRejtxdqWDJJUldVepM6JZqvd7s668pn5kKiFTHpHogVRtdVcNM6JYz+X0pFSmpduppf5OpFOrt/t07S8Vrro5IxW6qA7vqI3l8t1TjpNJ8Ui+T6yjVa9mdyrY0leCpikrFWKZd9j06DsrTk1suQ50UqV5NFUoq5NMFSU+3Uc1bqrf7aoCWXH2UWG5WRPX0lmrKvpB5mu1TLulNtUuq3DpXQX/Q+j+V930llU+pXkolbLp66Mn2Kfsefdm2SHVQKgE7DojZnVuueOnLvhubA8BlHZXplqrLni4X2V9Jdwy9tY+U7V+qw1JxncqvVIXl83O5fK6GmZjtao41mlXoEyvb9kybVKWl4nZ84x580C3HFn21HUgbs+6YmGmU/YHeHPCvq0GSUi2d/bfudoXWcTnIfktfSMVfKo7z+ale7+nxQfaHO3YL1Beyf5SrDzp3VfBBt2xz+3LwrlSX5ng31cZZv6WStLtjfuSW/fcsS73RBVpHWX/k6qpU2GYdkqtNsp7qqqul7tyyjzQpy0b2h7J9ShV2jt9Tid7VFY7d2Z/MlTh9sXzmKpNU9yc/M7H7aBO6ynNSJfeRCv8c+zXnY/JZU8oAZq8MlIrbESNGlPnnn7/ceeedZc0112x//Nvf/na55ZZbyj3NEoQODj/88HLEEUeM8/iUUHHblDmas0n//GfbmZycYc2ZlFRX5exOzpJGzmKvumpbpU7OTqWqri+kuiZnVnPG7Zln2qr9cuYw7ciZm+aZp5wFzhmgAw5oa1MrpB05k3rrrW3TJ2c+m5UdqXZNNVX+z2299UrZa6+2v1shZ8hyBv+cc9oqDDpWAOcMcbNyKGfKUhGQs8ITWw3RU2lDqjcffrgtxlJxkOqMVMZkXjarI1JtkrOXqaxLW1shMZ6Kh1R4ZDnILfM0cZaYyzTK3zn7mUrrrFp66wxid6UaImcuE3OJwdyyvObxzOO0MWdoM92ynLZa5mXmayr+Mq9TIZGzojkDm7OfmbdLLNF2JjfzOpVzqRzubanOSFsyP3MWP9MrlSNZTjOdElOZdzn7n7PqqcJKm3qromRCUmmQ2PrjH9uqr/J3s22JwWZ1fKZPqtBSFfv5z/duZdWEpC2pbkp1QipZUhWXyo20LfGfv1MlkfXH5z5Xyic/WVombUgVYa5cSKV05mFz3qZyKJvqVC2noihn+9PGVknlxJ13tsV0Kl9T4ZXtVtqXeEz8J9ZSgZXqjFRktVq2B1km0p6XX25b/ybusu5Ne1KtkKq/DTfs3SrD7u5/pHIklTGZn7mfdVvamvVG5m9kHme7m6qKVH02q9h6U6ZJYj/V6Pk/67C0I8tu/m/eMo0y3VL9sc02rdkeZF2f7WeWgeYtFUCJuUyzZnV8loNUXqVqLhVirZL1bqo2sw+SbWm2oalOaq7bUjmUaZb1/v77917FeXdkWcyVI4mxbJNS9Zj9ykyrTLfmfM16LftsebxV+2xZV6RiLctA4j7zM9uqzNOs+5sV6Kly+ta3Wrc96Dhf074RI9ramnVJ2ph2ZDuf5TDrjewXpRq8t64s60n7Mi+zXcjykGU4265I/GUdl+V1pZXajluyzc9+Zm/L/Mo0+vOf264oTMVf2pJY63jUnPYkvtKOXJHQim1V4izHdZmP2VZlG5V52LxlPmb7nnmZtuX4IBX/zXVvX8v6NXGVKuTsG2WapV3Zl8zymemX46jFFitl003brvLpi/X/hLZPmW6peE1sZV3ccZuQ7VSu1ssVha3aHjRlm5mK2uy75dg5t7Qt8zjr3czXdddtW7dlH6TVEnupZM30y3KabUPzWD77Iom3rNs+/em2+dtKzX2NVFmnLdnvTnuyTsk+UuZrcz2cOEyFbfY/cizTF21JXOXKj6zLsjzkGCHrkTye4/fM2xwfZFuade6++7Zmfy3xlOOW7A9l3yjzMFfPdL4yLvM00zDzM1cltOK4KnI8nPVG1ve5inNKMKoHFbcDrquEt99+u7p1nBgLLrjgFJW4BQAAAAAm78Rti8/19syQIUPKKqusUm7s0LnPmDFjqvsdK3A7mnbaaasf3fEGAAAAADA5adHFyxNvn332qSpsV1111bL66quXH/3oR+X1118vu2TEFQAAAACAAaj2idvtt9++vPjii+XQQw8tzz33XFlppZXKNddcU+buj47lAAAAAABaoNZ93La63wgAAAAAgL4yYPq4BQAAAACYEkncAgAAAADUjMQtAAAAAEDNSNwCAAAAANSMxC0AAAAAQM1I3AIAAAAA1IzELQAAAABAzUjcAgAAAADUjMQtAAAAAEDNSNwCAAAAANSMxC0AAAAAQM1I3AIAAAAA1IzELQAAAABAzUjcAgAAAADUjMQtAAAAAEDNSNwCAAAAANSMxC0AAAAAQM1I3AIAAAAA1MzUZYBrNBrV/6NGjervpgAAAAAAU7BR/z9H2cxZTtGJ21dffbX6f8EFF+zvpgAAAAAAlOQshw0bNsHXDGp0J707GRszZkwZMWJEGTp0aBk0aFCZErL2SVI//fTTZeaZZ+7v5jCAiTVaSbzRKmKNVhFrtIpYo5XEG60i1gaWKW1+NhqNKmk733zzlcGDB0/ZFbeZAAsssECZ0iTQp4Rgp/+JNVpJvNEqYo1WEWu0ilijlcQbrSLWBpYpaX4O+4BK2yaDkwEAAAAA1IzELQAAAABAzUjcDjDTTjttOeyww6r/oS+JNVpJvNEqYo1WEWu0ilijlcQbrSLWBhbzcwoenAwAAAAAYHKj4hYAAAAAoGYkbgEAAAAAakbiFgAAAACgZiRuAQAAAABqRuIWAAAGqDFjxvR3EwAAmEgSt/RIo9Ho7yYwBXjhhRf6uwlMoSQ4aBWxRl/661//Wrbbbrvq78GD7e7Ttxwf0AqOD+gv9tkGhjGT8Xwc1LClpRtefvnlMt1005Xpp5++2jkbNGhQfzeJAerBBx8sq6yySrn55pvLuuuu29/NYQB7/PHHy+23317+97//lWWXXbZssskm1ePWcfS2f//73+X8888vI0eOLAsvvHDZd999+7tJDGB/+ctfykYbbVSt26644oryiU98wnqNPuH4gFZxfECrOD4YeF588cVqOzXTTDNVydvJ8YT25NdiWu7vf/972XTTTcuJJ55Y3njjjWqFJd9PXx1srrfeemXvvfe2U0afevjhh8vqq69eLrvssnLGGWeUAw88sGywwQZl1KhR1nH0eqytueaa1bb0oYceKhdeeGH5wQ9+0N/NYgBvR9dYY43yhS98ofr/4osvrh53sElvc3xAqzg+oFUcHwzMbdWaa65ZvvnNb5ZXXnmlStpOjpW3ErdM0FNPPVV22GGH8vTTT5drr722nH766XbO6LPLOtdaa62y5557lu9///tVfD366KPllltuKc8++2x/N48BJGfQd9ppp7LrrruW3/72t+W+++6rKiATax//+MereMs6bnLcqFMvWYd98pOfLLvttluVQPv9739fFlhggfL222+P9TqxRm9VpOXgZK+99io/+tGPyj777FN+97vfVRVq0JscH9Aqjg9oFccHA89//vOfsssuu5Spp566uvrtoIMOmmyTtxK3jFc2jFdffXWZZ555ylVXXVVWWGGF6sCz487Z5Bbw1FOSGAcffHB58803y1FHHVU9lks7t99+++osZxIfORCF3jBixIjy3nvvVTtmMXTo0LLhhhuWD3/4w+Wxxx4rW2yxRfX45HgZDfUxevToqrp2nXXWqdZvzVibc845y1133VV23HHH8vWvf72KxclxB5L6XQaYKttvfOMb5dhjj60ey35buubIQWeIMXqD4wNaxfEBreT4YOC5+eabqy4SzjvvvGrdkRPcHZO32VefXIg6xis7Xp/61KfKV7/61apPoR//+MfV/82ds9dff70KeGfWmVRDhgwp3/nOd8oyyyxTPvrRj1Z9CU011VTV5Xe5ZCU7ZlnxHnnkkf3dVAaIV199tYqtpuYG/Ic//GHVD+nxxx/fr+1j8pd1WJKzqdbITmMcd9xx5dxzzy1LLLFElcC96aabqgrJbEcdCDCp29Gf/vSn1XazackllyxbbrllVX373HPPiTF6heMDWsXxAa3m+GBg+dznPlddfZSuow444IDy6U9/uj15m/mZ9UnHE411TuQanIwJ6tx5c85C7bHHHuX+++8v2267bVXZMcMMM1RnMb74xS/2a1uZ/GMtfVjtvPPOZZpppimXX355dUlx5Ex7DhByJvQPf/hDtSMHkzIqcTbkM844Y5U0W2655aoEWy6lSd+jn/3sZ6tEWxJsMDGaA1h0HMgilxSnSujQQw8tm2++efXYH//4x+qxXM6+9tpr93OrmVx1NdBG87FcGpjk7ec///nqoCX0d8uk6jxIj+MD+vr4IHGUy50dH9CXV66kC5gMYJVEn+ODgWf06NHlpJNOqva7P/KRj1RXKA0bNqycfPLJVXcsdTZ1fzeAeknfLcOHD682jIsvvnh1GVTHnbI8fsopp5Rvfetb1Zn1bExz6cDZZ59dXbKSS/Kgp7G22GKLlXnnnbestNJK5Re/+EW1A9aMvaxgs5FcaqmlyiOPPOLyOyYp1j70oQ+V+eabr5x66qlVAi07Xzn4TIf1zcvw5pprrvLPf/6zv5vNZHpZ57TTTttlYmPBBResLi/ODmLzudxSedtxWws9jbeuErHNRG7WeRkV+9JLL60GWQkjYzMxfT8+88wz1d9Jms0666ztJweyn+b4gL6Itfnnn7/MNttsZfnlly8///nPq/05xwf0Razl2CD7Y0ngHXbYYeX888+vtpWODyYvTz/9dHUC8d13360Ss8lndc5l5Uq4SPI2lbd5/Gc/+1nVj3GuiKsriVvaZbTrXPqUasf0UZUN4GmnnVZdhpIzmAn0BHaeT9IjZ9azYstBw5/+9Cc7ZUxSrCWmPvOZz1R9pWUHrXlQmUsYIlVDeS5xCJMSa9kp22677coFF1xQrdOy49Zcf2UnLScOcpYdejpq7Ve+8pVqB3/99dfv8jLhmWeeufq/uX7LoD5zzz13dWAKkxpvnZOxzcRaXpOrC84888yy++67S9rSI7lsONWO6QIh29EcDGefbaGFFmrfT0sSzfEBfRFrOSGQGEo/o9k3a56UcnxAb8ZaiofSrVDi7Jxzzqm2ky+//HL7es7xweRxzLfZZptV+9SvvfZadYVlKmpzzJfEfDOXlf/322+/ap6mm5Vsqx544IFaJ21DZ1e0XxqQS5tyCcCtt95arrjiiupSgVzCmT5d0t9LJNCbZ9az4cxlUHfeeWe1YYVJibXcz6ULWdF2PKhMUi39W1155ZVl//33t2PGJMdabtmQ52xsBh5oHlRmlOLvfve71eXrX/7yl/u7+UxGnnjiieoEQZJpzRGIuxpdvbluyyi3qX5Mn6Q5kZDqNejteGsmOHLAkv5us7/2zjvv9FOrmRylumyjjTaqbpdcckk5+uijq/20VNVGM+aa/QQ6PqC3Yy1/R+KqY5cwjg/ozVhLAveyyy6rnk9XCTk+aCZtHR/U38svv1wl4tPlYrY999xzT3XSOvPthBNOqK4Aiawnsq3KNivVuTnhePvtt1eJ+9pLH7fw2GOPNZZaaqnGfffdN9bjP/zhDxuDBg1qnHrqqdX90aNHV/+fc8451eMPPPBAv7SXKSPWrr766sbOO+/cWGCBBcQafRprzz//fOPII49sLLTQQo0HH3ywn1rM5Oitt95qfPOb32xstdVWjYsuuqix3XbbNVZYYYXGzTffXD0/ZsyY6tZ0xx13VK9fcsklxRp9Em9dyfb073//e4tby+Tstddea+ywww6NXXfddazHv/jFLzbWWWedLt/j+IBWxNo111zj+ICWxNoLL7zg+GAy8MILLzSWXnrpxlVXXTXW4xdccEFjjjnmaHz7299uvPnmm+2PX3LJJY0hQ4ZMVusPFbdURo0aVR5//PH2M+epRIu99tqrHHPMMWXvvfeu+gtpnulMJ905c+FMOn0Za4mvddddt6qWFGv0ZazNPvvs1Xrt7rvvnjzOulIbucQq/WJlwLFUdyeu0ude+npsVkJ2vIog/Y2mC6IbbrhBrNEn8dZRc/2X1y+99NL91GomR2+99VbVn+iGG2441mjbW221VfV3Ljnt3K+o4wNaEWsrrrii4wNaEmu5IiqVnI4P6qvRaFRXh6fqNn3/R/P/DC6XitsTTzyx3HTTTe3v2XrrrSe7bdWgZG/7uxHUw6c//eny/PPPV5cTp/PtrLia/Qflkrz0F5KOmxMyRu2kL2MtG8mzzjqrOkA1iAqtWK/l0hlxRm+54447qn75/vGPf1T/r7feetVO5L/+9a+q/zRoRbzloGSZZZbp7+YxGbvvvvvKqquuWv3d3B/LIIsZ0OXee++tLjNt9gWpyxdaEWv//e9/q5PtzT68oa9iLd1xGINg8vGVr3yl/OEPf6j6Vs+g5ynYaR7f5aRiinmuueaa6jgw83hyY21Hu69+9atVEKefoJdeeqkK9ObKLGem8liel7Slr2MtO2XNkdkl02jFek2c0RuaVRprr712VQGZCsf8f+ONN1YxmP7Umn3GQ1/H2wYbbCDemCSdkxuRviDT92gOfvPYwQcfXFV06z+ZVsRarjhIrNlvo69j7WMf+1gVa+oc663x/+dPrqhcfPHFqzGaMpBcju+aFdUZzySvm2666SbLpG1I3NIuK6eMuve3v/2tfO1rX6uq1JpnMvP/LLPMYuVFrxBrtIpYoxWa8ZOYanbJ0UympeIxo9z+/Oc/ryq/M+AFTArxRqtPDiSR0TwAnnnmmcv0009fJTiS3PjBD35QTj/9dIUdtDTWJG6ZWGJtYBn0/+dPuiLLgK25uvITn/hEddVRc9DCFIVl0Lk333xzsj3mM/wi1QorK6lcVrfHHntUiYxcOpzLOXNW85VXXqlGUcwIfXbKmBRijVYRa7Q61pqX1OVMfrOKI8m04447rkqeZdRa3SQwqcQb/RVrzW6GckVUukXYZ599qsRGtqOrrLJKfzeXyZhYo1XE2sCdp6NGjarGkMh8/N73vleWW265ss4661SvSR/Ft912W5Wcn1ypuJ3CpdIsgf7kk09WJeSXXXZZ1YnzueeeW5WbxyKLLFLuueeesvzyy/d3c5mMiTVaRazRH7GWHcRf/vKXY1VxHHvssdUJggyIIInGpBJv9HesNSuXcmIgYxHcddddkhtMErFGq4i1gZu0ffLJJ9vHyEmy9vLLLy8nn3xyNfjYWmutVfV7m0ENJ2cGJ5tC/POf/6ySFi+88EIVwOmLKn2AxBNPPFFVaWSgnlNPPbW9pBwmhlijVcQadYu1M844Y6xL6jIIQk4eGCCKnhBv1DnWHnrooXLggQeWk046qbo0FbpDrNEqYm3gefHFF6srjHIFZWfpzzaJ9s985jPVMV+zinqgkbidAqRvx5xpWGONNcoMM8xQbrjhhrLmmmtW/T7uuuuu5aijjqoWhpyVaK68OnbWDd0l1mgVsUadYw0mlnhjcoi1kSNHdnkADV0Ra7SKWBuY83TllVcuW265ZVVR2+y7v3lcl64tnnvuuXLkkUcO6GM+idsp4JKAL33pS2XGGWcsP/nJT6rHhg8fXg499NDy1FNPld13373svPPO/d1MBgCxRquINVpFrNFK4o26x9pAPBimb4k1WkWsDTxJyG611VZluummK3/5y1/KpptuWn7605+ONfBqBptrDjw9kA38XziFy6A7CfhmMGfFtNRSS5Xjjz+++j+D9Vx11VX93UwGALFGq4g1WkWs0UrijbrHmuQGPSXWaBWxNrBk/j344INl0UUXLSeccEK58sorqy6hvvKVr5RXX321/TUdk7YDuSZV4nYAS+C+++67ZYEFFqhGTszo6nksZyUyMM/BBx9cPX/hhRf2d1OZzIk1WkWs0SpijVYSb7SKWKNVxBqtItYGniTU03ftl7/85bLqqqtWXV50TN6OGjVqrK4Rmu8ZsNJVAgPbjTfe2Bg8eHDj9NNPr+6PGTOm8d5774313N/+9rd+biUDgVijVcQarSLWaCXxRquINVpFrNEqYm3gGj16dPX/HXfc0Zhlllkan/3sZxujRo1qvPPOO40f//jHjRtuuKExkBlme4B54403qhH3csuZh9w23HDDcuyxx5Y99tijTD/99GWXXXZpH21v2LBh1aUD6bwbekKs0SpijVYRa7SSeKNVxBqtItZoFbE2sOdpZ4P/f5cIGXzuD3/4Q/n4xz9evvrVr1bz+Re/+EU1iNlAJnE7gCRYs5Lae++9y+abb16mnvr92ZvHX3/99Wo0xSeffLJ85jOfKQsvvHC55JJLynvvvWcFRo+INVpFrNEqYo1WEm+0ilijVcQarSLWpqx52lm6Tbj88svL+uuvX2adddZy1113lcUWW6wMaP1d8kvveOKJJxpLL710Y6qppmosssgijeuuu67x7rvvjvO6c845pzH33HM35p9//sYyyyzTmG+++RoPPPBAv7SZyZNYo1XEGq0i1mgl8UariDVaRazRKmJtyp2nTW+//XZj9913bwwdOrTxyCOPNKYEg/JPfyePmTQ5c3TaaaeVW265pZx88slVyfif//zncsEFF5QNNthgnLMVjz32WHn66afLm2++WZZbbrmqE2/oDrFGq4g1WkWs0UrijVYRa7SKWKNVxNrA09N5Gvfee2/50pe+VM4999yy2mqrlSmBxO0AkFl45513lueff75stdVW1WMpL3/ooYfK+eefX5WQN/t+GfCj7dGnxBqtItZoFbFGK4k3WkWs0SpijVYRa1PuPO1o5MiRZcyYMWW22WYrUwqJ2wEigdvssLkpAf+Xv/ylOluRjrrTMfeVV15ZnbmYccYZ+62tTN7EGq0i1mgVsUYriTdaRazRKmKNVhFrU/Y8XX/99ctMM81UpjQStwO03LxZUv6xj32sCvizzz67/O53vyt//OMfy6233lrmnXfe/m4mA4BYo1XEGq0i1mgl8UariDVaRazRKmJt4DFPuyZxO0BkNna8FODdd99tLyn/+Mc/Xq655ppqBMX0HbLKKqv0Y0uZ3Ik1WkWs0SpijVYSb7SKWKNVxBqtItYGHvP0g41dj0ztdZVnHz16dBXoL7/8cnn00UerxxLoOVsRSy21VJl11lmrTpyn1ECn58QarSLWaBWxRiuJN1pFrNEqYo1WEWsDj3k68SRuJyOPP/54ufjii8srr7wyVqCnv48nn3yyGinx/vvvb38uJeY/+9nPqtH5rrvuurLsssv2U8uZ3Ig1WkWs0SpijVYSb7SKWKNVxBqtItYGHvN00kjcTiYyqt7qq69eHnzwwfLiiy+2d+KcQH/66afLSiutVLbYYouy/fbbj/W+dN782GOPTdFnJ+gZsUariDVaRazRSuKNVhFrtIpYo1XE2sBjnk46fdxOBhLM66yzTtl2223LSSed1P74O++8U4YMGVIuvfTSctddd5UTTjhhnNH4oCfEGq0i1mgVsUYriTdaRazRKmKNVhFrA4952jskbicDv/71r8uZZ55ZbrrppurMxKGHHlr+/e9/V8G+xx57VGcioDeINVpFrNEqYo1WEm+0ilijVcQarSLWBh7ztHdIaU8mZymGDRtW/Z2zFffdd1+Zfvrpq/sbbrhhOeecc6q/5eCZVGKNVhFrtIpYo5XEG60i1mgVsUariLWBxzztHVP30ufQh+abb75y9913l7PPPrsaUe/nP/95mW222arnjjnmmPLVr361fPSjHy0f/vCH+7upTObEGq0i1mgVsUYriTdaRazRKmKNVhFrA4952jtU3E4G1l577aoz5x//+MfljTfeqAI9Zebx5S9/uSy66KLlkUce6e9mMgCINVpFrNEqYo1WEm+0ilijVcQarSLWBh7ztHeouK2ZJ554olx//fVVx8wLLLBA2WyzzcrCCy9cNtpoo3L00UeX9957rzz++ONVgMdMM81UZpllljLttNP2d9OZzIg1WkWs0SpijVYSb7SKWKNVxBqtItYGHvO0D2VwMurhoYceasw+++yNNdZYo7HYYos1ZppppsYuu+zSePnll6vnTzrppMY888zTWGGFFRp333134+GHH24ceuihjUUWWaTx1FNP9XfzmYyINVpFrNEqYo1WEm+0ilijVcQarSLWBh7ztG9J3NbEq6++2lhzzTUbe+yxR3X/2WefbVx99dWN2WabrbHxxhs3RowYUT3+i1/8orH55ps3Bg0a1Pjwhz/cWHzxxRsPPPBAP7eeyYlYo1XEGq0i1mgl8UariDVaRazRKmJt4DFP+57EbU28+eabjZVXXrnxq1/9aqzHhw8f3phjjjkan/zkJ9sfGzNmTOP+++9vPProo43nn3++H1rL5Eys0SpijVYRa7SSeKNVxBqtItZoFbE28Jinfc/gZDUxevTo8vzzz5fhw4e3P/buu++WJZdcstx4443lj3/8YzniiCOqxwcNGlRWXnnlsvjii5e55pqrH1vN5Eis0SpijVYRa7SSeKNVxBqtItZoFbE28JinfU/itiZmnHHGss8++5SzzjqrXHnlldVj00wzTRXwK6ywQjnooIPK1VdfXf73v/+lSrq/m8tkTKzRKmKNVhFrtJJ4o1XEGq0i1mgVsTbwmKd9b+oWfAddePbZZ8vTTz9dXn755bLxxhuXqaaaqmy11Vbl7rvvLieccEIZMmRI2XTTTauAjznmmKOMGjWqTDfddNVZCugusUariDVaRazRSuKNVhFrtIpYo1XE2sBjnraeitt+8NBDD5U111yz7LjjjmX77bcvH/7wh8uvfvWrMv/885dvf/vbZdiwYeXggw+uHoucqXjssceqUvKUoUN3iTVaRazRKmKNVhJvtIpYo1XEGq0i1gYe87SftKAfXTp44YUXGksvvXTjO9/5TuPf//5345lnnmlsv/32jSWXXLJxxBFHNN56663Gn//858buu+/emHrqqRsrrrhiY4011mjMOuusjQcffLC/m89kRKzRKmKNVhFrtJJ4o1XEGq0i1mgVsTbwmKf9Z1D+6a+k8ZTob3/7W9liiy3KJZdcUlZZZZX2xw888MCqP5Bddtml6h/kjTfeKA8//HC54YYbypxzzlk22mijqgNn6C6xRquINVpFrNFK4o1WEWu0ilijVcTawGOe9h993LZYSsXfe++9KpjjzTffLNNPP3057rjjqr9PPfXUsskmm1SdOK+xxhrVDSaGWKNVxBqtItZoJfFGq4g1WkWs0SpibeAxT/uPitt+sPrqq5eZZpqp/PGPf6zuv/3222Xaaaet/l5ttdWqsxEXXXRRP7eSgUCs0SpijVYRa7SSeKNVxBqtItZoFbE28Jin/cPgZH3s9ddfL6+++mo1il7TT37yk/LII4+Uz33uc9X9BHrOXMS6665bvQd6SqzRKmKNVhFrtJJ4o1XEGq0i1mgVsTbwmKf1IXHbx32AbLXVVmW99dYryyyzTPnlL39ZPZ6/Tz755HL99deXbbfdtio5Hzy4bVa88MILZcYZZ6yCXzE03SXWaBWxRquINVpJvNEqYo1WEWu0ilgbeMzTetHHbR8Ges447LTTTmXVVVct999/f9VZ87LLLls+8pGPlE996lNVUH/961+v+gBZeumly5AhQ8pVV11V7r777jL11GYN3SPWaBWxRquINVpJvNEqYo1WEWu0ilgbeMzT+tHHbR/43//+V3bYYYcqgHM2ommDDTYoyy+/fDnllFPaH0vp+dFHH129Z7rppitf+9rXqgUCukOs0SpijVYRa7SSeKNVxBqtItZoFbE28Jin9SQV3gdSLj5y5MiyzTbbVPfHjBlTlY8vuuiiVVBH8uW5DR06tBx//PFjvQ66S6zRKmKNVhFrtJJ4o1XEGq0i1mgVsTbwmKf1ZMr2gbnnnrv84he/KP/3f/9X3R89enT1//zzz98ezIMGDar+7tjRcx6DnhBrtIpYo1XEGq0k3mgVsUariDVaRawNPOZpPUnc9pElllii/czDNNNMU/2dsxLpsLnp2GOPLT/72c/aR+ET7EwMsUariDVaRazRSuKNVhFrtIpYo1XE2sBjntaPrhL6WM5EJMibgdw8S3HooYdW/YE8+OCDOm+mV4g1WkWs0SpijVYSb7SKWKNVxBqtItYGHvO0PlTctkBz/LcE9YILLlhOOumkcsIJJ5T77ruvrLjiiv3dPAYQsUariDVaRazRSuKNVhFrtIpYo1XE2sBjntaD9HgLNM9MpMz8rLPOKjPPPHO5/fbby8orr9zfTWOAEWu0ilijVcQarSTeaBWxRquINVpFrA085mk9qLhtoc0226z6/8477yyrrrpqfzeHAUys0SpijVYRa7SSeKNVxBqtItZoFbE28Jin/WtQo1n7TEu8/vrrZcYZZ+zvZjAFEGu0ilijVcQarSTeaBWxRquINVpFrA085mn/kbgFAAAAAKgZXSUAAAAAANSMxC0AAAAAQM1I3AIAAAAA1IzELQAAAABAzUjcAgAAAADUjMQtAAAAAEDNSNwCADDZ+eIXv1i23HLL/m4GAAD0man77qMBAKDnBg0aNMHnDzvssHLyySeXRqNR+jt5PHLkyPK73/2uX9sBAMDAJHELAECtPPvss+1///rXvy6HHnpoGT58ePtjM800U3UDAICBTFcJAADUyjzzzNN+GzZsWFWB2/GxJG07d5Ww/vrrlz322KPstddeZdZZZy1zzz13Oeuss8rrr79edtlllzJ06NCy+OKLl6uvvnqs7/rrX/9aPvaxj1WfmffsuOOO5aWXXmp//pJLLinLL798mX766cvss89eNt544+ozDz/88HL++eeXyy+/vGpfbjfffHP1ngMOOKAsueSSZYYZZigf+tCHyiGHHFLefffd9s/Me1daaaVyzjnnlIUWWqj67q9//etl9OjR5YQTTqh+41xzzVW+973vjdXWfMePf/zjqr1pTz477QMAYGCSuAUAYEBIInWOOeYo9957b5XE/drXvla23XbbstZaa5UHHnigbLrpplVi9o033qhen24ONtxww/KRj3yk3HfffeWaa64pzz//fNluu+3aK3932GGH8qUvfan8/e9/rxKzW221VdVFw3777Ve9bvPNN69el1u+J5IkPu+888rf/va3qkuHJJB/+MMfjtXWf//731USOd950UUXlbPPPrtsscUW5T//+U+55ZZbyvHHH18OPvjgcs8994z1viSBt9566/KXv/ylfP7zny+f/exnq7YBADDwDGr0d+dgAAAwHkmApoo2SdYJ9S+bittUrN52223V/fydat0kWi+44ILqseeee67MO++85a677iprrLFGOfroo6vXX3vtte2fm8TpggsuWHXN8Nprr5VVVlmlPPHEE2XhhRee6D5uTzrppPKrX/2qSg43K25PPPHEqj1J8kYSwPnOJHQHD26rrVh66aWr7zjwwAPbK2533333quq2Kb9j5ZVXLmecccZETmEAAOpKH7cAAAwIK6ywQvvfU001VdW1Qbo5aEpXCPHCCy9U/6dq9aabbuqyv9wkUFOhu9FGG1Wfsdlmm1X3t9lmm6orhglJv7ynnHJK9RlJ/r733ntl5plnHus1iyyySHvSttm2tLmZtG0+1mxr05prrjnO/T//+c8fOG0AAJj86CoBAIABYZppphnrfipUOz6W+zFmzJjq/yRVP/nJT1aJz463Rx99tKy77rpVIvX666+vujRYdtlly6mnnlqWWmqp8vjjj4+3DanmTRcGH//4x8uVV15ZHnzwwfLd7363vPPOOz1qa/OxZlsBAJjySNwCADBFShcDjzzySFX9moHLOt5mnHHG9uTp2muvXY444ogqCTtkyJDy29/+tnouf6dLho7uvPPOqluFJGtXXXXVssQSS5Qnn3yy19p89913j3N/mWWW6bXPBwCgPiRuAQCYIn3jG98o//vf/6oByP70pz9VXRukv9tddtmlSshmYLBjjjmm6pv2qaeeKpdddll58cUX2xOlSfg+9NBDVd+0L730Unn33XerRG1emz5t83npMqGZ6O0NF198cTnnnHPKP//5z3LYYYdVA7F985vf7LXPBwCgPiRuAQCYIs0333zljjvuqJK06b82fdlmILRZZpml6ms2/dLeeuutVbcHSy65ZDn44IPL97///fKxj32sev9uu+1WdZ2Qyto555yz+qxPfepTZe+9966SqSuttFJVgXvIIYf0WptT+ZukcPrzzaBrF110UdWNAwAAA8+gRqPR6O9GAAAAE5ZuG1K9u+WWW/Z3UwAAaAEVtwAAAAAANSNxCwAAAABQM1P3dwMAAIAPpoczAIApi4pbAAAAAICakbgFAAAAAKgZiVsAAAAAgJqRuAUAAAAAqBmJWwAAAACAmpG4BQAAAACoGYlbAAAAAICakbgFAAAAAKgZiVsAAAAAgFIv/w9LAmKgzbIkEwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(site_data['timestamp'], site_data['volume'], label='Actual Volume', color='blue')\n",
    "plt.plot(site_data['timestamp'][:len(y_pred)], pred_volume, label='Predicted Volume', color='red')\n",
    "\n",
    "# plt.plot(site_data['timestamp'], y_pred_actual, label='Predicted Volume', color='red')\n",
    "plt.title(f'Volume Prediction for Site {id}')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Volume')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c72a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "traffic_based_guidance_solution",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
